// Autogenerated by jnigen. DO NOT EDIT!

// ignore_for_file: annotate_overrides
// ignore_for_file: camel_case_types
// ignore_for_file: constant_identifier_names
// ignore_for_file: file_names
// ignore_for_file: no_leading_underscores_for_local_identifiers
// ignore_for_file: non_constant_identifier_names
// ignore_for_file: unused_element
// ignore_for_file: unused_field
// ignore_for_file: unused_import
// ignore_for_file: unused_shown_name

import "package:jni/jni.dart" as jni;

import "package:jni/internal_helpers_for_jnigen.dart";

import "MediaFormat.dart" as mediaformat_;

import "../view/Surface.dart" as surface_;

import "MediaCrypto.dart" as mediacrypto_;

import "MediaDescrambler.dart" as mediadescrambler_;

import "Image.dart" as image_;

import "../os/PersistableBundle.dart" as persistablebundle_;

import "../os/Bundle.dart" as bundle_;

import "../os/Handler.dart" as handler_;

import "MediaCodecInfo.dart" as mediacodecinfo_;
import "../../_init.dart" show jniEnv, jniAccessors;

/// from: android.media.MediaCodec
///
/// MediaCodec class can be used to access low-level media codecs, i.e. encoder/decoder components.
/// It is part of the Android low-level multimedia support infrastructure (normally used together
/// with MediaExtractor, MediaSync, MediaMuxer, MediaCrypto,
/// MediaDrm, Image, Surface, and AudioTrack.)
///
/// <center><object style="width: 540px; height: 205px;"type="image/svg+xml"data="../../../images/media/mediacodec_buffers.svg"><img src="../../../images/media/mediacodec_buffers.png"style="width: 540px; height: 205px"alt="MediaCodec buffer flow diagram"></object></center>
///
/// In broad terms, a codec processes input data to generate output data. It processes data
/// asynchronously and uses a set of input and output buffers. At a simplistic level, you request
/// (or receive) an empty input buffer, fill it up with data and send it to the codec for
/// processing. The codec uses up the data and transforms it into one of its empty output buffers.
/// Finally, you request (or receive) a filled output buffer, consume its contents and release it
/// back to the codec.
///
/// <h3>Data Types</h3>
///
/// Codecs operate on three kinds of data: compressed data, raw audio data and raw video data.
/// All three kinds of data can be processed using ByteBuffer ByteBuffers, but you should use
/// a Surface for raw video data to improve codec performance. Surface uses native video
/// buffers without mapping or copying them to ByteBuffers; thus, it is much more efficient.
/// You normally cannot access the raw video data when using a Surface, but you can use the
/// ImageReader class to access unsecured decoded (raw) video frames. This may still be more
/// efficient than using ByteBuffers, as some native buffers may be mapped into {@linkplain ByteBuffer\#isDirect direct} ByteBuffers. When using ByteBuffer mode, you can access raw video
/// frames using the Image class and \#getInputImage getInput/\#getOutputImage OutputImage(int).
///
/// <h4>Compressed Buffers</h4>
///
/// Input buffers (for decoders) and output buffers (for encoders) contain compressed data according
/// to the {@linkplain MediaFormat\#KEY_MIME format's type}. For video types this is normally a single
/// compressed video frame. For audio data this is normally a single access unit (an encoded audio
/// segment typically containing a few milliseconds of audio as dictated by the format type), but
/// this requirement is slightly relaxed in that a buffer may contain multiple encoded access units
/// of audio. In either case, buffers do not start or end on arbitrary byte boundaries, but rather on
/// frame/access unit boundaries unless they are flagged with \#BUFFER_FLAG_PARTIAL_FRAME.
///
/// <h4>Raw Audio Buffers</h4>
///
/// Raw audio buffers contain entire frames of PCM audio data, which is one sample for each channel
/// in channel order. Each sample is a {@linkplain AudioFormat\#ENCODING_PCM_16BIT 16-bit signed
/// integer in native byte order}.
///
/// <pre class=prettyprint>
/// short[] getSamplesForChannel(MediaCodec codec, int bufferId, int channelIx) {
///  ByteBuffer outputBuffer = codec.getOutputBuffer(bufferId);
///  MediaFormat format = codec.getOutputFormat(bufferId);
///  ShortBuffer samples = outputBuffer.order(ByteOrder.nativeOrder()).asShortBuffer();
///  int numChannels = formet.getInteger(MediaFormat.KEY_CHANNEL_COUNT);
///  if (channelIx &lt; 0 || channelIx &gt;= numChannels) {
///    return null;
///  }
///  short[] res = new short[samples.remaining() / numChannels];
///  for (int i = 0; i &lt; res.length; ++i) {
///    res[i] = samples.get(i * numChannels + channelIx);
///  }
///  return res;
/// }</pre>
///
/// <h4>Raw Video Buffers</h4>
///
/// In ByteBuffer mode video buffers are laid out according to their {@linkplain MediaFormat\#KEY_COLOR_FORMAT color format}. You can get the supported color formats as an array
/// from \#getCodecInfo{@code .}MediaCodecInfo\#getCapabilitiesForType getCapabilitiesForType(&hellip;){@code .}CodecCapabilities\#colorFormats colorFormats.
/// Video codecs may support three kinds of color formats:
/// <ul>
/// <li><strong>native raw video format:</strong> This is marked by CodecCapabilities\#COLOR_FormatSurface and it can be used with an input or output Surface.</li>
/// <li><strong>flexible YUV buffers</strong> (such as CodecCapabilities\#COLOR_FormatYUV420Flexible): These can be used with an input/output Surface,
/// as well as in ByteBuffer mode, by using \#getInputImage getInput/\#getOutputImage OutputImage(int).</li>
/// <li><strong>other, specific formats:</strong> These are normally only supported in ByteBuffer
/// mode. Some color formats are vendor specific. Others are defined in CodecCapabilities.
/// For color formats that are equivalent to a flexible format, you can still use \#getInputImage getInput/\#getOutputImage OutputImage(int).</li>
/// </ul>
///
/// All video codecs support flexible YUV 4:2:0 buffers since android.os.Build.VERSION_CODES\#LOLLIPOP_MR1.
///
/// <h4>Accessing Raw Video ByteBuffers on Older Devices</h4>
///
/// Prior to android.os.Build.VERSION_CODES\#LOLLIPOP and Image support, you need to
/// use the MediaFormat\#KEY_STRIDE and MediaFormat\#KEY_SLICE_HEIGHT output format
/// values to understand the layout of the raw output buffers.
/// <p class=note>
/// Note that on some devices the slice-height is advertised as 0. This could mean either that the
/// slice-height is the same as the frame height, or that the slice-height is the frame height
/// aligned to some value (usually a power of 2). Unfortunately, there is no standard and simple way
/// to tell the actual slice height in this case. Furthermore, the vertical stride of the {@code U}
/// plane in planar formats is also not specified or defined, though usually it is half of the slice
/// height.
///
/// The MediaFormat\#KEY_WIDTH and MediaFormat\#KEY_HEIGHT keys specify the size of the
/// video frames; however, for most encondings the video (picture) only occupies a portion of the
/// video frame. This is represented by the 'crop rectangle'.
///
/// You need to use the following keys to get the crop rectangle of raw output images from the
/// {@linkplain \#getOutputFormat output format}. If these keys are not present, the video occupies the
/// entire video frame.The crop rectangle is understood in the context of the output frame
/// _before_ applying any {@linkplain MediaFormat\#KEY_ROTATION rotation}.
/// <table style="width: 0%">
/// <thead>
///  <tr>
///   <th>Format Key</th>
///   <th>Type</th>
///   <th>Description</th>
///  </tr>
/// </thead>
/// <tbody>
///  <tr>
///   <td>{@code "crop-left"}</td>
///   <td>Integer</td>
///   <td>The left-coordinate (x) of the crop rectangle</td>
///  </tr><tr>
///   <td>{@code "crop-top"}</td>
///   <td>Integer</td>
///   <td>The top-coordinate (y) of the crop rectangle</td>
///  </tr><tr>
///   <td>{@code "crop-right"}</td>
///   <td>Integer</td>
///   <td>The right-coordinate (x) <strong>MINUS 1</strong> of the crop rectangle</td>
///  </tr><tr>
///   <td>{@code "crop-bottom"}</td>
///   <td>Integer</td>
///   <td>The bottom-coordinate (y) <strong>MINUS 1</strong> of the crop rectangle</td>
///  </tr><tr>
///   <td colspan=3>
///    The right and bottom coordinates can be understood as the coordinates of the right-most
///    valid column/bottom-most valid row of the cropped output image.
///   </td>
///  </tr>
/// </tbody>
/// </table>
///
/// The size of the video frame (before rotation) can be calculated as such:
/// <pre class=prettyprint>
/// MediaFormat format = decoder.getOutputFormat(&hellip;);
/// int width = format.getInteger(MediaFormat.KEY_WIDTH);
/// if (format.containsKey("crop-left") && format.containsKey("crop-right")) {
///    width = format.getInteger("crop-right") + 1 - format.getInteger("crop-left");
/// }
/// int height = format.getInteger(MediaFormat.KEY_HEIGHT);
/// if (format.containsKey("crop-top") && format.containsKey("crop-bottom")) {
///    height = format.getInteger("crop-bottom") + 1 - format.getInteger("crop-top");
/// }
/// </pre>
/// <p class=note>
/// Also note that the meaning of BufferInfo\#offset BufferInfo.offset was not consistent across
/// devices. On some devices the offset pointed to the top-left pixel of the crop rectangle, while on
/// most devices it pointed to the top-left pixel of the entire frame.
///
/// <h3>States</h3>
///
/// During its life a codec conceptually exists in one of three states: Stopped, Executing or
/// Released. The Stopped collective state is actually the conglomeration of three states:
/// Uninitialized, Configured and Error, whereas the Executing state conceptually progresses through
/// three sub-states: Flushed, Running and End-of-Stream.
///
/// <center><object style="width: 516px; height: 353px;"type="image/svg+xml"data="../../../images/media/mediacodec_states.svg"><img src="../../../images/media/mediacodec_states.png"style="width: 519px; height: 356px"alt="MediaCodec state diagram"></object></center>
///
/// When you create a codec using one of the factory methods, the codec is in the Uninitialized
/// state. First, you need to configure it via \#configure configure(&hellip;), which brings
/// it to the Configured state, then call \#start to move it to the Executing state. In this
/// state you can process data through the buffer queue manipulation described above.
///
/// The Executing state has three sub-states: Flushed, Running and End-of-Stream. Immediately after
/// \#start the codec is in the Flushed sub-state, where it holds all the buffers. As soon
/// as the first input buffer is dequeued, the codec moves to the Running sub-state, where it spends
/// most of its life. When you queue an input buffer with the {@linkplain \#BUFFER_FLAG_END_OF_STREAM end-of-stream marker}, the codec transitions to the End-of-Stream sub-state. In this state the
/// codec no longer accepts further input buffers, but still generates output buffers until the
/// end-of-stream is reached on the output. You can move back to the Flushed sub-state at any time
/// while in the Executing state using \#flush.
///
/// Call \#stop to return the codec to the Uninitialized state, whereupon it may be configured
/// again. When you are done using a codec, you must release it by calling \#release.
///
/// On rare occasions the codec may encounter an error and move to the Error state. This is
/// communicated using an invalid return value from a queuing operation, or sometimes via an
/// exception. Call \#reset to make the codec usable again. You can call it from any state to
/// move the codec back to the Uninitialized state. Otherwise, call \#release to move to the
/// terminal Released state.
///
/// <h3>Creation</h3>
///
/// Use MediaCodecList to create a MediaCodec for a specific MediaFormat. When
/// decoding a file or a stream, you can get the desired format from MediaExtractor\#getTrackFormat MediaExtractor.getTrackFormat. Inject any specific features that
/// you want to add using MediaFormat\#setFeatureEnabled MediaFormat.setFeatureEnabled, then
/// call MediaCodecList\#findDecoderForFormat MediaCodecList.findDecoderForFormat to get the
/// name of a codec that can handle that specific media format. Finally, create the codec using
/// \#createByCodecName.
/// <p class=note>
/// <strong>Note:</strong> On android.os.Build.VERSION_CODES\#LOLLIPOP, the format to
/// {@code MediaCodecList.findDecoder}/{@code EncoderForFormat} must not contain a {@linkplain MediaFormat\#KEY_FRAME_RATE frame rate}. Use
/// <code class=prettyprint>format.setString(MediaFormat.KEY_FRAME_RATE, null)</code>
/// to clear any existing frame rate setting in the format.
///
/// You can also create the preferred codec for a specific MIME type using \#createDecoderByType createDecoder/\#createEncoderByType EncoderByType(String).
/// This, however, cannot be used to inject features, and may create a codec that cannot handle the
/// specific desired media format.
///
/// <h4>Creating secure decoders</h4>
///
/// On versions android.os.Build.VERSION_CODES\#KITKAT_WATCH and earlier, secure codecs might
/// not be listed in MediaCodecList, but may still be available on the system. Secure codecs
/// that exist can be instantiated by name only, by appending {@code ".secure"} to the name of a
/// regular codec (the name of all secure codecs must end in {@code ".secure"}.) \#createByCodecName will throw an {@code IOException} if the codec is not present on the system.
///
/// From android.os.Build.VERSION_CODES\#LOLLIPOP onwards, you should use the CodecCapabilities\#FEATURE_SecurePlayback feature in the media format to create a secure decoder.
///
/// <h3>Initialization</h3>
///
/// After creating the codec, you can set a callback using \#setCallback setCallback if you
/// want to process data asynchronously. Then, {@linkplain \#configure configure} the codec using the
/// specific media format. This is when you can specify the output Surface for video
/// producers &ndash; codecs that generate raw video data (e.g. video decoders). This is also when
/// you can set the decryption parameters for secure codecs (see MediaCrypto). Finally, since
/// some codecs can operate in multiple modes, you must specify whether you want it to work as a
/// decoder or an encoder.
///
/// Since android.os.Build.VERSION_CODES\#LOLLIPOP, you can query the resulting input and
/// output format in the Configured state. You can use this to verify the resulting configuration,
/// e.g. color formats, before starting the codec.
///
/// If you want to process raw input video buffers natively with a video consumer &ndash; a codec
/// that processes raw video input, such as a video encoder &ndash; create a destination Surface for
/// your input data using \#createInputSurface after configuration. Alternately, set up the
/// codec to use a previously created {@linkplain \#createPersistentInputSurface persistent input
/// surface} by calling \#setInputSurface.
///
/// <h4 id=CSD><a name="CSD"></a>Codec-specific Data</h4>
///
/// Some formats, notably AAC audio and MPEG4, H.264 and H.265 video formats require the actual data
/// to be prefixed by a number of buffers containing setup data, or codec specific data. When
/// processing such compressed formats, this data must be submitted to the codec after \#start and before any frame data. Such data must be marked using the flag \#BUFFER_FLAG_CODEC_CONFIG in a call to \#queueInputBuffer queueInputBuffer.
///
/// Codec-specific data can also be included in the format passed to \#configure configure in
/// ByteBuffer entries with keys "csd-0", "csd-1", etc. These keys are always included in the track
/// MediaFormat obtained from the MediaExtractor\#getTrackFormat MediaExtractor.
/// Codec-specific data in the format is automatically submitted to the codec upon \#start;
/// you <strong>MUST NOT</strong> submit this data explicitly. If the format did not contain codec
/// specific data, you can choose to submit it using the specified number of buffers in the correct
/// order, according to the format requirements. In case of H.264 AVC, you can also concatenate all
/// codec-specific data and submit it as a single codec-config buffer.
///
/// Android uses the following codec-specific data buffers. These are also required to be set in
/// the track format for proper MediaMuxer track configuration. Each parameter set and the
/// codec-specific-data sections marked with (<sup>*</sup>) must start with a start code of
/// {@code "\x00\x00\x00\x01"}.
///
/// <style>td.NA { background: \#ccc; } .mid > tr > td { vertical-align: middle; }</style>
/// <table>
/// <thead>
///  <th>Format</th>
///  <th>CSD buffer \#0</th>
///  <th>CSD buffer \#1</th>
///  <th>CSD buffer \#2</th>
/// </thead>
/// <tbody class=mid>
///  <tr>
///   <td>AAC</td>
///   <td>Decoder-specific information from ESDS<sup>*</sup></td>
///   <td class=NA>Not Used</td>
///   <td class=NA>Not Used</td>
///  </tr>
///  <tr>
///   <td>VORBIS</td>
///   <td>Identification header</td>
///   <td>Setup header</td>
///   <td class=NA>Not Used</td>
///  </tr>
///  <tr>
///   <td>OPUS</td>
///   <td>Identification header</td>
///   <td>Pre-skip in nanosecs<br>
///       (unsigned 64-bit {@linkplain ByteOrder\#nativeOrder native-order} integer.)<br>
///       This overrides the pre-skip value in the identification header.</td>
///   <td>Seek Pre-roll in nanosecs<br>
///       (unsigned 64-bit {@linkplain ByteOrder\#nativeOrder native-order} integer.)</td>
///  </tr>
///  <tr>
///   <td>FLAC</td>
///   <td>mandatory metadata block (called the STREAMINFO block),<br>
///       optionally followed by any number of other metadata blocks</td>
///   <td class=NA>Not Used</td>
///   <td class=NA>Not Used</td>
///  </tr>
///  <tr>
///   <td>MPEG-4</td>
///   <td>Decoder-specific information from ESDS<sup>*</sup></td>
///   <td class=NA>Not Used</td>
///   <td class=NA>Not Used</td>
///  </tr>
///  <tr>
///   <td>H.264 AVC</td>
///   <td>SPS (Sequence Parameter Sets<sup>*</sup>)</td>
///   <td>PPS (Picture Parameter Sets<sup>*</sup>)</td>
///   <td class=NA>Not Used</td>
///  </tr>
///  <tr>
///   <td>H.265 HEVC</td>
///   <td>VPS (Video Parameter Sets<sup>*</sup>) +<br>
///    SPS (Sequence Parameter Sets<sup>*</sup>) +<br>
///    PPS (Picture Parameter Sets<sup>*</sup>)</td>
///   <td class=NA>Not Used</td>
///   <td class=NA>Not Used</td>
///  </tr>
///  <tr>
///   <td>VP9</td>
///   <td>VP9 <a href="http://wiki.webmproject.org/vp9-codecprivate">CodecPrivate</a> Data
///       (optional)</td>
///   <td class=NA>Not Used</td>
///   <td class=NA>Not Used</td>
///  </tr>
/// </tbody>
/// </table>
///
/// <p class=note>
/// <strong>Note:</strong> care must be taken if the codec is flushed immediately or shortly
/// after start, before any output buffer or output format change has been returned, as the codec
/// specific data may be lost during the flush. You must resubmit the data using buffers marked with
/// \#BUFFER_FLAG_CODEC_CONFIG after such flush to ensure proper codec operation.
///
/// Encoders (or codecs that generate compressed data) will create and return the codec specific data
/// before any valid output buffer in output buffers marked with the {@linkplain \#BUFFER_FLAG_CODEC_CONFIG codec-config flag}. Buffers containing codec-specific-data have no
/// meaningful timestamps.
///
/// <h3>Data Processing</h3>
///
/// Each codec maintains a set of input and output buffers that are referred to by a buffer-ID in
/// API calls. After a successful call to \#start the client "owns" neither input nor output
/// buffers. In synchronous mode, call \#dequeueInputBuffer dequeueInput/\#dequeueOutputBuffer OutputBuffer(&hellip;) to obtain (get ownership of) an input or output
/// buffer from the codec. In asynchronous mode, you will automatically receive available buffers via
/// the Callback\#onInputBufferAvailable MediaCodec.Callback.onInput/Callback\#onOutputBufferAvailable OutputBufferAvailable(&hellip;) callbacks.
///
/// Upon obtaining an input buffer, fill it with data and submit it to the codec using \#queueInputBuffer queueInputBuffer &ndash; or \#queueSecureInputBuffer queueSecureInputBuffer if using decryption. Do not submit multiple input buffers with the same
/// timestamp (unless it is <a href="\#CSD">codec-specific data</a> marked as such).
///
/// The codec in turn will return a read-only output buffer via the Callback\#onOutputBufferAvailable onOutputBufferAvailable callback in asynchronous mode, or in
/// response to a \#dequeueOutputBuffer dequeuOutputBuffer call in synchronous mode. After the
/// output buffer has been processed, call one of the \#releaseOutputBuffer releaseOutputBuffer methods to return the buffer to the codec.
///
/// While you are not required to resubmit/release buffers immediately to the codec, holding onto
/// input and/or output buffers may stall the codec, and this behavior is device dependent.
/// <strong>Specifically, it is possible that a codec may hold off on generating output buffers until
/// _all_ outstanding buffers have been released/resubmitted.</strong> Therefore, try to
/// hold onto to available buffers as little as possible.
///
/// Depending on the API version, you can process data in three ways:
/// <table>
/// <thead>
///  <tr>
///   <th>Processing Mode</th>
///   <th>API version <= 20<br>Jelly Bean/KitKat</th>
///   <th>API version >= 21<br>Lollipop and later</th>
///  </tr>
/// </thead>
/// <tbody>
///  <tr>
///   <td>Synchronous API using buffer arrays</td>
///   <td>Supported</td>
///   <td>Deprecated</td>
///  </tr>
///  <tr>
///   <td>Synchronous API using buffers</td>
///   <td class=NA>Not Available</td>
///   <td>Supported</td>
///  </tr>
///  <tr>
///   <td>Asynchronous API using buffers</td>
///   <td class=NA>Not Available</td>
///   <td>Supported</td>
///  </tr>
/// </tbody>
/// </table>
///
/// <h4>Asynchronous Processing using Buffers</h4>
///
/// Since android.os.Build.VERSION_CODES\#LOLLIPOP, the preferred method is to process data
/// asynchronously by setting a callback before calling \#configure configure. Asynchronous
/// mode changes the state transitions slightly, because you must call \#start after \#flush to transition the codec to the Running sub-state and start receiving input buffers.
/// Similarly, upon an initial call to {@code start} the codec will move directly to the Running
/// sub-state and start passing available input buffers via the callback.
///
/// <center><object style="width: 516px; height: 353px;"type="image/svg+xml"data="../../../images/media/mediacodec_async_states.svg"><img src="../../../images/media/mediacodec_async_states.png"style="width: 516px; height: 353px"alt="MediaCodec state diagram for asynchronous operation"></object></center>
///
/// MediaCodec is typically used like this in asynchronous mode:
/// <pre class=prettyprint>
/// MediaCodec codec = MediaCodec.createByCodecName(name);
/// MediaFormat mOutputFormat; // member variable
/// codec.setCallback(new MediaCodec.Callback() {
///  {@literal @Override}
///  void onInputBufferAvailable(MediaCodec mc, int inputBufferId) {
///    ByteBuffer inputBuffer = codec.getInputBuffer(inputBufferId);
///    // fill inputBuffer with valid data
///    &hellip;
///    codec.queueInputBuffer(inputBufferId, &hellip;);
///  }
///
///  {@literal @Override}
///  void onOutputBufferAvailable(MediaCodec mc, int outputBufferId, &hellip;) {
///    ByteBuffer outputBuffer = codec.getOutputBuffer(outputBufferId);
///    MediaFormat bufferFormat = codec.getOutputFormat(outputBufferId); // option A
///    // bufferFormat is equivalent to mOutputFormat
///    // outputBuffer is ready to be processed or rendered.
///    &hellip;
///    codec.releaseOutputBuffer(outputBufferId, &hellip;);
///  }
///
///  {@literal @Override}
///  void onOutputFormatChanged(MediaCodec mc, MediaFormat format) {
///    // Subsequent data will conform to new format.
///    // Can ignore if using getOutputFormat(outputBufferId)
///    mOutputFormat = format; // option B
///  }
///
///  {@literal @Override}
///  void onError(&hellip;) {
///    &hellip;
///  }
/// });
/// codec.configure(format, &hellip;);
/// mOutputFormat = codec.getOutputFormat(); // option B
/// codec.start();
/// // wait for processing to complete
/// codec.stop();
/// codec.release();</pre>
///
/// <h4>Synchronous Processing using Buffers</h4>
///
/// Since android.os.Build.VERSION_CODES\#LOLLIPOP, you should retrieve input and output
/// buffers using \#getInputBuffer getInput/\#getOutputBuffer OutputBuffer(int) and/or
/// \#getInputImage getInput/\#getOutputImage OutputImage(int) even when using the
/// codec in synchronous mode. This allows certain optimizations by the framework, e.g. when
/// processing dynamic content. This optimization is disabled if you call \#getInputBuffers getInput/\#getOutputBuffers OutputBuffers().
///
/// <p class=note>
/// <strong>Note:</strong> do not mix the methods of using buffers and buffer arrays at the same
/// time. Specifically, only call {@code getInput}/{@code OutputBuffers} directly after \#start or after having dequeued an output buffer ID with the value of \#INFO_OUTPUT_FORMAT_CHANGED.
///
/// MediaCodec is typically used like this in synchronous mode:
/// <pre>
/// MediaCodec codec = MediaCodec.createByCodecName(name);
/// codec.configure(format, &hellip;);
/// MediaFormat outputFormat = codec.getOutputFormat(); // option B
/// codec.start();
/// for (;;) {
///  int inputBufferId = codec.dequeueInputBuffer(timeoutUs);
///  if (inputBufferId &gt;= 0) {
///    ByteBuffer inputBuffer = codec.getInputBuffer(&hellip;);
///    // fill inputBuffer with valid data
///    &hellip;
///    codec.queueInputBuffer(inputBufferId, &hellip;);
///  }
///  int outputBufferId = codec.dequeueOutputBuffer(&hellip;);
///  if (outputBufferId &gt;= 0) {
///    ByteBuffer outputBuffer = codec.getOutputBuffer(outputBufferId);
///    MediaFormat bufferFormat = codec.getOutputFormat(outputBufferId); // option A
///    // bufferFormat is identical to outputFormat
///    // outputBuffer is ready to be processed or rendered.
///    &hellip;
///    codec.releaseOutputBuffer(outputBufferId, &hellip;);
///  } else if (outputBufferId == MediaCodec.INFO_OUTPUT_FORMAT_CHANGED) {
///    // Subsequent data will conform to new format.
///    // Can ignore if using getOutputFormat(outputBufferId)
///    outputFormat = codec.getOutputFormat(); // option B
///  }
/// }
/// codec.stop();
/// codec.release();</pre>
///
/// <h4>Synchronous Processing using Buffer Arrays (deprecated)</h4>
///
/// In versions android.os.Build.VERSION_CODES\#KITKAT_WATCH and before, the set of input and
/// output buffers are represented by the {@code ByteBuffer[]} arrays. After a successful call to
/// \#start, retrieve the buffer arrays using \#getInputBuffers getInput/\#getOutputBuffers OutputBuffers(). Use the buffer ID-s as indices into these arrays (when
/// non-negative), as demonstrated in the sample below. Note that there is no inherent correlation
/// between the size of the arrays and the number of input and output buffers used by the system,
/// although the array size provides an upper bound.
/// <pre>
/// MediaCodec codec = MediaCodec.createByCodecName(name);
/// codec.configure(format, &hellip;);
/// codec.start();
/// ByteBuffer[] inputBuffers = codec.getInputBuffers();
/// ByteBuffer[] outputBuffers = codec.getOutputBuffers();
/// for (;;) {
///  int inputBufferId = codec.dequeueInputBuffer(&hellip;);
///  if (inputBufferId &gt;= 0) {
///    // fill inputBuffers[inputBufferId] with valid data
///    &hellip;
///    codec.queueInputBuffer(inputBufferId, &hellip;);
///  }
///  int outputBufferId = codec.dequeueOutputBuffer(&hellip;);
///  if (outputBufferId &gt;= 0) {
///    // outputBuffers[outputBufferId] is ready to be processed or rendered.
///    &hellip;
///    codec.releaseOutputBuffer(outputBufferId, &hellip;);
///  } else if (outputBufferId == MediaCodec.INFO_OUTPUT_BUFFERS_CHANGED) {
///    outputBuffers = codec.getOutputBuffers();
///  } else if (outputBufferId == MediaCodec.INFO_OUTPUT_FORMAT_CHANGED) {
///    // Subsequent data will conform to new format.
///    MediaFormat format = codec.getOutputFormat();
///  }
/// }
/// codec.stop();
/// codec.release();</pre>
///
/// <h4>End-of-stream Handling</h4>
///
/// When you reach the end of the input data, you must signal it to the codec by specifying the
/// \#BUFFER_FLAG_END_OF_STREAM flag in the call to \#queueInputBuffer queueInputBuffer. You can do this on the last valid input buffer, or by submitting an additional
/// empty input buffer with the end-of-stream flag set. If using an empty buffer, the timestamp will
/// be ignored.
///
/// The codec will continue to return output buffers until it eventually signals the end of the
/// output stream by specifying the same end-of-stream flag in the BufferInfo set in \#dequeueOutputBuffer dequeueOutputBuffer or returned via Callback\#onOutputBufferAvailable onOutputBufferAvailable. This can be set on the last valid output buffer, or on an empty buffer
/// after the last valid output buffer. The timestamp of such empty buffer should be ignored.
///
/// Do not submit additional input buffers after signaling the end of the input stream, unless the
/// codec has been flushed, or stopped and restarted.
///
/// <h4>Using an Output Surface</h4>
///
/// The data processing is nearly identical to the ByteBuffer mode when using an output Surface; however, the output buffers will not be accessible, and are represented as {@code null}
/// values. E.g. \#getOutputBuffer getOutputBuffer/\#getOutputImage Image(int) will
/// return {@code null} and \#getOutputBuffers will return an array containing only {@code
/// null}-s.
///
/// When using an output Surface, you can select whether or not to render each output buffer on the
/// surface. You have three choices:
/// <ul>
/// <li><strong>Do not render the buffer:</strong> Call \#releaseOutputBuffer(int, boolean) releaseOutputBuffer(bufferId, false).</li>
/// <li><strong>Render the buffer with the default timestamp:</strong> Call \#releaseOutputBuffer(int, boolean) releaseOutputBuffer(bufferId, true).</li>
/// <li><strong>Render the buffer with a specific timestamp:</strong> Call \#releaseOutputBuffer(int, long) releaseOutputBuffer(bufferId, timestamp).</li>
/// </ul>
///
/// Since android.os.Build.VERSION_CODES\#M, the default timestamp is the {@linkplain BufferInfo\#presentationTimeUs presentation timestamp} of the buffer (converted to nanoseconds).
/// It was not defined prior to that.
///
/// Also since android.os.Build.VERSION_CODES\#M, you can change the output Surface
/// dynamically using \#setOutputSurface setOutputSurface.
///
/// <h4>Transformations When Rendering onto Surface</h4>
///
/// If the codec is configured into Surface mode, any crop rectangle, {@linkplain MediaFormat\#KEY_ROTATION rotation} and {@linkplain \#setVideoScalingMode video scaling
/// mode} will be automatically applied with one exception:
/// <p class=note>
/// Prior to the android.os.Build.VERSION_CODES\#M release, software decoders may not
/// have applied the rotation when being rendered onto a Surface. Unfortunately, there is no standard
/// and simple way to identify software decoders, or if they apply the rotation other than by trying
/// it out.
///
/// There are also some caveats.
/// <p class=note>
/// Note that the pixel aspect ratio is not considered when displaying the output onto the
/// Surface. This means that if you are using \#VIDEO_SCALING_MODE_SCALE_TO_FIT mode, you
/// must position the output Surface so that it has the proper final display aspect ratio. Conversely,
/// you can only use \#VIDEO_SCALING_MODE_SCALE_TO_FIT_WITH_CROPPING mode for content with
/// square pixels (pixel aspect ratio or 1:1).
/// <p class=note>
/// Note also that as of android.os.Build.VERSION_CODES\#N release, \#VIDEO_SCALING_MODE_SCALE_TO_FIT_WITH_CROPPING mode may not work correctly for videos rotated
/// by 90 or 270 degrees.
/// <p class=note>
/// When setting the video scaling mode, note that it must be reset after each time the output
/// buffers change. Since the \#INFO_OUTPUT_BUFFERS_CHANGED event is deprecated, you can
/// do this after each time the output format changes.
///
/// <h4>Using an Input Surface</h4>
///
/// When using an input Surface, there are no accessible input buffers, as buffers are automatically
/// passed from the input surface to the codec. Calling \#dequeueInputBuffer dequeueInputBuffer will throw an {@code IllegalStateException}, and \#getInputBuffers
/// returns a bogus {@code ByteBuffer[]} array that <strong>MUST NOT</strong> be written into.
///
/// Call \#signalEndOfInputStream to signal end-of-stream. The input surface will stop
/// submitting data to the codec immediately after this call.
///
///
/// <h3>Seeking &amp; Adaptive Playback Support</h3>
///
/// Video decoders (and in general codecs that consume compressed video data) behave differently
/// regarding seek and format change whether or not they support and are configured for adaptive
/// playback. You can check if a decoder supports {@linkplain CodecCapabilities\#FEATURE_AdaptivePlayback adaptive playback} via CodecCapabilities\#isFeatureSupported CodecCapabilities.isFeatureSupported(String). Adaptive
/// playback support for video decoders is only activated if you configure the codec to decode onto a
/// Surface.
///
/// <h4 id=KeyFrames><a name="KeyFrames"></a>Stream Boundary and Key Frames</h4>
///
/// It is important that the input data after \#start or \#flush starts at a suitable
/// stream boundary: the first frame must a key frame. A _key frame_ can be decoded
/// completely on its own (for most codecs this means an I-frame), and no frames that are to be
/// displayed after a key frame refer to frames before the key frame.
///
/// The following table summarizes suitable key frames for various video formats.
/// <table>
/// <thead>
///  <tr>
///   <th>Format</th>
///   <th>Suitable key frame</th>
///  </tr>
/// </thead>
/// <tbody class=mid>
///  <tr>
///   <td>VP9/VP8</td>
///   <td>a suitable intraframe where no subsequent frames refer to frames prior to this frame.<br>
///     <i>(There is no specific name for such key frame.)</i></td>
///  </tr>
///  <tr>
///   <td>H.265 HEVC</td>
///   <td>IDR or CRA</td>
///  </tr>
///  <tr>
///   <td>H.264 AVC</td>
///   <td>IDR</td>
///  </tr>
///  <tr>
///   <td>MPEG-4<br>H.263<br>MPEG-2</td>
///   <td>a suitable I-frame where no subsequent frames refer to frames prior to this frame.<br>
///     <i>(There is no specific name for such key frame.)</td>
///  </tr>
/// </tbody>
/// </table>
///
/// <h4>For decoders that do not support adaptive playback (including when not decoding onto a
/// Surface)</h4>
///
/// In order to start decoding data that is not adjacent to previously submitted data (i.e. after a
/// seek) you <strong>MUST</strong> flush the decoder. Since all output buffers are immediately
/// revoked at the point of the flush, you may want to first signal then wait for the end-of-stream
/// before you call {@code flush}. It is important that the input data after a flush starts at a
/// suitable stream boundary/key frame.
/// <p class=note>
/// <strong>Note:</strong> the format of the data submitted after a flush must not change; \#flush does not support format discontinuities; for that, a full \#stop - \#configure configure(&hellip;) - \#start cycle is necessary.
///
/// <p class=note>
/// <strong>Also note:</strong> if you flush the codec too soon after \#start &ndash;
/// generally, before the first output buffer or output format change is received &ndash; you
/// will need to resubmit the codec-specific-data to the codec. See the <a href="\#CSD">codec-specific-data section</a> for more info.
///
/// <h4>For decoders that support and are configured for adaptive playback</h4>
///
/// In order to start decoding data that is not adjacent to previously submitted data (i.e. after a
/// seek) it is _not necessary_ to flush the decoder; however, input data after the
/// discontinuity must start at a suitable stream boundary/key frame.
///
/// For some video formats - namely H.264, H.265, VP8 and VP9 - it is also possible to change the
/// picture size or configuration mid-stream. To do this you must package the entire new
/// codec-specific configuration data together with the key frame into a single buffer (including
/// any start codes), and submit it as a <strong>regular</strong> input buffer.
///
/// You will receive an \#INFO_OUTPUT_FORMAT_CHANGED return value from \#dequeueOutputBuffer dequeueOutputBuffer or a Callback\#onOutputBufferAvailable onOutputFormatChanged callback just after the picture-size change takes place and before any
/// frames with the new size have been returned.
/// <p class=note>
/// <strong>Note:</strong> just as the case for codec-specific data, be careful when calling
/// \#flush shortly after you have changed the picture size. If you have not received
/// confirmation of the picture size change, you will need to repeat the request for the new picture
/// size.
///
/// <h3>Error handling</h3>
///
/// The factory methods \#createByCodecName createByCodecName and \#createDecoderByType createDecoder/\#createEncoderByType EncoderByType throw {@code IOException} on failure
/// which you must catch or declare to pass up. MediaCodec methods throw {@code
/// IllegalStateException} when the method is called from a codec state that does not allow it; this
/// is typically due to incorrect application API usage. Methods involving secure buffers may throw
/// CryptoException, which has further error information obtainable from CryptoException\#getErrorCode.
///
/// Internal codec errors result in a CodecException, which may be due to media content
/// corruption, hardware failure, resource exhaustion, and so forth, even when the application is
/// correctly using the API. The recommended action when receiving a {@code CodecException}
/// can be determined by calling CodecException\#isRecoverable and CodecException\#isTransient:
/// <ul>
/// <li><strong>recoverable errors:</strong> If {@code isRecoverable()} returns true, then call
/// \#stop, \#configure configure(&hellip;), and \#start to recover.</li>
/// <li><strong>transient errors:</strong> If {@code isTransient()} returns true, then resources are
/// temporarily unavailable and the method may be retried at a later time.</li>
/// <li><strong>fatal errors:</strong> If both {@code isRecoverable()} and {@code isTransient()}
/// return false, then the {@code CodecException} is fatal and the codec must be {@linkplain \#reset reset} or {@linkplain \#release released}.</li>
/// </ul>
///
/// Both {@code isRecoverable()} and {@code isTransient()} do not return true at the same time.
///
/// <h2 id=History><a name="History"></a>Valid API Calls and API History</h2>
///
/// This sections summarizes the valid API calls in each state and the API history of the MediaCodec
/// class. For API version numbers, see android.os.Build.VERSION_CODES.
///
/// <style>
/// .api > tr > th, .api > tr > td { text-align: center; padding: 4px 4px; }
/// .api > tr > th     { vertical-align: bottom; }
/// .api > tr > td     { vertical-align: middle; }
/// .sml > tr > th, .sml > tr > td { text-align: center; padding: 2px 4px; }
/// .fn { text-align: left; }
/// .fn > code > a { font: 14px/19px Roboto Condensed, sans-serif; }
/// .deg45 {
///  white-space: nowrap; background: none; border: none; vertical-align: bottom;
///  width: 30px; height: 83px;
/// }
/// .deg45 > div {
///  transform: skew(-45deg, 0deg) translate(1px, -67px);
///  transform-origin: bottom left 0;
///  width: 30px; height: 20px;
/// }
/// .deg45 > div > div { border: 1px solid \#ddd; background: \#999; height: 90px; width: 42px; }
/// .deg45 > div > div > div { transform: skew(45deg, 0deg) translate(-55px, 55px) rotate(-45deg); }
/// </style>
///
/// <table align="right"style="width: 0%">
/// <thead>
///  <tr><th>Symbol</th><th>Meaning</th></tr>
/// </thead>
/// <tbody class=sml>
///  <tr><td>&\#9679;</td><td>Supported</td></tr>
///  <tr><td>&\#8277;</td><td>Semantics changed</td></tr>
///  <tr><td>&\#9675;</td><td>Experimental support</td></tr>
///  <tr><td>[ ]</td><td>Deprecated</td></tr>
///  <tr><td>&\#9099;</td><td>Restricted to surface input mode</td></tr>
///  <tr><td>&\#9094;</td><td>Restricted to surface output mode</td></tr>
///  <tr><td>&\#9639;</td><td>Restricted to ByteBuffer input mode</td></tr>
///  <tr><td>&\#8617;</td><td>Restricted to synchronous mode</td></tr>
///  <tr><td>&\#8644;</td><td>Restricted to asynchronous mode</td></tr>
///  <tr><td>( )</td><td>Can be called, but shouldn't</td></tr>
/// </tbody>
/// </table>
///
/// <table style="width: 100%;">
/// <thead class=api>
///  <tr>
///   <th class=deg45><div><div style="background:\#4285f4"><div>Uninitialized</div></div></div></th>
///   <th class=deg45><div><div style="background:\#f4b400"><div>Configured</div></div></div></th>
///   <th class=deg45><div><div style="background:\#e67c73"><div>Flushed</div></div></div></th>
///   <th class=deg45><div><div style="background:\#0f9d58"><div>Running</div></div></div></th>
///   <th class=deg45><div><div style="background:\#f7cb4d"><div>End of Stream</div></div></div></th>
///   <th class=deg45><div><div style="background:\#db4437"><div>Error</div></div></div></th>
///   <th class=deg45><div><div style="background:\#666"><div>Released</div></div></div></th>
///   <th></th>
///   <th colspan="8">SDK Version</th>
///  </tr>
///  <tr>
///   <th colspan="7">State</th>
///   <th>Method</th>
///   <th>16</th>
///   <th>17</th>
///   <th>18</th>
///   <th>19</th>
///   <th>20</th>
///   <th>21</th>
///   <th>22</th>
///   <th>23</th>
///  </tr>
/// </thead>
/// <tbody class=api>
///  <tr>
///   <td></td>
///   <td></td>
///   <td></td>
///   <td></td>
///   <td></td>
///   <td></td>
///   <td></td>
///   <td class=fn>\#createByCodecName createByCodecName</td>
///   <td>&\#9679;</td>
///   <td>&\#9679;</td>
///   <td>&\#9679;</td>
///   <td>&\#9679;</td>
///   <td>&\#9679;</td>
///   <td>&\#9679;</td>
///   <td>&\#9679;</td>
///   <td>&\#9679;</td>
///  </tr>
///  <tr>
///   <td></td>
///   <td></td>
///   <td></td>
///   <td></td>
///   <td></td>
///   <td></td>
///   <td></td>
///   <td class=fn>\#createDecoderByType createDecoderByType</td>
///   <td>&\#9679;</td>
///   <td>&\#9679;</td>
///   <td>&\#9679;</td>
///   <td>&\#9679;</td>
///   <td>&\#9679;</td>
///   <td>&\#9679;</td>
///   <td>&\#9679;</td>
///   <td>&\#9679;</td>
///  </tr>
///  <tr>
///   <td></td>
///   <td></td>
///   <td></td>
///   <td></td>
///   <td></td>
///   <td></td>
///   <td></td>
///   <td class=fn>\#createEncoderByType createEncoderByType</td>
///   <td>&\#9679;</td>
///   <td>&\#9679;</td>
///   <td>&\#9679;</td>
///   <td>&\#9679;</td>
///   <td>&\#9679;</td>
///   <td>&\#9679;</td>
///   <td>&\#9679;</td>
///   <td>&\#9679;</td>
///  </tr>
///  <tr>
///   <td></td>
///   <td></td>
///   <td></td>
///   <td></td>
///   <td></td>
///   <td></td>
///   <td></td>
///   <td class=fn>\#createPersistentInputSurface createPersistentInputSurface</td>
///   <td></td>
///   <td></td>
///   <td></td>
///   <td></td>
///   <td></td>
///   <td></td>
///   <td></td>
///   <td>&\#9679;</td>
///  </tr>
///  <tr>
///   <td>16+</td>
///   <td>-</td>
///   <td>-</td>
///   <td>-</td>
///   <td>-</td>
///   <td>-</td>
///   <td>-</td>
///   <td class=fn>\#configure configure</td>
///   <td>&\#9679;</td>
///   <td>&\#9679;</td>
///   <td>&\#9679;</td>
///   <td>&\#9679;</td>
///   <td>&\#9679;</td>
///   <td>&\#8277;</td>
///   <td>&\#9679;</td>
///   <td>&\#9679;</td>
///  </tr>
///  <tr>
///   <td>-</td>
///   <td>18+</td>
///   <td>-</td>
///   <td>-</td>
///   <td>-</td>
///   <td>-</td>
///   <td>-</td>
///   <td class=fn>\#createInputSurface createInputSurface</td>
///   <td></td>
///   <td></td>
///   <td>&\#9099;</td>
///   <td>&\#9099;</td>
///   <td>&\#9099;</td>
///   <td>&\#9099;</td>
///   <td>&\#9099;</td>
///   <td>&\#9099;</td>
///  </tr>
///  <tr>
///   <td>-</td>
///   <td>-</td>
///   <td>16+</td>
///   <td>16+</td>
///   <td>(16+)</td>
///   <td>-</td>
///   <td>-</td>
///   <td class=fn>\#dequeueInputBuffer dequeueInputBuffer</td>
///   <td>&\#9679;</td>
///   <td>&\#9679;</td>
///   <td>&\#9639;</td>
///   <td>&\#9639;</td>
///   <td>&\#9639;</td>
///   <td>&\#8277;&\#9639;&\#8617;</td>
///   <td>&\#9639;&\#8617;</td>
///   <td>&\#9639;&\#8617;</td>
///  </tr>
///  <tr>
///   <td>-</td>
///   <td>-</td>
///   <td>16+</td>
///   <td>16+</td>
///   <td>16+</td>
///   <td>-</td>
///   <td>-</td>
///   <td class=fn>\#dequeueOutputBuffer dequeueOutputBuffer</td>
///   <td>&\#9679;</td>
///   <td>&\#9679;</td>
///   <td>&\#9679;</td>
///   <td>&\#9679;</td>
///   <td>&\#9679;</td>
///   <td>&\#8277;&\#8617;</td>
///   <td>&\#8617;</td>
///   <td>&\#8617;</td>
///  </tr>
///  <tr>
///   <td>-</td>
///   <td>-</td>
///   <td>16+</td>
///   <td>16+</td>
///   <td>16+</td>
///   <td>-</td>
///   <td>-</td>
///   <td class=fn>\#flush flush</td>
///   <td>&\#9679;</td>
///   <td>&\#9679;</td>
///   <td>&\#9679;</td>
///   <td>&\#9679;</td>
///   <td>&\#9679;</td>
///   <td>&\#9679;</td>
///   <td>&\#9679;</td>
///   <td>&\#9679;</td>
///  </tr>
///  <tr>
///   <td>18+</td>
///   <td>18+</td>
///   <td>18+</td>
///   <td>18+</td>
///   <td>18+</td>
///   <td>18+</td>
///   <td>-</td>
///   <td class=fn>\#getCodecInfo getCodecInfo</td>
///   <td></td>
///   <td></td>
///   <td>&\#9679;</td>
///   <td>&\#9679;</td>
///   <td>&\#9679;</td>
///   <td>&\#9679;</td>
///   <td>&\#9679;</td>
///   <td>&\#9679;</td>
///  </tr>
///  <tr>
///   <td>-</td>
///   <td>-</td>
///   <td>(21+)</td>
///   <td>21+</td>
///   <td>(21+)</td>
///   <td>-</td>
///   <td>-</td>
///   <td class=fn>\#getInputBuffer getInputBuffer</td>
///   <td></td>
///   <td></td>
///   <td></td>
///   <td></td>
///   <td></td>
///   <td>&\#9679;</td>
///   <td>&\#9679;</td>
///   <td>&\#9679;</td>
///  </tr>
///  <tr>
///   <td>-</td>
///   <td>-</td>
///   <td>16+</td>
///   <td>(16+)</td>
///   <td>(16+)</td>
///   <td>-</td>
///   <td>-</td>
///   <td class=fn>\#getInputBuffers getInputBuffers</td>
///   <td>&\#9679;</td>
///   <td>&\#9679;</td>
///   <td>&\#9679;</td>
///   <td>&\#9679;</td>
///   <td>&\#9679;</td>
///   <td>[&\#8277;&\#8617;]</td>
///   <td>[&\#8617;]</td>
///   <td>[&\#8617;]</td>
///  </tr>
///  <tr>
///   <td>-</td>
///   <td>21+</td>
///   <td>(21+)</td>
///   <td>(21+)</td>
///   <td>(21+)</td>
///   <td>-</td>
///   <td>-</td>
///   <td class=fn>\#getInputFormat getInputFormat</td>
///   <td></td>
///   <td></td>
///   <td></td>
///   <td></td>
///   <td></td>
///   <td>&\#9679;</td>
///   <td>&\#9679;</td>
///   <td>&\#9679;</td>
///  </tr>
///  <tr>
///   <td>-</td>
///   <td>-</td>
///   <td>(21+)</td>
///   <td>21+</td>
///   <td>(21+)</td>
///   <td>-</td>
///   <td>-</td>
///   <td class=fn>\#getInputImage getInputImage</td>
///   <td></td>
///   <td></td>
///   <td></td>
///   <td></td>
///   <td></td>
///   <td>&\#9675;</td>
///   <td>&\#9679;</td>
///   <td>&\#9679;</td>
///  </tr>
///  <tr>
///   <td>18+</td>
///   <td>18+</td>
///   <td>18+</td>
///   <td>18+</td>
///   <td>18+</td>
///   <td>18+</td>
///   <td>-</td>
///   <td class=fn>\#getName getName</td>
///   <td></td>
///   <td></td>
///   <td>&\#9679;</td>
///   <td>&\#9679;</td>
///   <td>&\#9679;</td>
///   <td>&\#9679;</td>
///   <td>&\#9679;</td>
///   <td>&\#9679;</td>
///  </tr>
///  <tr>
///   <td>-</td>
///   <td>-</td>
///   <td>(21+)</td>
///   <td>21+</td>
///   <td>21+</td>
///   <td>-</td>
///   <td>-</td>
///   <td class=fn>\#getOutputBuffer getOutputBuffer</td>
///   <td></td>
///   <td></td>
///   <td></td>
///   <td></td>
///   <td></td>
///   <td>&\#9679;</td>
///   <td>&\#9679;</td>
///   <td>&\#9679;</td>
///  </tr>
///  <tr>
///   <td>-</td>
///   <td>-</td>
///   <td>16+</td>
///   <td>16+</td>
///   <td>16+</td>
///   <td>-</td>
///   <td>-</td>
///   <td class=fn>\#getOutputBuffers getOutputBuffers</td>
///   <td>&\#9679;</td>
///   <td>&\#9679;</td>
///   <td>&\#9679;</td>
///   <td>&\#9679;</td>
///   <td>&\#9679;</td>
///   <td>[&\#8277;&\#8617;]</td>
///   <td>[&\#8617;]</td>
///   <td>[&\#8617;]</td>
///  </tr>
///  <tr>
///   <td>-</td>
///   <td>21+</td>
///   <td>16+</td>
///   <td>16+</td>
///   <td>16+</td>
///   <td>-</td>
///   <td>-</td>
///   <td class=fn>\#getOutputFormat()</td>
///   <td>&\#9679;</td>
///   <td>&\#9679;</td>
///   <td>&\#9679;</td>
///   <td>&\#9679;</td>
///   <td>&\#9679;</td>
///   <td>&\#9679;</td>
///   <td>&\#9679;</td>
///   <td>&\#9679;</td>
///  </tr>
///  <tr>
///   <td>-</td>
///   <td>-</td>
///   <td>(21+)</td>
///   <td>21+</td>
///   <td>21+</td>
///   <td>-</td>
///   <td>-</td>
///   <td class=fn>\#getOutputFormat(int)</td>
///   <td></td>
///   <td></td>
///   <td></td>
///   <td></td>
///   <td></td>
///   <td>&\#9679;</td>
///   <td>&\#9679;</td>
///   <td>&\#9679;</td>
///  </tr>
///  <tr>
///   <td>-</td>
///   <td>-</td>
///   <td>(21+)</td>
///   <td>21+</td>
///   <td>21+</td>
///   <td>-</td>
///   <td>-</td>
///   <td class=fn>\#getOutputImage getOutputImage</td>
///   <td></td>
///   <td></td>
///   <td></td>
///   <td></td>
///   <td></td>
///   <td>&\#9675;</td>
///   <td>&\#9679;</td>
///   <td>&\#9679;</td>
///  </tr>
///  <tr>
///   <td>-</td>
///   <td>-</td>
///   <td>-</td>
///   <td>16+</td>
///   <td>(16+)</td>
///   <td>-</td>
///   <td>-</td>
///   <td class=fn>\#queueInputBuffer queueInputBuffer</td>
///   <td>&\#9679;</td>
///   <td>&\#9679;</td>
///   <td>&\#9679;</td>
///   <td>&\#9679;</td>
///   <td>&\#9679;</td>
///   <td>&\#8277;</td>
///   <td>&\#9679;</td>
///   <td>&\#9679;</td>
///  </tr>
///  <tr>
///   <td>-</td>
///   <td>-</td>
///   <td>-</td>
///   <td>16+</td>
///   <td>(16+)</td>
///   <td>-</td>
///   <td>-</td>
///   <td class=fn>\#queueSecureInputBuffer queueSecureInputBuffer</td>
///   <td>&\#9679;</td>
///   <td>&\#9679;</td>
///   <td>&\#9679;</td>
///   <td>&\#9679;</td>
///   <td>&\#9679;</td>
///   <td>&\#8277;</td>
///   <td>&\#9679;</td>
///   <td>&\#9679;</td>
///  </tr>
///  <tr>
///   <td>16+</td>
///   <td>16+</td>
///   <td>16+</td>
///   <td>16+</td>
///   <td>16+</td>
///   <td>16+</td>
///   <td>16+</td>
///   <td class=fn>\#release release</td>
///   <td>&\#9679;</td>
///   <td>&\#9679;</td>
///   <td>&\#9679;</td>
///   <td>&\#9679;</td>
///   <td>&\#9679;</td>
///   <td>&\#9679;</td>
///   <td>&\#9679;</td>
///   <td>&\#9679;</td>
///  </tr>
///  <tr>
///   <td>-</td>
///   <td>-</td>
///   <td>-</td>
///   <td>16+</td>
///   <td>16+</td>
///   <td>-</td>
///   <td>-</td>
///   <td class=fn>\#releaseOutputBuffer(int, boolean)</td>
///   <td>&\#9679;</td>
///   <td>&\#9679;</td>
///   <td>&\#9679;</td>
///   <td>&\#9679;</td>
///   <td>&\#9679;</td>
///   <td>&\#8277;</td>
///   <td>&\#9679;</td>
///   <td>&\#8277;</td>
///  </tr>
///  <tr>
///   <td>-</td>
///   <td>-</td>
///   <td>-</td>
///   <td>21+</td>
///   <td>21+</td>
///   <td>-</td>
///   <td>-</td>
///   <td class=fn>\#releaseOutputBuffer(int, long)</td>
///   <td></td>
///   <td></td>
///   <td></td>
///   <td></td>
///   <td></td>
///   <td>&\#9094;</td>
///   <td>&\#9094;</td>
///   <td>&\#9094;</td>
///  </tr>
///  <tr>
///   <td>21+</td>
///   <td>21+</td>
///   <td>21+</td>
///   <td>21+</td>
///   <td>21+</td>
///   <td>21+</td>
///   <td>-</td>
///   <td class=fn>\#reset reset</td>
///   <td></td>
///   <td></td>
///   <td></td>
///   <td></td>
///   <td></td>
///   <td>&\#9679;</td>
///   <td>&\#9679;</td>
///   <td>&\#9679;</td>
///  </tr>
///  <tr>
///   <td>21+</td>
///   <td>-</td>
///   <td>-</td>
///   <td>-</td>
///   <td>-</td>
///   <td>-</td>
///   <td>-</td>
///   <td class=fn>\#setCallback(Callback) setCallback</td>
///   <td></td>
///   <td></td>
///   <td></td>
///   <td></td>
///   <td></td>
///   <td>&\#9679;</td>
///   <td>&\#9679;</td>
///   <td>\#setCallback(Callback, Handler) &\#8277;</td>
///  </tr>
///  <tr>
///   <td>-</td>
///   <td>23+</td>
///   <td>-</td>
///   <td>-</td>
///   <td>-</td>
///   <td>-</td>
///   <td>-</td>
///   <td class=fn>\#setInputSurface setInputSurface</td>
///   <td></td>
///   <td></td>
///   <td></td>
///   <td></td>
///   <td></td>
///   <td></td>
///   <td></td>
///   <td>&\#9099;</td>
///  </tr>
///  <tr>
///   <td>23+</td>
///   <td>23+</td>
///   <td>23+</td>
///   <td>23+</td>
///   <td>23+</td>
///   <td>(23+)</td>
///   <td>(23+)</td>
///   <td class=fn>\#setOnFrameRenderedListener setOnFrameRenderedListener</td>
///   <td></td>
///   <td></td>
///   <td></td>
///   <td></td>
///   <td></td>
///   <td></td>
///   <td></td>
///   <td>&\#9675; &\#9094;</td>
///  </tr>
///  <tr>
///   <td>-</td>
///   <td>23+</td>
///   <td>23+</td>
///   <td>23+</td>
///   <td>23+</td>
///   <td>-</td>
///   <td>-</td>
///   <td class=fn>\#setOutputSurface setOutputSurface</td>
///   <td></td>
///   <td></td>
///   <td></td>
///   <td></td>
///   <td></td>
///   <td></td>
///   <td></td>
///   <td>&\#9094;</td>
///  </tr>
///  <tr>
///   <td>19+</td>
///   <td>19+</td>
///   <td>19+</td>
///   <td>19+</td>
///   <td>19+</td>
///   <td>(19+)</td>
///   <td>-</td>
///   <td class=fn>\#setParameters setParameters</td>
///   <td></td>
///   <td></td>
///   <td></td>
///   <td>&\#9679;</td>
///   <td>&\#9679;</td>
///   <td>&\#9679;</td>
///   <td>&\#9679;</td>
///   <td>&\#9679;</td>
///  </tr>
///  <tr>
///   <td>-</td>
///   <td>(16+)</td>
///   <td>(16+)</td>
///   <td>16+</td>
///   <td>(16+)</td>
///   <td>(16+)</td>
///   <td>-</td>
///   <td class=fn>\#setVideoScalingMode setVideoScalingMode</td>
///   <td>&\#9094;</td>
///   <td>&\#9094;</td>
///   <td>&\#9094;</td>
///   <td>&\#9094;</td>
///   <td>&\#9094;</td>
///   <td>&\#9094;</td>
///   <td>&\#9094;</td>
///   <td>&\#9094;</td>
///  </tr>
///  <tr>
///   <td>-</td>
///   <td>-</td>
///   <td>18+</td>
///   <td>18+</td>
///   <td>-</td>
///   <td>-</td>
///   <td>-</td>
///   <td class=fn>\#signalEndOfInputStream signalEndOfInputStream</td>
///   <td></td>
///   <td></td>
///   <td>&\#9099;</td>
///   <td>&\#9099;</td>
///   <td>&\#9099;</td>
///   <td>&\#9099;</td>
///   <td>&\#9099;</td>
///   <td>&\#9099;</td>
///  </tr>
///  <tr>
///   <td>-</td>
///   <td>16+</td>
///   <td>21+(&\#8644;)</td>
///   <td>-</td>
///   <td>-</td>
///   <td>-</td>
///   <td>-</td>
///   <td class=fn>\#start start</td>
///   <td>&\#9679;</td>
///   <td>&\#9679;</td>
///   <td>&\#9679;</td>
///   <td>&\#9679;</td>
///   <td>&\#9679;</td>
///   <td>&\#8277;</td>
///   <td>&\#9679;</td>
///   <td>&\#9679;</td>
///  </tr>
///  <tr>
///   <td>-</td>
///   <td>-</td>
///   <td>16+</td>
///   <td>16+</td>
///   <td>16+</td>
///   <td>-</td>
///   <td>-</td>
///   <td class=fn>\#stop stop</td>
///   <td>&\#9679;</td>
///   <td>&\#9679;</td>
///   <td>&\#9679;</td>
///   <td>&\#9679;</td>
///   <td>&\#9679;</td>
///   <td>&\#9679;</td>
///   <td>&\#9679;</td>
///   <td>&\#9679;</td>
///  </tr>
/// </tbody>
/// </table>
class MediaCodec extends jni.JniObject {
  static final _classRef = jniAccessors.getClassOf("android/media/MediaCodec");
  MediaCodec.fromRef(jni.JObject ref) : super.fromRef(ref);

  /// from: static public final int BUFFER_FLAG_CODEC_CONFIG
  ///
  /// This indicated that the buffer marked as such contains codec
  /// initialization / codec specific data instead of media data.
  static const BUFFER_FLAG_CODEC_CONFIG = 2;

  /// from: static public final int BUFFER_FLAG_END_OF_STREAM
  ///
  /// This signals the end of stream, i.e. no buffers will be available
  /// after this, unless of course, \#flush follows.
  static const BUFFER_FLAG_END_OF_STREAM = 4;

  /// from: static public final int BUFFER_FLAG_KEY_FRAME
  ///
  /// This indicates that the (encoded) buffer marked as such contains
  /// the data for a key frame.
  static const BUFFER_FLAG_KEY_FRAME = 1;

  /// from: static public final int BUFFER_FLAG_PARTIAL_FRAME
  ///
  /// This indicates that the buffer only contains part of a frame,
  /// and the decoder should batch the data until a buffer without
  /// this flag appears before decoding the frame.
  static const BUFFER_FLAG_PARTIAL_FRAME = 8;

  /// from: static public final int BUFFER_FLAG_SYNC_FRAME
  ///
  /// This indicates that the (encoded) buffer marked as such contains
  /// the data for a key frame.
  ///@deprecated Use \#BUFFER_FLAG_KEY_FRAME instead.
  static const BUFFER_FLAG_SYNC_FRAME = 1;

  /// from: static public final int CONFIGURE_FLAG_ENCODE
  ///
  /// If this codec is to be used as an encoder, pass this flag.
  static const CONFIGURE_FLAG_ENCODE = 1;

  /// from: static public final int CRYPTO_MODE_AES_CBC
  static const CRYPTO_MODE_AES_CBC = 2;

  /// from: static public final int CRYPTO_MODE_AES_CTR
  static const CRYPTO_MODE_AES_CTR = 1;

  /// from: static public final int CRYPTO_MODE_UNENCRYPTED
  static const CRYPTO_MODE_UNENCRYPTED = 0;

  /// from: static public final int INFO_OUTPUT_BUFFERS_CHANGED
  ///
  /// The output buffers have changed, the client must refer to the new
  /// set of output buffers returned by \#getOutputBuffers from
  /// this point on.
  ///
  /// Additionally, this event signals that the video scaling mode
  /// may have been reset to the default.
  ///
  ///@deprecated This return value can be ignored as \#getOutputBuffers has been deprecated.  Client should
  /// request a current buffer using on of the get-buffer or
  /// get-image methods each time one has been dequeued.
  static const INFO_OUTPUT_BUFFERS_CHANGED = -3;

  /// from: static public final int INFO_OUTPUT_FORMAT_CHANGED
  ///
  /// The output format has changed, subsequent data will follow the new
  /// format. \#getOutputFormat() returns the new format.  Note, that
  /// you can also use the new \#getOutputFormat(int) method to
  /// get the format for a specific output buffer.  This frees you from
  /// having to track output format changes.
  static const INFO_OUTPUT_FORMAT_CHANGED = -2;

  /// from: static public final int INFO_TRY_AGAIN_LATER
  ///
  /// If a non-negative timeout had been specified in the call
  /// to \#dequeueOutputBuffer, indicates that the call timed out.
  static const INFO_TRY_AGAIN_LATER = -1;

  /// from: static public final java.lang.String PARAMETER_KEY_REQUEST_SYNC_FRAME
  ///
  /// Request that the encoder produce a sync frame "soon".
  /// Provide an Integer with the value 0.
  static const PARAMETER_KEY_REQUEST_SYNC_FRAME = "request-sync";

  /// from: static public final java.lang.String PARAMETER_KEY_SUSPEND
  ///
  /// Temporarily suspend/resume encoding of input data. While suspended
  /// input data is effectively discarded instead of being fed into the
  /// encoder. This parameter really only makes sense to use with an encoder
  /// in "surface-input" mode, as the client code has no control over the
  /// input-side of the encoder in that case.
  /// The value is an Integer object containing the value 1 to suspend
  /// or the value 0 to resume.
  static const PARAMETER_KEY_SUSPEND = "drop-input-frames";

  /// from: static public final java.lang.String PARAMETER_KEY_VIDEO_BITRATE
  ///
  /// Change a video encoder's target bitrate on the fly. The value is an
  /// Integer object containing the new bitrate in bps.
  static const PARAMETER_KEY_VIDEO_BITRATE = "video-bitrate";

  /// from: static public final int VIDEO_SCALING_MODE_SCALE_TO_FIT
  ///
  /// The content is scaled to the surface dimensions
  static const VIDEO_SCALING_MODE_SCALE_TO_FIT = 1;

  /// from: static public final int VIDEO_SCALING_MODE_SCALE_TO_FIT_WITH_CROPPING
  ///
  /// The content is scaled, maintaining its aspect ratio, the whole
  /// surface area is used, content may be cropped.
  /// <p class=note>
  /// This mode is only suitable for content with 1:1 pixel aspect ratio as you cannot
  /// configure the pixel aspect ratio for a Surface.
  /// <p class=note>
  /// As of android.os.Build.VERSION_CODES\#N release, this mode may not work if
  /// the video is {@linkplain MediaFormat\#KEY_ROTATION rotated} by 90 or 270 degrees.
  static const VIDEO_SCALING_MODE_SCALE_TO_FIT_WITH_CROPPING = 2;

  static final _id_createDecoderByType = jniAccessors.getStaticMethodIDOf(
      _classRef,
      "createDecoderByType",
      "(Ljava/lang/String;)Landroid/media/MediaCodec;");

  /// from: static public android.media.MediaCodec createDecoderByType(java.lang.String type)
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// Instantiate the preferred decoder supporting input data of the given mime type.
  ///
  /// The following is a partial list of defined mime types and their semantics:
  /// <ul>
  /// <li>"video/x-vnd.on2.vp8" - VP8 video (i.e. video in .webm)
  /// <li>"video/x-vnd.on2.vp9" - VP9 video (i.e. video in .webm)
  /// <li>"video/avc" - H.264/AVC video
  /// <li>"video/hevc" - H.265/HEVC video
  /// <li>"video/mp4v-es" - MPEG4 video
  /// <li>"video/3gpp" - H.263 video
  /// <li>"audio/3gpp" - AMR narrowband audio
  /// <li>"audio/amr-wb" - AMR wideband audio
  /// <li>"audio/mpeg" - MPEG1/2 audio layer III
  /// <li>"audio/mp4a-latm" - AAC audio (note, this is raw AAC packets, not packaged in LATM!)
  /// <li>"audio/vorbis" - vorbis audio
  /// <li>"audio/g711-alaw" - G.711 alaw audio
  /// <li>"audio/g711-mlaw" - G.711 ulaw audio
  /// </ul>
  ///
  /// <strong>Note:</strong> It is preferred to use MediaCodecList\#findDecoderForFormat
  /// and \#createByCodecName to ensure that the resulting codec can handle a
  /// given format.
  ///@param type The mime type of the input data.
  /// This value must never be {@code null}.
  ///@throws IOException if the codec cannot be created.
  ///@throws IllegalArgumentException if type is not a valid mime type.
  ///@throws NullPointerException if type is null.
  static MediaCodec createDecoderByType(jni.JniString type) =>
      MediaCodec.fromRef(jniAccessors.callStaticMethodWithArgs(
          _classRef,
          _id_createDecoderByType,
          jni.JniType.objectType,
          [type.reference]).object);

  static final _id_createEncoderByType = jniAccessors.getStaticMethodIDOf(
      _classRef,
      "createEncoderByType",
      "(Ljava/lang/String;)Landroid/media/MediaCodec;");

  /// from: static public android.media.MediaCodec createEncoderByType(java.lang.String type)
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// Instantiate the preferred encoder supporting output data of the given mime type.
  ///
  /// <strong>Note:</strong> It is preferred to use MediaCodecList\#findEncoderForFormat
  /// and \#createByCodecName to ensure that the resulting codec can handle a
  /// given format.
  ///@param type The desired mime type of the output data.
  /// This value must never be {@code null}.
  ///@throws IOException if the codec cannot be created.
  ///@throws IllegalArgumentException if type is not a valid mime type.
  ///@throws NullPointerException if type is null.
  static MediaCodec createEncoderByType(jni.JniString type) =>
      MediaCodec.fromRef(jniAccessors.callStaticMethodWithArgs(
          _classRef,
          _id_createEncoderByType,
          jni.JniType.objectType,
          [type.reference]).object);

  static final _id_createByCodecName = jniAccessors.getStaticMethodIDOf(
      _classRef,
      "createByCodecName",
      "(Ljava/lang/String;)Landroid/media/MediaCodec;");

  /// from: static public android.media.MediaCodec createByCodecName(java.lang.String name)
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// If you know the exact name of the component you want to instantiate
  /// use this method to instantiate it. Use with caution.
  /// Likely to be used with information obtained from android.media.MediaCodecList
  ///@param name The name of the codec to be instantiated.
  /// This value must never be {@code null}.
  ///@throws IOException if the codec cannot be created.
  ///@throws IllegalArgumentException if name is not valid.
  ///@throws NullPointerException if name is null.
  static MediaCodec createByCodecName(jni.JniString name) =>
      MediaCodec.fromRef(jniAccessors.callStaticMethodWithArgs(
          _classRef,
          _id_createByCodecName,
          jni.JniType.objectType,
          [name.reference]).object);

  static final _id_finalize =
      jniAccessors.getMethodIDOf(_classRef, "finalize", "()V");

  /// from: protected void finalize()
  void finalize() => jniAccessors.callMethodWithArgs(
      reference, _id_finalize, jni.JniType.voidType, []).check();

  static final _id_reset =
      jniAccessors.getMethodIDOf(_classRef, "reset", "()V");

  /// from: public void reset()
  ///
  /// Returns the codec to its initial (Uninitialized) state.
  ///
  /// Call this if an MediaCodec.CodecException\#isRecoverable unrecoverable
  /// error has occured to reset the codec to its initial state after creation.
  ///@throws CodecException if an unrecoverable error has occured and the codec
  /// could not be reset.
  ///@throws IllegalStateException if in the Released state.
  void reset() => jniAccessors.callMethodWithArgs(
      reference, _id_reset, jni.JniType.voidType, []).check();

  static final _id_release =
      jniAccessors.getMethodIDOf(_classRef, "release", "()V");

  /// from: public void release()
  ///
  /// Free up resources used by the codec instance.
  ///
  /// Make sure you call this when you're done to free up any opened
  /// component instance instead of relying on the garbage collector
  /// to do this for you at some point in the future.
  void release() => jniAccessors.callMethodWithArgs(
      reference, _id_release, jni.JniType.voidType, []).check();

  static final _id_configure = jniAccessors.getMethodIDOf(
      _classRef,
      "configure",
      "(Landroid/media/MediaFormat;Landroid/view/Surface;Landroid/media/MediaCrypto;I)V");

  /// from: public void configure(android.media.MediaFormat format, android.view.Surface surface, android.media.MediaCrypto crypto, int flags)
  ///
  /// Configures a component.
  ///@param format The format of the input data (decoder) or the desired
  ///               format of the output data (encoder). Passing {@code null}
  ///               as {@code format} is equivalent to passing an
  ///               MediaFormat\#MediaFormat an empty mediaformat.
  /// This value may be {@code null}.
  ///@param surface Specify a surface on which to render the output of this
  ///                decoder. Pass {@code null} as {@code surface} if the
  ///                codec does not generate raw video output (e.g. not a video
  ///                decoder) and/or if you want to configure the codec for
  ///                ByteBuffer output.
  /// This value may be {@code null}.
  ///@param crypto Specify a crypto object to facilitate secure decryption
  ///                of the media data. Pass {@code null} as {@code crypto} for
  ///                non-secure codecs.
  /// This value may be {@code null}.
  ///@param flags Specify \#CONFIGURE_FLAG_ENCODE to configure the
  ///                component as an encoder.
  /// Value is either <code>0</code> or android.media.MediaCodec\#CONFIGURE_FLAG_ENCODE
  ///@throws IllegalArgumentException if the surface has been released (or is invalid),
  /// or the format is unacceptable (e.g. missing a mandatory key),
  /// or the flags are not set properly
  /// (e.g. missing \#CONFIGURE_FLAG_ENCODE for an encoder).
  ///@throws IllegalStateException if not in the Uninitialized state.
  ///@throws CryptoException upon DRM error.
  ///@throws CodecException upon codec error.
  void configure(mediaformat_.MediaFormat format, surface_.Surface surface,
          mediacrypto_.MediaCrypto crypto, int flags) =>
      jniAccessors.callMethodWithArgs(
          reference, _id_configure, jni.JniType.voidType, [
        format.reference,
        surface.reference,
        crypto.reference,
        flags
      ]).check();

  static final _id_configure1 = jniAccessors.getMethodIDOf(
      _classRef,
      "configure",
      "(Landroid/media/MediaFormat;Landroid/view/Surface;ILandroid/media/MediaDescrambler;)V");

  /// from: public void configure(android.media.MediaFormat format, android.view.Surface surface, int flags, android.media.MediaDescrambler descrambler)
  ///
  /// Configure a component to be used with a descrambler.
  ///@param format The format of the input data (decoder) or the desired
  ///               format of the output data (encoder). Passing {@code null}
  ///               as {@code format} is equivalent to passing an
  ///               MediaFormat\#MediaFormat an empty mediaformat.
  /// This value may be {@code null}.
  ///@param surface Specify a surface on which to render the output of this
  ///                decoder. Pass {@code null} as {@code surface} if the
  ///                codec does not generate raw video output (e.g. not a video
  ///                decoder) and/or if you want to configure the codec for
  ///                ByteBuffer output.
  /// This value may be {@code null}.
  ///@param flags Specify \#CONFIGURE_FLAG_ENCODE to configure the
  ///                component as an encoder.
  /// Value is either <code>0</code> or android.media.MediaCodec\#CONFIGURE_FLAG_ENCODE
  ///@param descrambler Specify a descrambler object to facilitate secure
  ///                descrambling of the media data, or null for non-secure codecs.
  /// This value may be {@code null}.
  ///@throws IllegalArgumentException if the surface has been released (or is invalid),
  /// or the format is unacceptable (e.g. missing a mandatory key),
  /// or the flags are not set properly
  /// (e.g. missing \#CONFIGURE_FLAG_ENCODE for an encoder).
  ///@throws IllegalStateException if not in the Uninitialized state.
  ///@throws CryptoException upon DRM error.
  ///@throws CodecException upon codec error.
  void configure1(mediaformat_.MediaFormat format, surface_.Surface surface,
          int flags, mediadescrambler_.MediaDescrambler descrambler) =>
      jniAccessors.callMethodWithArgs(
          reference, _id_configure1, jni.JniType.voidType, [
        format.reference,
        surface.reference,
        flags,
        descrambler.reference
      ]).check();

  static final _id_setOutputSurface = jniAccessors.getMethodIDOf(
      _classRef, "setOutputSurface", "(Landroid/view/Surface;)V");

  /// from: public void setOutputSurface(android.view.Surface surface)
  ///
  /// Dynamically sets the output surface of a codec.
  ///
  ///  This can only be used if the codec was configured with an output surface.  The
  ///  new output surface should have a compatible usage type to the original output surface.
  ///  E.g. codecs may not support switching from a SurfaceTexture (GPU readable) output
  ///  to ImageReader (software readable) output.
  ///@param surface the output surface to use. It must not be {@code null}.
  ///
  /// This value must never be {@code null}.
  ///@throws IllegalStateException if the codec does not support setting the output
  ///            surface in the current state.
  ///@throws IllegalArgumentException if the new surface is not of a suitable type for the codec.
  void setOutputSurface(surface_.Surface surface) =>
      jniAccessors.callMethodWithArgs(reference, _id_setOutputSurface,
          jni.JniType.voidType, [surface.reference]).check();

  static final _id_createPersistentInputSurface =
      jniAccessors.getStaticMethodIDOf(_classRef,
          "createPersistentInputSurface", "()Landroid/view/Surface;");

  /// from: static public android.view.Surface createPersistentInputSurface()
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// Create a persistent input surface that can be used with codecs that normally have an input
  /// surface, such as video encoders. A persistent input can be reused by subsequent
  /// MediaCodec or MediaRecorder instances, but can only be used by at
  /// most one codec or recorder instance concurrently.
  ///
  /// The application is responsible for calling release() on the Surface when done.
  ///@return an input surface that can be used with \#setInputSurface.
  ///
  /// This value will never be {@code null}.
  static surface_.Surface createPersistentInputSurface() =>
      surface_.Surface.fromRef(jniAccessors.callStaticMethodWithArgs(_classRef,
          _id_createPersistentInputSurface, jni.JniType.objectType, []).object);

  static final _id_setInputSurface = jniAccessors.getMethodIDOf(
      _classRef, "setInputSurface", "(Landroid/view/Surface;)V");

  /// from: public void setInputSurface(android.view.Surface surface)
  ///
  /// Configures the codec (e.g.&nbsp;encoder) to use a persistent input surface in place of input
  /// buffers.  This may only be called after \#configure and before \#start, in
  /// lieu of \#createInputSurface.
  ///@param surface a persistent input surface created by \#createPersistentInputSurface
  /// This value must never be {@code null}.
  ///@throws IllegalStateException if not in the Configured state or does not require an input
  ///           surface.
  ///@throws IllegalArgumentException if the surface was not created by
  ///           \#createPersistentInputSurface.
  void setInputSurface(surface_.Surface surface) =>
      jniAccessors.callMethodWithArgs(reference, _id_setInputSurface,
          jni.JniType.voidType, [surface.reference]).check();

  static final _id_createInputSurface = jniAccessors.getMethodIDOf(
      _classRef, "createInputSurface", "()Landroid/view/Surface;");

  /// from: public native android.view.Surface createInputSurface()
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// Requests a Surface to use as the input to an encoder, in place of input buffers.  This
  /// may only be called after \#configure and before \#start.
  ///
  /// The application is responsible for calling release() on the Surface when
  /// done.
  ///
  /// The Surface must be rendered with a hardware-accelerated API, such as OpenGL ES.
  /// android.view.Surface\#lockCanvas(android.graphics.Rect) may fail or produce
  /// unexpected results.
  ///@throws IllegalStateException if not in the Configured state.
  ///@return This value will never be {@code null}.
  surface_.Surface createInputSurface() =>
      surface_.Surface.fromRef(jniAccessors.callMethodWithArgs(reference,
          _id_createInputSurface, jni.JniType.objectType, []).object);

  static final _id_start =
      jniAccessors.getMethodIDOf(_classRef, "start", "()V");

  /// from: public void start()
  ///
  /// After successfully configuring the component, call {@code start}.
  ///
  /// Call {@code start} also if the codec is configured in asynchronous mode,
  /// and it has just been flushed, to resume requesting input buffers.
  ///@throws IllegalStateException if not in the Configured state
  ///         or just after \#flush for a codec that is configured
  ///         in asynchronous mode.
  ///@throws MediaCodec.CodecException upon codec error. Note that some codec errors
  /// for start may be attributed to future method calls.
  void start() => jniAccessors.callMethodWithArgs(
      reference, _id_start, jni.JniType.voidType, []).check();

  static final _id_stop = jniAccessors.getMethodIDOf(_classRef, "stop", "()V");

  /// from: public void stop()
  ///
  /// Finish the decode/encode session, note that the codec instance
  /// remains active and ready to be \#started again.
  /// To ensure that it is available to other client call \#release
  /// and don't just rely on garbage collection to eventually do this for you.
  ///@throws IllegalStateException if in the Released state.
  void stop() => jniAccessors.callMethodWithArgs(
      reference, _id_stop, jni.JniType.voidType, []).check();

  static final _id_flush =
      jniAccessors.getMethodIDOf(_classRef, "flush", "()V");

  /// from: public void flush()
  ///
  /// Flush both input and output ports of the component.
  ///
  /// Upon return, all indices previously returned in calls to \#dequeueInputBuffer dequeueInputBuffer and \#dequeueOutputBuffer dequeueOutputBuffer &mdash; or obtained
  /// via Callback\#onInputBufferAvailable onInputBufferAvailable or
  /// Callback\#onOutputBufferAvailable onOutputBufferAvailable callbacks &mdash; become
  /// invalid, and all buffers are owned by the codec.
  ///
  /// If the codec is configured in asynchronous mode, call \#start
  /// after {@code flush} has returned to resume codec operations. The codec
  /// will not request input buffers until this has happened.
  /// <strong>Note, however, that there may still be outstanding {@code onOutputBufferAvailable}
  /// callbacks that were not handled prior to calling {@code flush}.
  /// The indices returned via these callbacks also become invalid upon calling {@code flush} and
  /// should be discarded.</strong>
  ///
  /// If the codec is configured in synchronous mode, codec will resume
  /// automatically if it is configured with an input surface.  Otherwise, it
  /// will resume when \#dequeueInputBuffer dequeueInputBuffer is called.
  ///@throws IllegalStateException if not in the Executing state.
  ///@throws MediaCodec.CodecException upon codec error.
  void flush() => jniAccessors.callMethodWithArgs(
      reference, _id_flush, jni.JniType.voidType, []).check();

  static final _id_queueInputBuffer =
      jniAccessors.getMethodIDOf(_classRef, "queueInputBuffer", "(IIIJI)V");

  /// from: public void queueInputBuffer(int index, int offset, int size, long presentationTimeUs, int flags)
  ///
  /// After filling a range of the input buffer at the specified index
  /// submit it to the component. Once an input buffer is queued to
  /// the codec, it MUST NOT be used until it is later retrieved by
  /// \#getInputBuffer in response to a \#dequeueInputBuffer
  /// return value or a Callback\#onInputBufferAvailable
  /// callback.
  ///
  /// Many decoders require the actual compressed data stream to be
  /// preceded by "codec specific data", i.e. setup data used to initialize
  /// the codec such as PPS/SPS in the case of AVC video or code tables
  /// in the case of vorbis audio.
  /// The class android.media.MediaExtractor provides codec
  /// specific data as part of
  /// the returned track format in entries named "csd-0", "csd-1" ...
  ///
  /// These buffers can be submitted directly after \#start or
  /// \#flush by specifying the flag \#BUFFER_FLAG_CODEC_CONFIG.  However, if you configure the
  /// codec with a MediaFormat containing these keys, they
  /// will be automatically submitted by MediaCodec directly after
  /// start.  Therefore, the use of \#BUFFER_FLAG_CODEC_CONFIG flag is discouraged and is
  /// recommended only for advanced users.
  ///
  /// To indicate that this is the final piece of input data (or rather that
  /// no more input data follows unless the decoder is subsequently flushed)
  /// specify the flag \#BUFFER_FLAG_END_OF_STREAM.
  /// <p class=note>
  /// <strong>Note:</strong> Prior to android.os.Build.VERSION_CODES\#M,
  /// {@code presentationTimeUs} was not propagated to the frame timestamp of (rendered)
  /// Surface output buffers, and the resulting frame timestamp was undefined.
  /// Use \#releaseOutputBuffer(int, long) to ensure a specific frame timestamp is set.
  /// Similarly, since frame timestamps can be used by the destination surface for rendering
  /// synchronization, <strong>care must be taken to normalize presentationTimeUs so as to not be
  /// mistaken for a system time. (See {@linkplain \#releaseOutputBuffer(int, long) SurfaceView specifics}).</strong>
  ///@param index The index of a client-owned input buffer previously returned
  ///              in a call to \#dequeueInputBuffer.
  ///@param offset The byte offset into the input buffer at which the data starts.
  ///@param size The number of bytes of valid input data.
  ///@param presentationTimeUs The presentation timestamp in microseconds for this
  ///                           buffer. This is normally the media time at which this
  ///                           buffer should be presented (rendered). When using an output
  ///                           surface, this will be propagated as the SurfaceTexture\#getTimestamp timestamp for the frame (after
  ///                           conversion to nanoseconds).
  ///@param flags A bitmask of flags
  ///              \#BUFFER_FLAG_CODEC_CONFIG and \#BUFFER_FLAG_END_OF_STREAM.
  ///              While not prohibited, most codecs do not use the
  ///              \#BUFFER_FLAG_KEY_FRAME flag for input buffers.
  ///@throws IllegalStateException if not in the Executing state.
  ///@throws MediaCodec.CodecException upon codec error.
  ///@throws CryptoException if a crypto object has been specified in
  ///         \#configure
  void queueInputBuffer(
          int index, int offset, int size, int presentationTimeUs, int flags) =>
      jniAccessors.callMethodWithArgs(
          reference,
          _id_queueInputBuffer,
          jni.JniType.voidType,
          [index, offset, size, presentationTimeUs, flags]).check();

  static final _id_queueSecureInputBuffer = jniAccessors.getMethodIDOf(
      _classRef,
      "queueSecureInputBuffer",
      "(IILandroid/media/MediaCodec\$CryptoInfo;JI)V");

  /// from: public void queueSecureInputBuffer(int index, int offset, android.media.MediaCodec.CryptoInfo info, long presentationTimeUs, int flags)
  ///
  /// Similar to \#queueInputBuffer queueInputBuffer but submits a buffer that is
  /// potentially encrypted.
  /// <strong>Check out further notes at \#queueInputBuffer queueInputBuffer.</strong>
  ///@param index The index of a client-owned input buffer previously returned
  ///              in a call to \#dequeueInputBuffer.
  ///@param offset The byte offset into the input buffer at which the data starts.
  ///@param info Metadata required to facilitate decryption, the object can be
  ///             reused immediately after this call returns.
  /// This value must never be {@code null}.
  ///@param presentationTimeUs The presentation timestamp in microseconds for this
  ///                           buffer. This is normally the media time at which this
  ///                           buffer should be presented (rendered).
  ///@param flags A bitmask of flags
  ///              \#BUFFER_FLAG_CODEC_CONFIG and \#BUFFER_FLAG_END_OF_STREAM.
  ///              While not prohibited, most codecs do not use the
  ///              \#BUFFER_FLAG_KEY_FRAME flag for input buffers.
  ///@throws IllegalStateException if not in the Executing state.
  ///@throws MediaCodec.CodecException upon codec error.
  ///@throws CryptoException if an error occurs while attempting to decrypt the buffer.
  ///              An error code associated with the exception helps identify the
  ///              reason for the failure.
  void queueSecureInputBuffer(int index, int offset, MediaCodec_CryptoInfo info,
          int presentationTimeUs, int flags) =>
      jniAccessors.callMethodWithArgs(
          reference,
          _id_queueSecureInputBuffer,
          jni.JniType.voidType,
          [index, offset, info.reference, presentationTimeUs, flags]).check();

  static final _id_dequeueInputBuffer =
      jniAccessors.getMethodIDOf(_classRef, "dequeueInputBuffer", "(J)I");

  /// from: public int dequeueInputBuffer(long timeoutUs)
  ///
  /// Returns the index of an input buffer to be filled with valid data
  /// or -1 if no such buffer is currently available.
  /// This method will return immediately if timeoutUs == 0, wait indefinitely
  /// for the availability of an input buffer if timeoutUs &lt; 0 or wait up
  /// to "timeoutUs" microseconds if timeoutUs &gt; 0.
  ///@param timeoutUs The timeout in microseconds, a negative timeout indicates "infinite".
  ///@throws IllegalStateException if not in the Executing state,
  ///         or codec is configured in asynchronous mode.
  ///@throws MediaCodec.CodecException upon codec error.
  int dequeueInputBuffer(int timeoutUs) => jniAccessors.callMethodWithArgs(
      reference,
      _id_dequeueInputBuffer,
      jni.JniType.intType,
      [timeoutUs]).integer;

  static final _id_dequeueOutputBuffer = jniAccessors.getMethodIDOf(_classRef,
      "dequeueOutputBuffer", "(Landroid/media/MediaCodec\$BufferInfo;J)I");

  /// from: public int dequeueOutputBuffer(android.media.MediaCodec.BufferInfo info, long timeoutUs)
  ///
  /// Dequeue an output buffer, block at most "timeoutUs" microseconds.
  /// Returns the index of an output buffer that has been successfully
  /// decoded or one of the INFO_* constants.
  ///@param info Will be filled with buffer meta data.
  /// This value must never be {@code null}.
  ///@param timeoutUs The timeout in microseconds, a negative timeout indicates "infinite".
  ///@throws IllegalStateException if not in the Executing state,
  ///         or codec is configured in asynchronous mode.
  ///@throws MediaCodec.CodecException upon codec error.
  ///@return Value is android.media.MediaCodec\#INFO_TRY_AGAIN_LATER, android.media.MediaCodec\#INFO_OUTPUT_FORMAT_CHANGED, or android.media.MediaCodec\#INFO_OUTPUT_BUFFERS_CHANGED
  int dequeueOutputBuffer(MediaCodec_BufferInfo info, int timeoutUs) =>
      jniAccessors.callMethodWithArgs(reference, _id_dequeueOutputBuffer,
          jni.JniType.intType, [info.reference, timeoutUs]).integer;

  static final _id_releaseOutputBuffer =
      jniAccessors.getMethodIDOf(_classRef, "releaseOutputBuffer", "(IZ)V");

  /// from: public void releaseOutputBuffer(int index, boolean render)
  ///
  /// If you are done with a buffer, use this call to return the buffer to the codec
  /// or to render it on the output surface. If you configured the codec with an
  /// output surface, setting {@code render} to {@code true} will first send the buffer
  /// to that output surface. The surface will release the buffer back to the codec once
  /// it is no longer used/displayed.
  ///
  /// Once an output buffer is released to the codec, it MUST NOT
  /// be used until it is later retrieved by \#getOutputBuffer in response
  /// to a \#dequeueOutputBuffer return value or a
  /// Callback\#onOutputBufferAvailable callback.
  ///@param index The index of a client-owned output buffer previously returned
  ///              from a call to \#dequeueOutputBuffer.
  ///@param render If a valid surface was specified when configuring the codec,
  ///               passing true renders this output buffer to the surface.
  ///@throws IllegalStateException if not in the Executing state.
  ///@throws MediaCodec.CodecException upon codec error.
  void releaseOutputBuffer(int index, bool render) =>
      jniAccessors.callMethodWithArgs(reference, _id_releaseOutputBuffer,
          jni.JniType.voidType, [index, render]).check();

  static final _id_releaseOutputBuffer1 =
      jniAccessors.getMethodIDOf(_classRef, "releaseOutputBuffer", "(IJ)V");

  /// from: public void releaseOutputBuffer(int index, long renderTimestampNs)
  ///
  /// If you are done with a buffer, use this call to update its surface timestamp
  /// and return it to the codec to render it on the output surface. If you
  /// have not specified an output surface when configuring this video codec,
  /// this call will simply return the buffer to the codec.
  ///
  /// The timestamp may have special meaning depending on the destination surface.
  ///
  /// <table>
  /// <tr><th>SurfaceView specifics</th></tr>
  /// <tr><td>
  /// If you render your buffer on a android.view.SurfaceView,
  /// you can use the timestamp to render the buffer at a specific time (at the
  /// VSYNC at or after the buffer timestamp).  For this to work, the timestamp
  /// needs to be <i>reasonably close</i> to the current System\#nanoTime.
  /// Currently, this is set as within one (1) second. A few notes:
  ///
  /// <ul>
  /// <li>the buffer will not be returned to the codec until the timestamp
  /// has passed and the buffer is no longer used by the android.view.Surface.
  /// <li>buffers are processed sequentially, so you may block subsequent buffers to
  /// be displayed on the android.view.Surface.  This is important if you
  /// want to react to user action, e.g. stop the video or seek.
  /// <li>if multiple buffers are sent to the android.view.Surface to be
  /// rendered at the same VSYNC, the last one will be shown, and the other ones
  /// will be dropped.
  /// <li>if the timestamp is _not_ "reasonably close" to the current system
  /// time, the android.view.Surface will ignore the timestamp, and
  /// display the buffer at the earliest feasible time.  In this mode it will not
  /// drop frames.
  /// <li>for best performance and quality, call this method when you are about
  /// two VSYNCs' time before the desired render time.  For 60Hz displays, this is
  /// about 33 msec.
  /// </ul>
  /// </td></tr>
  /// </table>
  ///
  /// Once an output buffer is released to the codec, it MUST NOT
  /// be used until it is later retrieved by \#getOutputBuffer in response
  /// to a \#dequeueOutputBuffer return value or a
  /// Callback\#onOutputBufferAvailable callback.
  ///@param index The index of a client-owned output buffer previously returned
  ///              from a call to \#dequeueOutputBuffer.
  ///@param renderTimestampNs The timestamp to associate with this buffer when
  ///              it is sent to the Surface.
  ///@throws IllegalStateException if not in the Executing state.
  ///@throws MediaCodec.CodecException upon codec error.
  void releaseOutputBuffer1(int index, int renderTimestampNs) =>
      jniAccessors.callMethodWithArgs(reference, _id_releaseOutputBuffer1,
          jni.JniType.voidType, [index, renderTimestampNs]).check();

  static final _id_signalEndOfInputStream =
      jniAccessors.getMethodIDOf(_classRef, "signalEndOfInputStream", "()V");

  /// from: public native void signalEndOfInputStream()
  ///
  /// Signals end-of-stream on input.  Equivalent to submitting an empty buffer with
  /// \#BUFFER_FLAG_END_OF_STREAM set.  This may only be used with
  /// encoders receiving input from a Surface created by \#createInputSurface.
  ///@throws IllegalStateException if not in the Executing state.
  ///@throws MediaCodec.CodecException upon codec error.
  void signalEndOfInputStream() => jniAccessors.callMethodWithArgs(
      reference, _id_signalEndOfInputStream, jni.JniType.voidType, []).check();

  static final _id_getOutputFormat = jniAccessors.getMethodIDOf(
      _classRef, "getOutputFormat", "()Landroid/media/MediaFormat;");

  /// from: public android.media.MediaFormat getOutputFormat()
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// Call this after dequeueOutputBuffer signals a format change by returning
  /// \#INFO_OUTPUT_FORMAT_CHANGED.
  /// You can also call this after \#configure returns
  /// successfully to get the output format initially configured
  /// for the codec.  Do this to determine what optional
  /// configuration parameters were supported by the codec.
  ///@throws IllegalStateException if not in the Executing or
  ///                               Configured state.
  ///@throws MediaCodec.CodecException upon codec error.
  ///@return This value will never be {@code null}.
  mediaformat_.MediaFormat getOutputFormat() =>
      mediaformat_.MediaFormat.fromRef(jniAccessors.callMethodWithArgs(
          reference, _id_getOutputFormat, jni.JniType.objectType, []).object);

  static final _id_getInputFormat = jniAccessors.getMethodIDOf(
      _classRef, "getInputFormat", "()Landroid/media/MediaFormat;");

  /// from: public android.media.MediaFormat getInputFormat()
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// Call this after \#configure returns successfully to
  /// get the input format accepted by the codec. Do this to
  /// determine what optional configuration parameters were
  /// supported by the codec.
  ///@throws IllegalStateException if not in the Executing or
  ///                               Configured state.
  ///@throws MediaCodec.CodecException upon codec error.
  ///@return This value will never be {@code null}.
  mediaformat_.MediaFormat getInputFormat() =>
      mediaformat_.MediaFormat.fromRef(jniAccessors.callMethodWithArgs(
          reference, _id_getInputFormat, jni.JniType.objectType, []).object);

  static final _id_getOutputFormat1 = jniAccessors.getMethodIDOf(
      _classRef, "getOutputFormat", "(I)Landroid/media/MediaFormat;");

  /// from: public android.media.MediaFormat getOutputFormat(int index)
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// Returns the output format for a specific output buffer.
  ///@param index The index of a client-owned input buffer previously
  ///              returned from a call to \#dequeueInputBuffer.
  ///@return the format for the output buffer, or null if the index
  /// is not a dequeued output buffer.
  mediaformat_.MediaFormat getOutputFormat1(int index) =>
      mediaformat_.MediaFormat.fromRef(jniAccessors.callMethodWithArgs(
          reference,
          _id_getOutputFormat1,
          jni.JniType.objectType,
          [index]).object);

  static final _id_getInputBuffers = jniAccessors.getMethodIDOf(
      _classRef, "getInputBuffers", "()[Ljava/nio/ByteBuffer;");

  /// from: public java.nio.ByteBuffer[] getInputBuffers()
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// Retrieve the set of input buffers.  Call this after start()
  /// returns. After calling this method, any ByteBuffers
  /// previously returned by an earlier call to this method MUST no
  /// longer be used.
  ///@deprecated Use the new \#getInputBuffer method instead
  /// each time an input buffer is dequeued.
  ///
  /// __Note:__ As of API 21, dequeued input buffers are
  /// automatically java.nio.Buffer\#clear cleared.
  ///
  /// _Do not use this method if using an input surface._
  ///@throws IllegalStateException if not in the Executing state,
  ///         or codec is configured in asynchronous mode.
  ///@throws MediaCodec.CodecException upon codec error.
  ///@return This value will never be {@code null}.
  jni.JniObject getInputBuffers() =>
      jni.JniObject.fromRef(jniAccessors.callMethodWithArgs(
          reference, _id_getInputBuffers, jni.JniType.objectType, []).object);

  static final _id_getOutputBuffers = jniAccessors.getMethodIDOf(
      _classRef, "getOutputBuffers", "()[Ljava/nio/ByteBuffer;");

  /// from: public java.nio.ByteBuffer[] getOutputBuffers()
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// Retrieve the set of output buffers.  Call this after start()
  /// returns and whenever dequeueOutputBuffer signals an output
  /// buffer change by returning \#INFO_OUTPUT_BUFFERS_CHANGED. After calling this method, any
  /// ByteBuffers previously returned by an earlier call to this
  /// method MUST no longer be used.
  ///@deprecated Use the new \#getOutputBuffer method instead
  /// each time an output buffer is dequeued.  This method is not
  /// supported if codec is configured in asynchronous mode.
  ///
  /// __Note:__ As of API 21, the position and limit of output
  /// buffers that are dequeued will be set to the valid data
  /// range.
  ///
  /// _Do not use this method if using an output surface._
  ///@throws IllegalStateException if not in the Executing state,
  ///         or codec is configured in asynchronous mode.
  ///@throws MediaCodec.CodecException upon codec error.
  ///@return This value will never be {@code null}.
  jni.JniObject getOutputBuffers() =>
      jni.JniObject.fromRef(jniAccessors.callMethodWithArgs(
          reference, _id_getOutputBuffers, jni.JniType.objectType, []).object);

  static final _id_getInputBuffer = jniAccessors.getMethodIDOf(
      _classRef, "getInputBuffer", "(I)Ljava/nio/ByteBuffer;");

  /// from: public java.nio.ByteBuffer getInputBuffer(int index)
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// Returns a java.nio.Buffer\#clear cleared, writable ByteBuffer
  /// object for a dequeued input buffer index to contain the input data.
  ///
  /// After calling this method any ByteBuffer or Image object
  /// previously returned for the same input index MUST no longer
  /// be used.
  ///@param index The index of a client-owned input buffer previously
  ///              returned from a call to \#dequeueInputBuffer,
  ///              or received via an onInputBufferAvailable callback.
  ///@return the input buffer, or null if the index is not a dequeued
  /// input buffer, or if the codec is configured for surface input.
  ///@throws IllegalStateException if not in the Executing state.
  ///@throws MediaCodec.CodecException upon codec error.
  jni.JniObject getInputBuffer(int index) =>
      jni.JniObject.fromRef(jniAccessors.callMethodWithArgs(reference,
          _id_getInputBuffer, jni.JniType.objectType, [index]).object);

  static final _id_getInputImage = jniAccessors.getMethodIDOf(
      _classRef, "getInputImage", "(I)Landroid/media/Image;");

  /// from: public android.media.Image getInputImage(int index)
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// Returns a writable Image object for a dequeued input buffer
  /// index to contain the raw input video frame.
  ///
  /// After calling this method any ByteBuffer or Image object
  /// previously returned for the same input index MUST no longer
  /// be used.
  ///@param index The index of a client-owned input buffer previously
  ///              returned from a call to \#dequeueInputBuffer,
  ///              or received via an onInputBufferAvailable callback.
  ///@return the input image, or null if the index is not a
  /// dequeued input buffer, or not a ByteBuffer that contains a
  /// raw image.
  ///@throws IllegalStateException if not in the Executing state.
  ///@throws MediaCodec.CodecException upon codec error.
  image_.Image getInputImage(int index) =>
      image_.Image.fromRef(jniAccessors.callMethodWithArgs(reference,
          _id_getInputImage, jni.JniType.objectType, [index]).object);

  static final _id_getOutputBuffer = jniAccessors.getMethodIDOf(
      _classRef, "getOutputBuffer", "(I)Ljava/nio/ByteBuffer;");

  /// from: public java.nio.ByteBuffer getOutputBuffer(int index)
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// Returns a read-only ByteBuffer for a dequeued output buffer
  /// index. The position and limit of the returned buffer are set
  /// to the valid output data.
  ///
  /// After calling this method, any ByteBuffer or Image object
  /// previously returned for the same output index MUST no longer
  /// be used.
  ///@param index The index of a client-owned output buffer previously
  ///              returned from a call to \#dequeueOutputBuffer,
  ///              or received via an onOutputBufferAvailable callback.
  ///@return the output buffer, or null if the index is not a dequeued
  /// output buffer, or the codec is configured with an output surface.
  ///@throws IllegalStateException if not in the Executing state.
  ///@throws MediaCodec.CodecException upon codec error.
  jni.JniObject getOutputBuffer(int index) =>
      jni.JniObject.fromRef(jniAccessors.callMethodWithArgs(reference,
          _id_getOutputBuffer, jni.JniType.objectType, [index]).object);

  static final _id_getOutputImage = jniAccessors.getMethodIDOf(
      _classRef, "getOutputImage", "(I)Landroid/media/Image;");

  /// from: public android.media.Image getOutputImage(int index)
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// Returns a read-only Image object for a dequeued output buffer
  /// index that contains the raw video frame.
  ///
  /// After calling this method, any ByteBuffer or Image object previously
  /// returned for the same output index MUST no longer be used.
  ///@param index The index of a client-owned output buffer previously
  ///              returned from a call to \#dequeueOutputBuffer,
  ///              or received via an onOutputBufferAvailable callback.
  ///@return the output image, or null if the index is not a
  /// dequeued output buffer, not a raw video frame, or if the codec
  /// was configured with an output surface.
  ///@throws IllegalStateException if not in the Executing state.
  ///@throws MediaCodec.CodecException upon codec error.
  image_.Image getOutputImage(int index) =>
      image_.Image.fromRef(jniAccessors.callMethodWithArgs(reference,
          _id_getOutputImage, jni.JniType.objectType, [index]).object);

  static final _id_setVideoScalingMode =
      jniAccessors.getMethodIDOf(_classRef, "setVideoScalingMode", "(I)V");

  /// from: public native void setVideoScalingMode(int mode)
  ///
  /// If a surface has been specified in a previous call to \#configure
  /// specifies the scaling mode to use. The default is "scale to fit".
  /// <p class=note>
  /// The scaling mode may be reset to the <strong>default</strong> each time an
  /// \#INFO_OUTPUT_BUFFERS_CHANGED event is received from the codec; therefore, the client
  /// must call this method after every buffer change event (and before the first output buffer is
  /// released for rendering) to ensure consistent scaling mode.
  /// <p class=note>
  /// Since the \#INFO_OUTPUT_BUFFERS_CHANGED event is deprecated, this can also be done
  /// after each \#INFO_OUTPUT_FORMAT_CHANGED event.
  ///@throws IllegalArgumentException if mode is not recognized.
  ///@throws IllegalStateException if in the Released state.
  ///@param mode Value is android.media.MediaCodec\#VIDEO_SCALING_MODE_SCALE_TO_FIT, or android.media.MediaCodec\#VIDEO_SCALING_MODE_SCALE_TO_FIT_WITH_CROPPING
  void setVideoScalingMode(int mode) => jniAccessors.callMethodWithArgs(
      reference, _id_setVideoScalingMode, jni.JniType.voidType, [mode]).check();

  static final _id_getName =
      jniAccessors.getMethodIDOf(_classRef, "getName", "()Ljava/lang/String;");

  /// from: public native java.lang.String getName()
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// Get the component name. If the codec was created by createDecoderByType
  /// or createEncoderByType, what component is chosen is not known beforehand.
  ///@throws IllegalStateException if in the Released state.
  ///@return This value will never be {@code null}.
  jni.JniString getName() =>
      jni.JniString.fromRef(jniAccessors.callMethodWithArgs(
          reference, _id_getName, jni.JniType.objectType, []).object);

  static final _id_getMetrics = jniAccessors.getMethodIDOf(
      _classRef, "getMetrics", "()Landroid/os/PersistableBundle;");

  /// from: public android.os.PersistableBundle getMetrics()
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// Return Metrics data about the current codec instance.
  ///@return a PersistableBundle containing the set of attributes and values
  /// available for the media being handled by this instance of MediaCodec
  /// The attributes are descibed in MetricsConstants.
  ///
  /// Additional vendor-specific fields may also be present in
  /// the return value.
  persistablebundle_.PersistableBundle getMetrics() =>
      persistablebundle_.PersistableBundle.fromRef(jniAccessors
          .callMethodWithArgs(
              reference, _id_getMetrics, jni.JniType.objectType, []).object);

  static final _id_setParameters = jniAccessors.getMethodIDOf(
      _classRef, "setParameters", "(Landroid/os/Bundle;)V");

  /// from: public void setParameters(android.os.Bundle params)
  ///
  /// Communicate additional parameter changes to the component instance.
  /// __Note:__ Some of these parameter changes may silently fail to apply.
  ///@param params The bundle of parameters to set.
  /// This value may be {@code null}.
  ///@throws IllegalStateException if in the Released state.
  void setParameters(bundle_.Bundle params) => jniAccessors.callMethodWithArgs(
      reference,
      _id_setParameters,
      jni.JniType.voidType,
      [params.reference]).check();

  static final _id_setCallback = jniAccessors.getMethodIDOf(
      _classRef,
      "setCallback",
      "(Landroid/media/MediaCodec\$Callback;Landroid/os/Handler;)V");

  /// from: public void setCallback(android.media.MediaCodec.Callback cb, android.os.Handler handler)
  ///
  /// Sets an asynchronous callback for actionable MediaCodec events.
  ///
  /// If the client intends to use the component in asynchronous mode,
  /// a valid callback should be provided before \#configure is called.
  ///
  /// When asynchronous callback is enabled, the client should not call
  /// \#getInputBuffers, \#getOutputBuffers,
  /// \#dequeueInputBuffer(long) or \#dequeueOutputBuffer(BufferInfo, long).
  ///
  /// Also, \#flush behaves differently in asynchronous mode.  After calling
  /// {@code flush}, you must call \#start to "resume" receiving input buffers,
  /// even if an input surface was created.
  ///@param cb The callback that will run.  Use {@code null} to clear a previously
  ///           set callback (before \#configure configure is called and run
  ///           in synchronous mode).
  /// This value may be {@code null}.
  ///@param handler Callbacks will happen on the handler's thread. If {@code null},
  ///           callbacks are done on the default thread (the caller's thread or the
  ///           main thread.)
  ///
  /// This value may be {@code null}.
  void setCallback(MediaCodec_Callback cb, handler_.Handler handler) =>
      jniAccessors.callMethodWithArgs(reference, _id_setCallback,
          jni.JniType.voidType, [cb.reference, handler.reference]).check();

  static final _id_setCallback1 = jniAccessors.getMethodIDOf(
      _classRef, "setCallback", "(Landroid/media/MediaCodec\$Callback;)V");

  /// from: public void setCallback(android.media.MediaCodec.Callback cb)
  ///
  /// Sets an asynchronous callback for actionable MediaCodec events on the default
  /// looper.
  ///
  /// Same as \#setCallback(Callback, Handler) with handler set to null.
  ///@param cb The callback that will run.  Use {@code null} to clear a previously
  ///           set callback (before \#configure configure is called and run
  ///           in synchronous mode).
  /// This value may be {@code null}.
  ///@see \#setCallback(Callback, Handler)
  void setCallback1(MediaCodec_Callback cb) => jniAccessors.callMethodWithArgs(
      reference,
      _id_setCallback1,
      jni.JniType.voidType,
      [cb.reference]).check();

  static final _id_setOnFrameRenderedListener = jniAccessors.getMethodIDOf(
      _classRef,
      "setOnFrameRenderedListener",
      "(Landroid/media/MediaCodec\$OnFrameRenderedListener;Landroid/os/Handler;)V");

  /// from: public void setOnFrameRenderedListener(android.media.MediaCodec.OnFrameRenderedListener listener, android.os.Handler handler)
  ///
  /// Registers a callback to be invoked when an output frame is rendered on the output surface.
  ///
  /// This method can be called in any codec state, but will only have an effect in the
  /// Executing state for codecs that render buffers to the output surface.
  ///
  /// <strong>Note:</strong> This callback is for informational purposes only: to get precise
  /// render timing samples, and can be significantly delayed and batched. Some frames may have
  /// been rendered even if there was no callback generated.
  ///@param listener the callback that will be run
  /// This value may be {@code null}.
  ///@param handler the callback will be run on the handler's thread. If {@code null},
  ///           the callback will be run on the default thread, which is the looper
  ///           from which the codec was created, or a new thread if there was none.
  ///
  /// This value may be {@code null}.
  void setOnFrameRenderedListener(MediaCodec_OnFrameRenderedListener listener,
          handler_.Handler handler) =>
      jniAccessors.callMethodWithArgs(
          reference,
          _id_setOnFrameRenderedListener,
          jni.JniType.voidType,
          [listener.reference, handler.reference]).check();

  static final _id_getCodecInfo = jniAccessors.getMethodIDOf(
      _classRef, "getCodecInfo", "()Landroid/media/MediaCodecInfo;");

  /// from: public android.media.MediaCodecInfo getCodecInfo()
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// Get the codec info. If the codec was created by createDecoderByType
  /// or createEncoderByType, what component is chosen is not known beforehand,
  /// and thus the caller does not have the MediaCodecInfo.
  ///@throws IllegalStateException if in the Released state.
  ///@return This value will never be {@code null}.
  mediacodecinfo_.MediaCodecInfo getCodecInfo() =>
      mediacodecinfo_.MediaCodecInfo.fromRef(jniAccessors.callMethodWithArgs(
          reference, _id_getCodecInfo, jni.JniType.objectType, []).object);
}

/// from: android.media.MediaCodec$OnFrameRenderedListener
///
/// Listener to be called when an output frame has rendered on the output surface
///@see MediaCodec\#setOnFrameRenderedListener
class MediaCodec_OnFrameRenderedListener extends jni.JniObject {
  static final _classRef = jniAccessors
      .getClassOf("android/media/MediaCodec\$OnFrameRenderedListener");
  MediaCodec_OnFrameRenderedListener.fromRef(jni.JObject ref)
      : super.fromRef(ref);

  static final _id_onFrameRendered = jniAccessors.getMethodIDOf(
      _classRef, "onFrameRendered", "(Landroid/media/MediaCodec;JJ)V");

  /// from: public abstract void onFrameRendered(android.media.MediaCodec codec, long presentationTimeUs, long nanoTime)
  ///
  /// Called when an output frame has rendered on the output surface.
  ///
  /// <strong>Note:</strong> This callback is for informational purposes only: to get precise
  /// render timing samples, and can be significantly delayed and batched. Some frames may have
  /// been rendered even if there was no callback generated.
  ///@param codec the MediaCodec instance
  /// This value must never be {@code null}.
  ///@param presentationTimeUs the presentation time (media time) of the frame rendered.
  ///          This is usually the same as specified in \#queueInputBuffer; however,
  ///          some codecs may alter the media time by applying some time-based transformation,
  ///          such as frame rate conversion. In that case, presentation time corresponds
  ///          to the actual output frame rendered.
  ///@param nanoTime The system time when the frame was rendered.
  ///@see System\#nanoTime
  void onFrameRendered(
          MediaCodec codec, int presentationTimeUs, int nanoTime) =>
      jniAccessors.callMethodWithArgs(
          reference,
          _id_onFrameRendered,
          jni.JniType.voidType,
          [codec.reference, presentationTimeUs, nanoTime]).check();
}

/// from: android.media.MediaCodec$MetricsConstants
class MediaCodec_MetricsConstants extends jni.JniObject {
  static final _classRef =
      jniAccessors.getClassOf("android/media/MediaCodec\$MetricsConstants");
  MediaCodec_MetricsConstants.fromRef(jni.JObject ref) : super.fromRef(ref);

  /// from: static public final java.lang.String CODEC
  ///
  /// Key to extract the codec being used
  /// from the MediaCodec\#getMetrics return value.
  /// The value is a String.
  static const CODEC = "android.media.mediacodec.codec";

  /// from: static public final java.lang.String ENCODER
  ///
  /// Key to extract the flag indicating whether the codec is running
  /// as an encoder or decoder from the MediaCodec\#getMetrics return value.
  /// The value is an integer.
  /// A 0 indicates decoder; 1 indicates encoder.
  static const ENCODER = "android.media.mediacodec.encoder";

  /// from: static public final java.lang.String HEIGHT
  ///
  /// Key to extract the height (in pixels) of the video track
  /// from the MediaCodec\#getMetrics return value.
  /// The value is an integer.
  static const HEIGHT = "android.media.mediacodec.height";

  /// from: static public final java.lang.String MIME_TYPE
  ///
  /// Key to extract the MIME type
  /// from the MediaCodec\#getMetrics return value.
  /// The value is a String.
  static const MIME_TYPE = "android.media.mediacodec.mime";

  /// from: static public final java.lang.String MODE
  ///
  /// Key to extract what the codec mode
  /// from the MediaCodec\#getMetrics return value.
  /// The value is a String. Values will be one of the constants
  /// \#MODE_AUDIO or \#MODE_VIDEO.
  static const MODE = "android.media.mediacodec.mode";

  /// from: static public final java.lang.String MODE_AUDIO
  ///
  /// The value returned for the key \#MODE when the
  /// codec is a audio codec.
  static const MODE_AUDIO = "audio";

  /// from: static public final java.lang.String MODE_VIDEO
  ///
  /// The value returned for the key \#MODE when the
  /// codec is a video codec.
  static const MODE_VIDEO = "video";

  /// from: static public final java.lang.String ROTATION
  ///
  /// Key to extract the rotation (in degrees) to properly orient the video
  /// from the MediaCodec\#getMetrics return.
  /// The value is a integer.
  static const ROTATION = "android.media.mediacodec.rotation";

  /// from: static public final java.lang.String SECURE
  ///
  /// Key to extract the flag indicating whether the codec is running
  /// in secure (DRM) mode from the MediaCodec\#getMetrics return value.
  /// The value is an integer.
  static const SECURE = "android.media.mediacodec.secure";

  /// from: static public final java.lang.String WIDTH
  ///
  /// Key to extract the width (in pixels) of the video track
  /// from the MediaCodec\#getMetrics return value.
  /// The value is an integer.
  static const WIDTH = "android.media.mediacodec.width";
}

/// from: android.media.MediaCodec$CryptoInfo
///
/// Metadata describing the structure of an encrypted input sample.
///
/// A buffer's data is considered to be partitioned into "subSamples". Each subSample starts with
/// a run of plain, unencrypted bytes followed by a run of encrypted bytes. Either of these runs
/// may be empty. If pattern encryption applies, each of the encrypted runs is encrypted only
/// partly, according to a repeating pattern of "encrypt" and "skip" blocks.
/// \#numBytesOfClearData can be null to indicate that all data is encrypted, and
/// \#numBytesOfEncryptedData can be null to indicate that all data is clear. At least one
/// of \#numBytesOfClearData and \#numBytesOfEncryptedData must be non-null.
///
/// This information encapsulates per-sample metadata as outlined in ISO/IEC FDIS 23001-7:2016
/// "Common encryption in ISO base media file format files".
///
/// <h3>ISO-CENC Schemes</h3>
/// ISO/IEC FDIS 23001-7:2016 defines four possible schemes by which media may be encrypted,
/// corresponding to each possible combination of an AES mode with the presence or absence of
/// patterned encryption.
///
/// <table style="width: 0%">
///   <thead>
///     <tr>
///       <th>&nbsp;</th>
///       <th>AES-CTR</th>
///       <th>AES-CBC</th>
///     </tr>
///   </thead>
///   <tbody>
///     <tr>
///       <th>Without Patterns</th>
///       <td>cenc</td>
///       <td>cbc1</td>
///     </tr><tr>
///       <th>With Patterns</th>
///       <td>cens</td>
///       <td>cbcs</td>
///     </tr>
///   </tbody>
/// </table>
///
/// For {@code CryptoInfo}, the scheme is selected implicitly by the combination of the
/// \#mode field and the value set with \#setPattern. For the pattern, setting the
/// pattern to all zeroes (that is, both {@code blocksToEncrypt} and {@code blocksToSkip} are
/// zero) is interpreted as turning patterns off completely. A scheme that does not use patterns
/// will be selected, either cenc or cbc1. Setting the pattern to any nonzero value will choose
/// one of the pattern-supporting schemes, cens or cbcs. The default pattern if
/// \#setPattern is never called is all zeroes.
///
/// <h4>HLS SAMPLE-AES Audio</h4>
/// HLS SAMPLE-AES audio is encrypted in a manner compatible with the cbcs scheme, except that it
/// does not use patterned encryption. However, if \#setPattern is used to set the pattern
/// to all zeroes, this will be interpreted as selecting the cbc1 scheme. The cbc1 scheme cannot
/// successfully decrypt HLS SAMPLE-AES audio because of differences in how the IVs are handled.
/// For this reason, it is recommended that a pattern of {@code 1} encrypted block and {@code 0}
/// skip blocks be used with HLS SAMPLE-AES audio. This will trigger decryption to use cbcs mode
/// while still decrypting every block.
class MediaCodec_CryptoInfo extends jni.JniObject {
  static final _classRef =
      jniAccessors.getClassOf("android/media/MediaCodec\$CryptoInfo");
  MediaCodec_CryptoInfo.fromRef(jni.JObject ref) : super.fromRef(ref);

  static final _id_iv = jniAccessors.getFieldIDOf(_classRef, "iv", "[B");

  /// from: public byte[] iv
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// A 16-byte initialization vector
  jni.JniObject get iv => jni.JniObject.fromRef(
      jniAccessors.getField(reference, _id_iv, jni.JniType.objectType).object);

  /// from: public byte[] iv
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// A 16-byte initialization vector
  set iv(jni.JniObject value) =>
      jniEnv.SetObjectField(reference, _id_iv, value.reference);

  static final _id_key = jniAccessors.getFieldIDOf(_classRef, "key", "[B");

  /// from: public byte[] key
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// A 16-byte key id
  jni.JniObject get key => jni.JniObject.fromRef(
      jniAccessors.getField(reference, _id_key, jni.JniType.objectType).object);

  /// from: public byte[] key
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// A 16-byte key id
  set key(jni.JniObject value) =>
      jniEnv.SetObjectField(reference, _id_key, value.reference);

  static final _id_mode = jniAccessors.getFieldIDOf(_classRef, "mode", "I");

  /// from: public int mode
  ///
  /// The type of encryption that has been applied,
  /// see \#CRYPTO_MODE_UNENCRYPTED, \#CRYPTO_MODE_AES_CTR
  /// and \#CRYPTO_MODE_AES_CBC
  int get mode =>
      jniAccessors.getField(reference, _id_mode, jni.JniType.intType).integer;

  /// from: public int mode
  ///
  /// The type of encryption that has been applied,
  /// see \#CRYPTO_MODE_UNENCRYPTED, \#CRYPTO_MODE_AES_CTR
  /// and \#CRYPTO_MODE_AES_CBC
  set mode(int value) => jniEnv.SetIntField(reference, _id_mode, value);

  static final _id_numBytesOfClearData =
      jniAccessors.getFieldIDOf(_classRef, "numBytesOfClearData", "[I");

  /// from: public int[] numBytesOfClearData
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// The number of leading unencrypted bytes in each subSample. If null, all bytes are treated
  /// as encrypted and \#numBytesOfEncryptedData must be specified.
  jni.JniObject get numBytesOfClearData => jni.JniObject.fromRef(jniAccessors
      .getField(reference, _id_numBytesOfClearData, jni.JniType.objectType)
      .object);

  /// from: public int[] numBytesOfClearData
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// The number of leading unencrypted bytes in each subSample. If null, all bytes are treated
  /// as encrypted and \#numBytesOfEncryptedData must be specified.
  set numBytesOfClearData(jni.JniObject value) => jniEnv.SetObjectField(
      reference, _id_numBytesOfClearData, value.reference);

  static final _id_numBytesOfEncryptedData =
      jniAccessors.getFieldIDOf(_classRef, "numBytesOfEncryptedData", "[I");

  /// from: public int[] numBytesOfEncryptedData
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// The number of trailing encrypted bytes in each subSample. If null, all bytes are treated
  /// as clear and \#numBytesOfClearData must be specified.
  jni.JniObject get numBytesOfEncryptedData =>
      jni.JniObject.fromRef(jniAccessors
          .getField(
              reference, _id_numBytesOfEncryptedData, jni.JniType.objectType)
          .object);

  /// from: public int[] numBytesOfEncryptedData
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// The number of trailing encrypted bytes in each subSample. If null, all bytes are treated
  /// as clear and \#numBytesOfClearData must be specified.
  set numBytesOfEncryptedData(jni.JniObject value) => jniEnv.SetObjectField(
      reference, _id_numBytesOfEncryptedData, value.reference);

  static final _id_numSubSamples =
      jniAccessors.getFieldIDOf(_classRef, "numSubSamples", "I");

  /// from: public int numSubSamples
  ///
  /// The number of subSamples that make up the buffer's contents.
  int get numSubSamples => jniAccessors
      .getField(reference, _id_numSubSamples, jni.JniType.intType)
      .integer;

  /// from: public int numSubSamples
  ///
  /// The number of subSamples that make up the buffer's contents.
  set numSubSamples(int value) =>
      jniEnv.SetIntField(reference, _id_numSubSamples, value);

  static final _id_ctor =
      jniAccessors.getMethodIDOf(_classRef, "<init>", "()V");

  /// from: public void <init>()
  /// The returned object must be deleted after use, by calling the `delete` method.
  MediaCodec_CryptoInfo()
      : super.fromRef(
            jniAccessors.newObjectWithArgs(_classRef, _id_ctor, []).object);

  static final _id_set0 =
      jniAccessors.getMethodIDOf(_classRef, "set", "(I[I[I[B[BI)V");

  /// from: public void set(int newNumSubSamples, int[] newNumBytesOfClearData, int[] newNumBytesOfEncryptedData, byte[] newKey, byte[] newIV, int newMode)
  ///
  /// Set the subsample count, clear/encrypted sizes, key, IV and mode fields of
  /// a MediaCodec.CryptoInfo instance.
  ///@param newNumBytesOfClearData This value must never be {@code null}.
  ///@param newNumBytesOfEncryptedData This value must never be {@code null}.
  ///@param newKey This value must never be {@code null}.
  ///@param newIV This value must never be {@code null}.
  void set0(
          int newNumSubSamples,
          jni.JniObject newNumBytesOfClearData,
          jni.JniObject newNumBytesOfEncryptedData,
          jni.JniObject newKey,
          jni.JniObject newIV,
          int newMode) =>
      jniAccessors
          .callMethodWithArgs(reference, _id_set0, jni.JniType.voidType, [
        newNumSubSamples,
        newNumBytesOfClearData.reference,
        newNumBytesOfEncryptedData.reference,
        newKey.reference,
        newIV.reference,
        newMode
      ]).check();

  static final _id_setPattern = jniAccessors.getMethodIDOf(_classRef,
      "setPattern", "(Landroid/media/MediaCodec\$CryptoInfo\$Pattern;)V");

  /// from: public void setPattern(android.media.MediaCodec.CryptoInfo.Pattern newPattern)
  ///
  /// Set the encryption pattern on a MediaCodec.CryptoInfo instance.
  /// See MediaCodec.CryptoInfo.Pattern.
  void setPattern(MediaCodec_CryptoInfo_Pattern newPattern) =>
      jniAccessors.callMethodWithArgs(reference, _id_setPattern,
          jni.JniType.voidType, [newPattern.reference]).check();

  static final _id_toString1 =
      jniAccessors.getMethodIDOf(_classRef, "toString", "()Ljava/lang/String;");

  /// from: public java.lang.String toString()
  /// The returned object must be deleted after use, by calling the `delete` method.
  jni.JniString toString1() =>
      jni.JniString.fromRef(jniAccessors.callMethodWithArgs(
          reference, _id_toString1, jni.JniType.objectType, []).object);
}

/// from: android.media.MediaCodec$CryptoInfo$Pattern
///
/// Metadata describing an encryption pattern for the protected bytes in a subsample.  An
/// encryption pattern consists of a repeating sequence of crypto blocks comprised of a
/// number of encrypted blocks followed by a number of unencrypted, or skipped, blocks.
class MediaCodec_CryptoInfo_Pattern extends jni.JniObject {
  static final _classRef =
      jniAccessors.getClassOf("android/media/MediaCodec\$CryptoInfo\$Pattern");
  MediaCodec_CryptoInfo_Pattern.fromRef(jni.JObject ref) : super.fromRef(ref);

  static final _id_ctor =
      jniAccessors.getMethodIDOf(_classRef, "<init>", "(II)V");

  /// from: public void <init>(int blocksToEncrypt, int blocksToSkip)
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// Construct a sample encryption pattern given the number of blocks to encrypt and skip
  /// in the pattern. If both parameters are zero, pattern encryption is inoperative.
  MediaCodec_CryptoInfo_Pattern(int blocksToEncrypt, int blocksToSkip)
      : super.fromRef(jniAccessors.newObjectWithArgs(
            _classRef, _id_ctor, [blocksToEncrypt, blocksToSkip]).object);

  static final _id_set0 = jniAccessors.getMethodIDOf(_classRef, "set", "(II)V");

  /// from: public void set(int blocksToEncrypt, int blocksToSkip)
  ///
  /// Set the number of blocks to encrypt and skip in a sample encryption pattern. If both
  /// parameters are zero, pattern encryption is inoperative.
  void set0(int blocksToEncrypt, int blocksToSkip) =>
      jniAccessors.callMethodWithArgs(reference, _id_set0, jni.JniType.voidType,
          [blocksToEncrypt, blocksToSkip]).check();

  static final _id_getSkipBlocks =
      jniAccessors.getMethodIDOf(_classRef, "getSkipBlocks", "()I");

  /// from: public int getSkipBlocks()
  ///
  /// Return the number of blocks to skip in a sample encryption pattern.
  int getSkipBlocks() => jniAccessors.callMethodWithArgs(
      reference, _id_getSkipBlocks, jni.JniType.intType, []).integer;

  static final _id_getEncryptBlocks =
      jniAccessors.getMethodIDOf(_classRef, "getEncryptBlocks", "()I");

  /// from: public int getEncryptBlocks()
  ///
  /// Return the number of blocks to encrypt in a sample encryption pattern.
  int getEncryptBlocks() => jniAccessors.callMethodWithArgs(
      reference, _id_getEncryptBlocks, jni.JniType.intType, []).integer;
}

/// from: android.media.MediaCodec$CryptoException
///
/// Thrown when a crypto error occurs while queueing a secure input buffer.
class MediaCodec_CryptoException extends jni.JniObject {
  static final _classRef =
      jniAccessors.getClassOf("android/media/MediaCodec\$CryptoException");
  MediaCodec_CryptoException.fromRef(jni.JObject ref) : super.fromRef(ref);

  /// from: static public final int ERROR_INSUFFICIENT_OUTPUT_PROTECTION
  ///
  /// This indicates that the output protection levels supported by the
  /// device are not sufficient to meet the requirements set by the
  /// content owner in the license policy.
  static const ERROR_INSUFFICIENT_OUTPUT_PROTECTION = 4;

  /// from: static public final int ERROR_KEY_EXPIRED
  ///
  /// This indicates that the key used for decryption is no longer
  /// valid due to license term expiration.  The operation can be retried
  /// after updating the expired keys.
  static const ERROR_KEY_EXPIRED = 2;

  /// from: static public final int ERROR_NO_KEY
  ///
  /// This indicates that the requested key was not found when trying to
  /// perform a decrypt operation.  The operation can be retried after adding
  /// the correct decryption key.
  static const ERROR_NO_KEY = 1;

  /// from: static public final int ERROR_RESOURCE_BUSY
  ///
  /// This indicates that a required crypto resource was not able to be
  /// allocated while attempting the requested operation.  The operation
  /// can be retried if the app is able to release resources.
  static const ERROR_RESOURCE_BUSY = 3;

  /// from: static public final int ERROR_SESSION_NOT_OPENED
  ///
  /// This indicates that decryption was attempted on a session that is
  /// not opened, which could be due to a failure to open the session,
  /// closing the session prematurely, or the session being reclaimed
  /// by the resource manager.
  static const ERROR_SESSION_NOT_OPENED = 5;

  /// from: static public final int ERROR_UNSUPPORTED_OPERATION
  ///
  /// This indicates that an operation was attempted that could not be
  /// supported by the crypto system of the device in its current
  /// configuration.  It may occur when the license policy requires
  /// device security features that aren't supported by the device,
  /// or due to an internal error in the crypto system that prevents
  /// the specified security policy from being met.
  static const ERROR_UNSUPPORTED_OPERATION = 6;

  static final _id_ctor =
      jniAccessors.getMethodIDOf(_classRef, "<init>", "(ILjava/lang/String;)V");

  /// from: public void <init>(int errorCode, java.lang.String detailMessage)
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// @param detailMessage This value may be {@code null}.
  MediaCodec_CryptoException(int errorCode, jni.JniString detailMessage)
      : super.fromRef(jniAccessors.newObjectWithArgs(
            _classRef, _id_ctor, [errorCode, detailMessage.reference]).object);

  static final _id_getErrorCode =
      jniAccessors.getMethodIDOf(_classRef, "getErrorCode", "()I");

  /// from: public int getErrorCode()
  ///
  /// Retrieve the error code associated with a CryptoException
  ///@return Value is android.media.MediaCodec.CryptoException\#ERROR_NO_KEY, android.media.MediaCodec.CryptoException\#ERROR_KEY_EXPIRED, android.media.MediaCodec.CryptoException\#ERROR_RESOURCE_BUSY, android.media.MediaCodec.CryptoException\#ERROR_INSUFFICIENT_OUTPUT_PROTECTION, android.media.MediaCodec.CryptoException\#ERROR_SESSION_NOT_OPENED, or android.media.MediaCodec.CryptoException\#ERROR_UNSUPPORTED_OPERATION
  int getErrorCode() => jniAccessors.callMethodWithArgs(
      reference, _id_getErrorCode, jni.JniType.intType, []).integer;
}

/// from: android.media.MediaCodec$CodecException
///
/// Thrown when an internal codec error occurs.
class MediaCodec_CodecException extends jni.JniObject {
  static final _classRef =
      jniAccessors.getClassOf("android/media/MediaCodec\$CodecException");
  MediaCodec_CodecException.fromRef(jni.JObject ref) : super.fromRef(ref);

  /// from: static public final int ERROR_INSUFFICIENT_RESOURCE
  ///
  /// This indicates required resource was not able to be allocated.
  static const ERROR_INSUFFICIENT_RESOURCE = 1100;

  /// from: static public final int ERROR_RECLAIMED
  ///
  /// This indicates the resource manager reclaimed the media resource used by the codec.
  ///
  /// With this exception, the codec must be released, as it has moved to terminal state.
  static const ERROR_RECLAIMED = 1101;

  static final _id_isTransient =
      jniAccessors.getMethodIDOf(_classRef, "isTransient", "()Z");

  /// from: public boolean isTransient()
  ///
  /// Returns true if the codec exception is a transient issue,
  /// perhaps due to resource constraints, and that the method
  /// (or encoding/decoding) may be retried at a later time.
  bool isTransient() => jniAccessors.callMethodWithArgs(
      reference, _id_isTransient, jni.JniType.booleanType, []).boolean;

  static final _id_isRecoverable =
      jniAccessors.getMethodIDOf(_classRef, "isRecoverable", "()Z");

  /// from: public boolean isRecoverable()
  ///
  /// Returns true if the codec cannot proceed further,
  /// but can be recovered by stopping, configuring,
  /// and starting again.
  bool isRecoverable() => jniAccessors.callMethodWithArgs(
      reference, _id_isRecoverable, jni.JniType.booleanType, []).boolean;

  static final _id_getErrorCode =
      jniAccessors.getMethodIDOf(_classRef, "getErrorCode", "()I");

  /// from: public int getErrorCode()
  ///
  /// Retrieve the error code associated with a CodecException
  int getErrorCode() => jniAccessors.callMethodWithArgs(
      reference, _id_getErrorCode, jni.JniType.intType, []).integer;

  static final _id_getDiagnosticInfo = jniAccessors.getMethodIDOf(
      _classRef, "getDiagnosticInfo", "()Ljava/lang/String;");

  /// from: public java.lang.String getDiagnosticInfo()
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// Retrieve a developer-readable diagnostic information string
  /// associated with the exception. Do not show this to end-users,
  /// since this string will not be localized or generally
  /// comprehensible to end-users.
  ///@return This value will never be {@code null}.
  jni.JniString getDiagnosticInfo() =>
      jni.JniString.fromRef(jniAccessors.callMethodWithArgs(
          reference, _id_getDiagnosticInfo, jni.JniType.objectType, []).object);
}

/// from: android.media.MediaCodec$Callback
///
/// MediaCodec callback interface. Used to notify the user asynchronously
/// of various MediaCodec events.
class MediaCodec_Callback extends jni.JniObject {
  static final _classRef =
      jniAccessors.getClassOf("android/media/MediaCodec\$Callback");
  MediaCodec_Callback.fromRef(jni.JObject ref) : super.fromRef(ref);

  static final _id_ctor =
      jniAccessors.getMethodIDOf(_classRef, "<init>", "()V");

  /// from: public void <init>()
  /// The returned object must be deleted after use, by calling the `delete` method.
  MediaCodec_Callback()
      : super.fromRef(
            jniAccessors.newObjectWithArgs(_classRef, _id_ctor, []).object);

  static final _id_onInputBufferAvailable = jniAccessors.getMethodIDOf(
      _classRef, "onInputBufferAvailable", "(Landroid/media/MediaCodec;I)V");

  /// from: public abstract void onInputBufferAvailable(android.media.MediaCodec codec, int index)
  ///
  /// Called when an input buffer becomes available.
  ///@param codec The MediaCodec object.
  /// This value must never be {@code null}.
  ///@param index The index of the available input buffer.
  void onInputBufferAvailable(MediaCodec codec, int index) =>
      jniAccessors.callMethodWithArgs(reference, _id_onInputBufferAvailable,
          jni.JniType.voidType, [codec.reference, index]).check();

  static final _id_onOutputBufferAvailable = jniAccessors.getMethodIDOf(
      _classRef,
      "onOutputBufferAvailable",
      "(Landroid/media/MediaCodec;ILandroid/media/MediaCodec\$BufferInfo;)V");

  /// from: public abstract void onOutputBufferAvailable(android.media.MediaCodec codec, int index, android.media.MediaCodec.BufferInfo info)
  ///
  /// Called when an output buffer becomes available.
  ///@param codec The MediaCodec object.
  /// This value must never be {@code null}.
  ///@param index The index of the available output buffer.
  ///@param info Info regarding the available output buffer MediaCodec.BufferInfo.
  ///
  /// This value must never be {@code null}.
  void onOutputBufferAvailable(
          MediaCodec codec, int index, MediaCodec_BufferInfo info) =>
      jniAccessors.callMethodWithArgs(
          reference,
          _id_onOutputBufferAvailable,
          jni.JniType.voidType,
          [codec.reference, index, info.reference]).check();

  static final _id_onError = jniAccessors.getMethodIDOf(_classRef, "onError",
      "(Landroid/media/MediaCodec;Landroid/media/MediaCodec\$CodecException;)V");

  /// from: public abstract void onError(android.media.MediaCodec codec, android.media.MediaCodec.CodecException e)
  ///
  /// Called when the MediaCodec encountered an error
  ///@param codec The MediaCodec object.
  /// This value must never be {@code null}.
  ///@param e The MediaCodec.CodecException object describing the error.
  ///
  /// This value must never be {@code null}.
  void onError(MediaCodec codec, MediaCodec_CodecException e) =>
      jniAccessors.callMethodWithArgs(reference, _id_onError,
          jni.JniType.voidType, [codec.reference, e.reference]).check();

  static final _id_onOutputFormatChanged = jniAccessors.getMethodIDOf(
      _classRef,
      "onOutputFormatChanged",
      "(Landroid/media/MediaCodec;Landroid/media/MediaFormat;)V");

  /// from: public abstract void onOutputFormatChanged(android.media.MediaCodec codec, android.media.MediaFormat format)
  ///
  /// Called when the output format has changed
  ///@param codec The MediaCodec object.
  /// This value must never be {@code null}.
  ///@param format The new output format.
  ///
  /// This value must never be {@code null}.
  void onOutputFormatChanged(
          MediaCodec codec, mediaformat_.MediaFormat format) =>
      jniAccessors.callMethodWithArgs(reference, _id_onOutputFormatChanged,
          jni.JniType.voidType, [codec.reference, format.reference]).check();
}

/// from: android.media.MediaCodec$BufferInfo
///
/// Per buffer metadata includes an offset and size specifying
/// the range of valid data in the associated codec (output) buffer.
class MediaCodec_BufferInfo extends jni.JniObject {
  static final _classRef =
      jniAccessors.getClassOf("android/media/MediaCodec\$BufferInfo");
  MediaCodec_BufferInfo.fromRef(jni.JObject ref) : super.fromRef(ref);

  static final _id_flags = jniAccessors.getFieldIDOf(_classRef, "flags", "I");

  /// from: public int flags
  ///
  /// Buffer flags associated with the buffer.  A combination of
  /// \#BUFFER_FLAG_KEY_FRAME and \#BUFFER_FLAG_END_OF_STREAM.
  ///
  /// Encoded buffers that are key frames are marked with
  /// \#BUFFER_FLAG_KEY_FRAME.
  ///
  /// The last output buffer corresponding to the input buffer
  /// marked with \#BUFFER_FLAG_END_OF_STREAM will also be marked
  /// with \#BUFFER_FLAG_END_OF_STREAM. In some cases this could
  /// be an empty buffer, whose sole purpose is to carry the end-of-stream
  /// marker.
  ///
  /// Value is either <code>0</code> or a combination of android.media.MediaCodec\#BUFFER_FLAG_SYNC_FRAME, android.media.MediaCodec\#BUFFER_FLAG_KEY_FRAME, android.media.MediaCodec\#BUFFER_FLAG_CODEC_CONFIG, android.media.MediaCodec\#BUFFER_FLAG_END_OF_STREAM, android.media.MediaCodec\#BUFFER_FLAG_PARTIAL_FRAME, and android.media.MediaCodec.BUFFER_FLAG_MUXER_DATA
  int get flags =>
      jniAccessors.getField(reference, _id_flags, jni.JniType.intType).integer;

  /// from: public int flags
  ///
  /// Buffer flags associated with the buffer.  A combination of
  /// \#BUFFER_FLAG_KEY_FRAME and \#BUFFER_FLAG_END_OF_STREAM.
  ///
  /// Encoded buffers that are key frames are marked with
  /// \#BUFFER_FLAG_KEY_FRAME.
  ///
  /// The last output buffer corresponding to the input buffer
  /// marked with \#BUFFER_FLAG_END_OF_STREAM will also be marked
  /// with \#BUFFER_FLAG_END_OF_STREAM. In some cases this could
  /// be an empty buffer, whose sole purpose is to carry the end-of-stream
  /// marker.
  ///
  /// Value is either <code>0</code> or a combination of android.media.MediaCodec\#BUFFER_FLAG_SYNC_FRAME, android.media.MediaCodec\#BUFFER_FLAG_KEY_FRAME, android.media.MediaCodec\#BUFFER_FLAG_CODEC_CONFIG, android.media.MediaCodec\#BUFFER_FLAG_END_OF_STREAM, android.media.MediaCodec\#BUFFER_FLAG_PARTIAL_FRAME, and android.media.MediaCodec.BUFFER_FLAG_MUXER_DATA
  set flags(int value) => jniEnv.SetIntField(reference, _id_flags, value);

  static final _id_offset = jniAccessors.getFieldIDOf(_classRef, "offset", "I");

  /// from: public int offset
  ///
  /// The start-offset of the data in the buffer.
  int get offset =>
      jniAccessors.getField(reference, _id_offset, jni.JniType.intType).integer;

  /// from: public int offset
  ///
  /// The start-offset of the data in the buffer.
  set offset(int value) => jniEnv.SetIntField(reference, _id_offset, value);

  static final _id_presentationTimeUs =
      jniAccessors.getFieldIDOf(_classRef, "presentationTimeUs", "J");

  /// from: public long presentationTimeUs
  ///
  /// The presentation timestamp in microseconds for the buffer.
  /// This is derived from the presentation timestamp passed in
  /// with the corresponding input buffer.  This should be ignored for
  /// a 0-sized buffer.
  int get presentationTimeUs => jniAccessors
      .getField(reference, _id_presentationTimeUs, jni.JniType.longType)
      .long;

  /// from: public long presentationTimeUs
  ///
  /// The presentation timestamp in microseconds for the buffer.
  /// This is derived from the presentation timestamp passed in
  /// with the corresponding input buffer.  This should be ignored for
  /// a 0-sized buffer.
  set presentationTimeUs(int value) =>
      jniEnv.SetLongField(reference, _id_presentationTimeUs, value);

  static final _id_size = jniAccessors.getFieldIDOf(_classRef, "size", "I");

  /// from: public int size
  ///
  /// The amount of data (in bytes) in the buffer.  If this is {@code 0},
  /// the buffer has no data in it and can be discarded.  The only
  /// use of a 0-size buffer is to carry the end-of-stream marker.
  int get size =>
      jniAccessors.getField(reference, _id_size, jni.JniType.intType).integer;

  /// from: public int size
  ///
  /// The amount of data (in bytes) in the buffer.  If this is {@code 0},
  /// the buffer has no data in it and can be discarded.  The only
  /// use of a 0-size buffer is to carry the end-of-stream marker.
  set size(int value) => jniEnv.SetIntField(reference, _id_size, value);

  static final _id_ctor =
      jniAccessors.getMethodIDOf(_classRef, "<init>", "()V");

  /// from: public void <init>()
  /// The returned object must be deleted after use, by calling the `delete` method.
  MediaCodec_BufferInfo()
      : super.fromRef(
            jniAccessors.newObjectWithArgs(_classRef, _id_ctor, []).object);

  static final _id_set0 =
      jniAccessors.getMethodIDOf(_classRef, "set", "(IIJI)V");

  /// from: public void set(int newOffset, int newSize, long newTimeUs, int newFlags)
  ///
  /// Update the buffer metadata information.
  ///@param newOffset the start-offset of the data in the buffer.
  ///@param newSize the amount of data (in bytes) in the buffer.
  ///@param newTimeUs the presentation timestamp in microseconds.
  ///@param newFlags buffer flags associated with the buffer.  This
  /// should be a combination of  \#BUFFER_FLAG_KEY_FRAME and
  /// \#BUFFER_FLAG_END_OF_STREAM.
  ///
  /// Value is either <code>0</code> or a combination of android.media.MediaCodec\#BUFFER_FLAG_SYNC_FRAME, android.media.MediaCodec\#BUFFER_FLAG_KEY_FRAME, android.media.MediaCodec\#BUFFER_FLAG_CODEC_CONFIG, android.media.MediaCodec\#BUFFER_FLAG_END_OF_STREAM, android.media.MediaCodec\#BUFFER_FLAG_PARTIAL_FRAME, and android.media.MediaCodec.BUFFER_FLAG_MUXER_DATA
  void set0(int newOffset, int newSize, int newTimeUs, int newFlags) =>
      jniAccessors.callMethodWithArgs(reference, _id_set0, jni.JniType.voidType,
          [newOffset, newSize, newTimeUs, newFlags]).check();
}
