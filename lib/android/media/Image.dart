// Autogenerated by jnigen. DO NOT EDIT!

// ignore_for_file: annotate_overrides
// ignore_for_file: camel_case_types
// ignore_for_file: constant_identifier_names
// ignore_for_file: file_names
// ignore_for_file: no_leading_underscores_for_local_identifiers
// ignore_for_file: non_constant_identifier_names
// ignore_for_file: unused_element
// ignore_for_file: unused_field
// ignore_for_file: unused_import
// ignore_for_file: unused_shown_name

import "package:jni/jni.dart" as jni;

import "package:jni/internal_helpers_for_jnigen.dart";

import "../hardware/HardwareBuffer.dart" as hardwarebuffer_;

import "../graphics/Rect.dart" as rect_;
import "../../_init.dart" show jniEnv, jniAccessors;

/// from: android.media.Image
///
/// A single complete image buffer to use with a media source such as a
/// MediaCodec or a
/// android.hardware.camera2.CameraDevice CameraDevice.
///
///
/// This class allows for efficient direct application access to the pixel
/// data of the Image through one or more
/// java.nio.ByteBuffer ByteBuffers. Each buffer is encapsulated in a
/// Plane that describes the layout of the pixel data in that plane. Due
/// to this direct access, and unlike the android.graphics.Bitmap Bitmap class,
/// Images are not directly usable as UI resources.
///
///
/// Since Images are often directly produced or consumed by hardware
/// components, they are a limited resource shared across the system, and should
/// be closed as soon as they are no longer needed.
///
///
/// For example, when using the ImageReader class to read out Images
/// from various media sources, not closing old Image objects will prevent the
/// availability of new Images once
/// ImageReader\#getMaxImages the maximum outstanding image count is
/// reached. When this happens, the function acquiring new Images will typically
/// throw an IllegalStateException.
///
///@see ImageReader
class Image extends jni.JniObject {
  static final _classRef = jniAccessors.getClassOf("android/media/Image");
  Image.fromRef(jni.JObject ref) : super.fromRef(ref);

  static final _id_getFormat =
      jniAccessors.getMethodIDOf(_classRef, "getFormat", "()I");

  /// from: public abstract int getFormat()
  ///
  /// Get the format for this image. This format determines the number of
  /// ByteBuffers needed to represent the image, and the general layout of the
  /// pixel data in each in ByteBuffer.
  ///
  ///
  /// The format is one of the values from
  /// android.graphics.ImageFormat ImageFormat. The mapping between the
  /// formats and the planes is as follows:
  ///
  ///
  ///
  /// <table>
  /// <tr>
  ///   <th>Format</th>
  ///   <th>Plane count</th>
  ///   <th>Layout details</th>
  /// </tr>
  /// <tr>
  ///   <td>android.graphics.ImageFormat\#JPEG JPEG</td>
  ///   <td>1</td>
  ///   <td>Compressed data, so row and pixel strides are 0. To uncompress, use
  ///      android.graphics.BitmapFactory\#decodeByteArray BitmapFactory\#decodeByteArray.
  ///   </td>
  /// </tr>
  /// <tr>
  ///   <td>android.graphics.ImageFormat\#YUV_420_888 YUV_420_888</td>
  ///   <td>3</td>
  ///   <td>A luminance plane followed by the Cb and Cr chroma planes.
  ///     The chroma planes have half the width and height of the luminance
  ///     plane (4:2:0 subsampling). Each pixel sample in each plane has 8 bits.
  ///     Each plane has its own row stride and pixel stride.</td>
  /// </tr>
  /// <tr>
  ///   <td>android.graphics.ImageFormat\#YUV_422_888 YUV_422_888</td>
  ///   <td>3</td>
  ///   <td>A luminance plane followed by the Cb and Cr chroma planes.
  ///     The chroma planes have half the width and the full height of the luminance
  ///     plane (4:2:2 subsampling). Each pixel sample in each plane has 8 bits.
  ///     Each plane has its own row stride and pixel stride.</td>
  /// </tr>
  /// <tr>
  ///   <td>android.graphics.ImageFormat\#YUV_444_888 YUV_444_888</td>
  ///   <td>3</td>
  ///   <td>A luminance plane followed by the Cb and Cr chroma planes.
  ///     The chroma planes have the same width and height as that of the luminance
  ///     plane (4:4:4 subsampling). Each pixel sample in each plane has 8 bits.
  ///     Each plane has its own row stride and pixel stride.</td>
  /// </tr>
  /// <tr>
  ///   <td>android.graphics.ImageFormat\#FLEX_RGB_888 FLEX_RGB_888</td>
  ///   <td>3</td>
  ///   <td>A R (red) plane followed by the G (green) and B (blue) planes.
  ///     All planes have the same widths and heights.
  ///     Each pixel sample in each plane has 8 bits.
  ///     Each plane has its own row stride and pixel stride.</td>
  /// </tr>
  /// <tr>
  ///   <td>android.graphics.ImageFormat\#FLEX_RGBA_8888 FLEX_RGBA_8888</td>
  ///   <td>4</td>
  ///   <td>A R (red) plane followed by the G (green), B (blue), and
  ///     A (alpha) planes. All planes have the same widths and heights.
  ///     Each pixel sample in each plane has 8 bits.
  ///     Each plane has its own row stride and pixel stride.</td>
  /// </tr>
  /// <tr>
  ///   <td>android.graphics.ImageFormat\#RAW_SENSOR RAW_SENSOR</td>
  ///   <td>1</td>
  ///   <td>A single plane of raw sensor image data, with 16 bits per color
  ///     sample. The details of the layout need to be queried from the source of
  ///     the raw sensor data, such as
  ///     android.hardware.camera2.CameraDevice CameraDevice.
  ///   </td>
  /// </tr>
  /// <tr>
  ///   <td>android.graphics.ImageFormat\#RAW_PRIVATE RAW_PRIVATE</td>
  ///   <td>1</td>
  ///   <td>A single plane of raw sensor image data of private layout.
  ///   The details of the layout is implementation specific. Row stride and
  ///   pixel stride are undefined for this format. Calling Plane\#getRowStride()
  ///   or Plane\#getPixelStride() on RAW_PRIVATE image will cause
  ///   UnSupportedOperationException being thrown.
  ///   </td>
  /// </tr>
  /// </table>
  ///@see android.graphics.ImageFormat
  int getFormat() => jniAccessors.callMethodWithArgs(
      reference, _id_getFormat, jni.JniType.intType, []).integer;

  static final _id_getWidth =
      jniAccessors.getMethodIDOf(_classRef, "getWidth", "()I");

  /// from: public abstract int getWidth()
  ///
  /// The width of the image in pixels. For formats where some color channels
  /// are subsampled, this is the width of the largest-resolution plane.
  int getWidth() => jniAccessors.callMethodWithArgs(
      reference, _id_getWidth, jni.JniType.intType, []).integer;

  static final _id_getHeight =
      jniAccessors.getMethodIDOf(_classRef, "getHeight", "()I");

  /// from: public abstract int getHeight()
  ///
  /// The height of the image in pixels. For formats where some color channels
  /// are subsampled, this is the height of the largest-resolution plane.
  int getHeight() => jniAccessors.callMethodWithArgs(
      reference, _id_getHeight, jni.JniType.intType, []).integer;

  static final _id_getTimestamp =
      jniAccessors.getMethodIDOf(_classRef, "getTimestamp", "()J");

  /// from: public abstract long getTimestamp()
  ///
  /// Get the timestamp associated with this frame.
  ///
  /// The timestamp is measured in nanoseconds, and is normally monotonically
  /// increasing. The timestamps for the images from different sources may have
  /// different timebases therefore may not be comparable. The specific meaning and
  /// timebase of the timestamp depend on the source providing images. See
  /// android.hardware.Camera Camera,
  /// android.hardware.camera2.CameraDevice CameraDevice,
  /// MediaPlayer and MediaCodec for more details.
  ///
  ///
  int getTimestamp() => jniAccessors.callMethodWithArgs(
      reference, _id_getTimestamp, jni.JniType.longType, []).long;

  static final _id_getHardwareBuffer = jniAccessors.getMethodIDOf(
      _classRef, "getHardwareBuffer", "()Landroid/hardware/HardwareBuffer;");

  /// from: public android.hardware.HardwareBuffer getHardwareBuffer()
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// Get the android.hardware.HardwareBuffer HardwareBuffer handle of the input image
  /// intended for GPU and/or hardware access.
  ///
  /// The returned android.hardware.HardwareBuffer HardwareBuffer shall not be used
  /// after  Image\#close Image.close() has been called.
  ///
  ///
  ///@return the HardwareBuffer associated with this Image or null if this Image doesn't support
  /// this feature. (Unsupported use cases include Image instances obtained through
  /// android.media.MediaCodec MediaCodec, and on versions prior to Android P,
  /// android.media.ImageWriter ImageWriter).
  hardwarebuffer_.HardwareBuffer getHardwareBuffer() =>
      hardwarebuffer_.HardwareBuffer.fromRef(jniAccessors.callMethodWithArgs(
          reference, _id_getHardwareBuffer, jni.JniType.objectType, []).object);

  static final _id_setTimestamp =
      jniAccessors.getMethodIDOf(_classRef, "setTimestamp", "(J)V");

  /// from: public void setTimestamp(long timestamp)
  ///
  /// Set the timestamp associated with this frame.
  ///
  /// The timestamp is measured in nanoseconds, and is normally monotonically
  /// increasing. The timestamps for the images from different sources may have
  /// different timebases therefore may not be comparable. The specific meaning and
  /// timebase of the timestamp depend on the source providing images. See
  /// android.hardware.Camera Camera,
  /// android.hardware.camera2.CameraDevice CameraDevice,
  /// MediaPlayer and MediaCodec for more details.
  ///
  ///
  ///
  /// For images dequeued from ImageWriter via
  /// ImageWriter\#dequeueInputImage(), it's up to the application to
  /// set the timestamps correctly before sending them back to the
  /// ImageWriter, or the timestamp will be generated automatically when
  /// ImageWriter\#queueInputImage queueInputImage() is called.
  ///
  ///
  ///@param timestamp The timestamp to be set for this image.
  void setTimestamp(int timestamp) => jniAccessors.callMethodWithArgs(
      reference, _id_setTimestamp, jni.JniType.voidType, [timestamp]).check();

  static final _id_getCropRect = jniAccessors.getMethodIDOf(
      _classRef, "getCropRect", "()Landroid/graphics/Rect;");

  /// from: public android.graphics.Rect getCropRect()
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// Get the crop rectangle associated with this frame.
  ///
  /// The crop rectangle specifies the region of valid pixels in the image,
  /// using coordinates in the largest-resolution plane.
  rect_.Rect getCropRect() =>
      rect_.Rect.fromRef(jniAccessors.callMethodWithArgs(
          reference, _id_getCropRect, jni.JniType.objectType, []).object);

  static final _id_setCropRect = jniAccessors.getMethodIDOf(
      _classRef, "setCropRect", "(Landroid/graphics/Rect;)V");

  /// from: public void setCropRect(android.graphics.Rect cropRect)
  ///
  /// Set the crop rectangle associated with this frame.
  ///
  /// The crop rectangle specifies the region of valid pixels in the image,
  /// using coordinates in the largest-resolution plane.
  void setCropRect(rect_.Rect cropRect) => jniAccessors.callMethodWithArgs(
      reference,
      _id_setCropRect,
      jni.JniType.voidType,
      [cropRect.reference]).check();

  static final _id_getPlanes = jniAccessors.getMethodIDOf(
      _classRef, "getPlanes", "()[Landroid/media/Image\$Plane;");

  /// from: public abstract android.media.Image.Plane[] getPlanes()
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// Get the array of pixel planes for this Image. The number of planes is
  /// determined by the format of the Image. The application will get an empty
  /// array if the image format is android.graphics.ImageFormat\#PRIVATE PRIVATE, because the image pixel data is not directly accessible. The
  /// application can check the image format by calling
  /// Image\#getFormat().
  jni.JniObject getPlanes() =>
      jni.JniObject.fromRef(jniAccessors.callMethodWithArgs(
          reference, _id_getPlanes, jni.JniType.objectType, []).object);

  static final _id_close =
      jniAccessors.getMethodIDOf(_classRef, "close", "()V");

  /// from: public abstract void close()
  ///
  /// Free up this frame for reuse.
  ///
  /// After calling this method, calling any methods on this {@code Image} will
  /// result in an IllegalStateException, and attempting to read from
  /// or write to ByteBuffer ByteBuffers returned by an earlier
  /// Plane\#getBuffer call will have undefined behavior. If the image
  /// was obtained from ImageWriter via
  /// ImageWriter\#dequeueInputImage(), after calling this method, any
  /// image data filled by the application will be lost and the image will be
  /// returned to ImageWriter for reuse. Images given to
  /// ImageWriter\#queueInputImage queueInputImage() are automatically
  /// closed.
  ///
  ///
  void close() => jniAccessors.callMethodWithArgs(
      reference, _id_close, jni.JniType.voidType, []).check();
}

/// from: android.media.Image$Plane
///
/// A single color plane of image data.
///
///
/// The number and meaning of the planes in an Image are determined by the
/// format of the Image.
///
///
/// Once the Image has been closed, any access to the the plane's
/// ByteBuffer will fail.
///
///@see \#getFormat
class Image_Plane extends jni.JniObject {
  static final _classRef =
      jniAccessors.getClassOf("android/media/Image\$Plane");
  Image_Plane.fromRef(jni.JObject ref) : super.fromRef(ref);

  static final _id_getRowStride =
      jniAccessors.getMethodIDOf(_classRef, "getRowStride", "()I");

  /// from: public abstract int getRowStride()
  ///
  /// The row stride for this color plane, in bytes.
  ///
  ///
  /// This is the distance between the start of two consecutive rows of
  /// pixels in the image. Note that row stried is undefined for some formats
  /// such as
  /// android.graphics.ImageFormat\#RAW_PRIVATE RAW_PRIVATE,
  /// and calling getRowStride on images of these formats will
  /// cause an UnsupportedOperationException being thrown.
  /// For formats where row stride is well defined, the row stride
  /// is always greater than 0.
  ///
  int getRowStride() => jniAccessors.callMethodWithArgs(
      reference, _id_getRowStride, jni.JniType.intType, []).integer;

  static final _id_getPixelStride =
      jniAccessors.getMethodIDOf(_classRef, "getPixelStride", "()I");

  /// from: public abstract int getPixelStride()
  ///
  /// The distance between adjacent pixel samples, in bytes.
  ///
  ///
  /// This is the distance between two consecutive pixel values in a row
  /// of pixels. It may be larger than the size of a single pixel to
  /// account for interleaved image data or padded formats.
  /// Note that pixel stride is undefined for some formats such as
  /// android.graphics.ImageFormat\#RAW_PRIVATE RAW_PRIVATE,
  /// and calling getPixelStride on images of these formats will
  /// cause an UnsupportedOperationException being thrown.
  /// For formats where pixel stride is well defined, the pixel stride
  /// is always greater than 0.
  ///
  int getPixelStride() => jniAccessors.callMethodWithArgs(
      reference, _id_getPixelStride, jni.JniType.intType, []).integer;

  static final _id_getBuffer = jniAccessors.getMethodIDOf(
      _classRef, "getBuffer", "()Ljava/nio/ByteBuffer;");

  /// from: public abstract java.nio.ByteBuffer getBuffer()
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// Get a direct java.nio.ByteBuffer ByteBuffer
  /// containing the frame data.
  ///
  ///
  /// In particular, the buffer returned will always have
  /// java.nio.ByteBuffer\#isDirect isDirect return {@code true}, so
  /// the underlying data could be mapped as a pointer in JNI without doing
  /// any copies with {@code GetDirectBufferAddress}.
  ///
  ///
  /// For raw formats, each plane is only guaranteed to contain data
  /// up to the last pixel in the last row. In other words, the stride
  /// after the last row may not be mapped into the buffer. This is a
  /// necessary requirement for any interleaved format.
  ///
  ///@return the byte buffer containing the image data for this plane.
  jni.JniObject getBuffer() =>
      jni.JniObject.fromRef(jniAccessors.callMethodWithArgs(
          reference, _id_getBuffer, jni.JniType.objectType, []).object);
}
