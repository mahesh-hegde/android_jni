// Autogenerated by jnigen. DO NOT EDIT!

// ignore_for_file: camel_case_types
// ignore_for_file: file_names
// ignore_for_file: non_constant_identifier_names
// ignore_for_file: constant_identifier_names
// ignore_for_file: unused_shown_name
// ignore_for_file: annotate_overrides
// ignore_for_file: no_leading_underscores_for_local_identifiers
// ignore_for_file: unused_import
// ignore_for_file: unused_element
// ignore_for_file: unused_field

import "package:jni/jni.dart" as jni;

import "package:jni/internal_helpers_for_jnigen.dart";

import "../os/Handler.dart" as handler_;

import "../view/Surface.dart" as surface_;

import "AudioTrack.dart" as audiotrack_;

import "PlaybackParams.dart" as playbackparams_;

import "SyncParams.dart" as syncparams_;

import "MediaTimestamp.dart" as mediatimestamp_;
import "../../_init.dart" show jniEnv, jniAccessors;

/// from: android.media.MediaSync
///
/// MediaSync class can be used to synchronously play audio and video streams.
/// It can be used to play audio-only or video-only stream, too.
///
/// MediaSync is generally used like this:
/// <pre>
/// MediaSync sync = new MediaSync();
/// sync.setSurface(surface);
/// Surface inputSurface = sync.createInputSurface();
/// ...
/// // MediaCodec videoDecoder = ...;
/// videoDecoder.configure(format, inputSurface, ...);
/// ...
/// sync.setAudioTrack(audioTrack);
/// sync.setCallback(new MediaSync.Callback() {
///     {@literal @Override}
///     public void onAudioBufferConsumed(MediaSync sync, ByteBuffer audioBuffer, int bufferId) {
///         ...
///     }
/// }, null);
/// // This needs to be done since sync is paused on creation.
/// sync.setPlaybackParams(new PlaybackParams().setSpeed(1.f));
///
/// for (;;) {
///   ...
///   // send video frames to surface for rendering, e.g., call
///   // videoDecoder.releaseOutputBuffer(videoOutputBufferIx, videoPresentationTimeNs);
///   // More details are available as below.
///   ...
///   sync.queueAudio(audioByteBuffer, bufferId, audioPresentationTimeUs); // non-blocking.
///   // The audioByteBuffer and bufferId will be returned via callback.
///   // More details are available as below.
///   ...
///     ...
/// }
/// sync.setPlaybackParams(new PlaybackParams().setSpeed(0.f));
/// sync.release();
/// sync = null;
///
/// // The following code snippet illustrates how video/audio raw frames are created by
/// // MediaCodec's, how they are fed to MediaSync and how they are returned by MediaSync.
/// // This is the callback from MediaCodec.
/// onOutputBufferAvailable(MediaCodec codec, int bufferId, BufferInfo info) {
///     // ...
///     if (codec == videoDecoder) {
///         // surface timestamp must contain media presentation time in nanoseconds.
///         codec.releaseOutputBuffer(bufferId, 1000 * info.presentationTime);
///     } else {
///         ByteBuffer audioByteBuffer = codec.getOutputBuffer(bufferId);
///         sync.queueAudio(audioByteBuffer, bufferId, info.presentationTime);
///     }
///     // ...
/// }
///
/// // This is the callback from MediaSync.
/// onAudioBufferConsumed(MediaSync sync, ByteBuffer buffer, int bufferId) {
///     // ...
///     audioDecoder.releaseBuffer(bufferId, false);
///     // ...
/// }
///
/// </pre>
///
/// The client needs to configure corresponding sink by setting the Surface and/or AudioTrack
/// based on the stream type it will play.
///
/// For video, the client needs to call \#createInputSurface to obtain a surface on
/// which it will render video frames.
///
/// For audio, the client needs to set up audio track correctly, e.g., using AudioTrack\#MODE_STREAM. The audio buffers are sent to MediaSync directly via \#queueAudio, and are returned to the client via Callback\#onAudioBufferConsumed
/// asynchronously. The client should not modify an audio buffer till it's returned.
///
/// The client can optionally pre-fill audio/video buffers by setting playback rate to 0.0,
/// and then feed audio/video buffers to corresponding components. This can reduce possible
/// initial underrun.
///
class MediaSync extends jni.JniObject {
  static final _classRef = jniAccessors.getClassOf("android/media/MediaSync");
  MediaSync.fromRef(jni.JObject ref) : super.fromRef(ref);

  /// from: static public final int MEDIASYNC_ERROR_AUDIOTRACK_FAIL
  ///
  /// Audio track failed.
  ///@see android.media.MediaSync.OnErrorListener
  static const MEDIASYNC_ERROR_AUDIOTRACK_FAIL = 1;

  /// from: static public final int MEDIASYNC_ERROR_SURFACE_FAIL
  ///
  /// The surface failed to handle video buffers.
  ///@see android.media.MediaSync.OnErrorListener
  static const MEDIASYNC_ERROR_SURFACE_FAIL = 2;

  static final _id_ctor =
      jniAccessors.getMethodIDOf(_classRef, "<init>", "()V");

  /// from: public void <init>()
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// Class constructor. On creation, MediaSync is paused, i.e., playback rate is 0.0f.
  MediaSync()
      : super.fromRef(
            jniAccessors.newObjectWithArgs(_classRef, _id_ctor, []).object);

  static final _id_finalize =
      jniAccessors.getMethodIDOf(_classRef, "finalize", "()V");

  /// from: protected void finalize()
  void finalize() => jniAccessors.callMethodWithArgs(
      reference, _id_finalize, jni.JniType.voidType, []).check();

  static final _id_release =
      jniAccessors.getMethodIDOf(_classRef, "release", "()V");

  /// from: public void release()
  ///
  /// Make sure you call this when you're done to free up any opened
  /// component instance instead of relying on the garbage collector
  /// to do this for you at some point in the future.
  void release() => jniAccessors.callMethodWithArgs(
      reference, _id_release, jni.JniType.voidType, []).check();

  static final _id_setCallback = jniAccessors.getMethodIDOf(
      _classRef,
      "setCallback",
      "(Landroid/media/MediaSync\$Callback;Landroid/os/Handler;)V");

  /// from: public void setCallback(android.media.MediaSync.Callback cb, android.os.Handler handler)
  ///
  /// Sets an asynchronous callback for actionable MediaSync events.
  ///
  /// This method can be called multiple times to update a previously set callback. If the
  /// handler is changed, undelivered notifications scheduled for the old handler may be dropped.
  ///
  /// __Do not call this inside callback.__
  ///@param cb The callback that will run. Use {@code null} to stop receiving callbacks.
  /// This value may be {@code null}.
  ///@param handler The Handler that will run the callback. Use {@code null} to use MediaSync's
  ///     internal handler if it exists.
  ///
  /// This value may be {@code null}.
  void setCallback(MediaSync_Callback cb, handler_.Handler handler) =>
      jniAccessors.callMethodWithArgs(reference, _id_setCallback,
          jni.JniType.voidType, [cb.reference, handler.reference]).check();

  static final _id_setOnErrorListener = jniAccessors.getMethodIDOf(
      _classRef,
      "setOnErrorListener",
      "(Landroid/media/MediaSync\$OnErrorListener;Landroid/os/Handler;)V");

  /// from: public void setOnErrorListener(android.media.MediaSync.OnErrorListener listener, android.os.Handler handler)
  ///
  /// Sets an asynchronous callback for error events.
  ///
  /// This method can be called multiple times to update a previously set listener. If the
  /// handler is changed, undelivered notifications scheduled for the old handler may be dropped.
  ///
  /// __Do not call this inside callback.__
  ///@param listener The callback that will run. Use {@code null} to stop receiving callbacks.
  /// This value may be {@code null}.
  ///@param handler The Handler that will run the callback. Use {@code null} to use MediaSync's
  ///     internal handler if it exists.
  ///
  /// This value may be {@code null}.
  void setOnErrorListener(
          MediaSync_OnErrorListener listener, handler_.Handler handler) =>
      jniAccessors.callMethodWithArgs(
          reference,
          _id_setOnErrorListener,
          jni.JniType.voidType,
          [listener.reference, handler.reference]).check();

  static final _id_setSurface = jniAccessors.getMethodIDOf(
      _classRef, "setSurface", "(Landroid/view/Surface;)V");

  /// from: public void setSurface(android.view.Surface surface)
  ///
  /// Sets the output surface for MediaSync.
  ///
  /// Currently, this is only supported in the Initialized state.
  ///@param surface Specify a surface on which to render the video data.
  /// This value may be {@code null}.
  ///@throws IllegalArgumentException if the surface has been released, is invalid,
  ///     or can not be connected.
  ///@throws IllegalStateException if setting the surface is not supported, e.g.
  ///     not in the Initialized state, or another surface has already been set.
  void setSurface(surface_.Surface surface) => jniAccessors.callMethodWithArgs(
      reference,
      _id_setSurface,
      jni.JniType.voidType,
      [surface.reference]).check();

  static final _id_setAudioTrack = jniAccessors.getMethodIDOf(
      _classRef, "setAudioTrack", "(Landroid/media/AudioTrack;)V");

  /// from: public void setAudioTrack(android.media.AudioTrack audioTrack)
  ///
  /// Sets the audio track for MediaSync.
  ///
  /// Currently, this is only supported in the Initialized state.
  ///@param audioTrack Specify an AudioTrack through which to render the audio data.
  /// This value may be {@code null}.
  ///@throws IllegalArgumentException if the audioTrack has been released, or is invalid.
  ///@throws IllegalStateException if setting the audio track is not supported, e.g.
  ///     not in the Initialized state, or another audio track has already been set.
  void setAudioTrack(audiotrack_.AudioTrack audioTrack) =>
      jniAccessors.callMethodWithArgs(reference, _id_setAudioTrack,
          jni.JniType.voidType, [audioTrack.reference]).check();

  static final _id_createInputSurface = jniAccessors.getMethodIDOf(
      _classRef, "createInputSurface", "()Landroid/view/Surface;");

  /// from: public native android.view.Surface createInputSurface()
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// Requests a Surface to use as the input. This may only be called after
  /// \#setSurface.
  ///
  /// The application is responsible for calling release() on the Surface when
  /// done.
  ///@throws IllegalStateException if not set, or another input surface has
  ///     already been created.
  ///@return This value will never be {@code null}.
  surface_.Surface createInputSurface() =>
      surface_.Surface.fromRef(jniAccessors.callMethodWithArgs(reference,
          _id_createInputSurface, jni.JniType.objectType, []).object);

  static final _id_setPlaybackParams = jniAccessors.getMethodIDOf(
      _classRef, "setPlaybackParams", "(Landroid/media/PlaybackParams;)V");

  /// from: public void setPlaybackParams(android.media.PlaybackParams params)
  ///
  /// Sets playback rate using PlaybackParams.
  ///
  /// When using MediaSync with AudioTrack, set playback params using this
  /// call instead of calling it directly on the track, so that the sync is aware of
  /// the params change.
  ///
  /// This call also works if there is no audio track.
  ///@param params the playback params to use. PlaybackParams\#getSpeed Speed is the ratio between desired playback rate and normal one. 1.0 means
  ///     normal playback speed. 0.0 means pause. Value larger than 1.0 means faster playback,
  ///     while value between 0.0 and 1.0 for slower playback. __Note:__ the normal rate
  ///     does not change as a result of this call. To restore the original rate at any time,
  ///     use speed of 1.0.
  ///
  /// This value must never be {@code null}.
  ///@throws IllegalStateException if the internal sync engine or the audio track has not
  ///     been initialized.
  ///@throws IllegalArgumentException if the params are not supported.
  void setPlaybackParams(playbackparams_.PlaybackParams params) =>
      jniAccessors.callMethodWithArgs(reference, _id_setPlaybackParams,
          jni.JniType.voidType, [params.reference]).check();

  static final _id_getPlaybackParams = jniAccessors.getMethodIDOf(
      _classRef, "getPlaybackParams", "()Landroid/media/PlaybackParams;");

  /// from: public native android.media.PlaybackParams getPlaybackParams()
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// Gets the playback rate using PlaybackParams.
  ///@return the playback rate being used.
  ///
  /// This value will never be {@code null}.
  ///@throws IllegalStateException if the internal sync engine or the audio track has not
  ///     been initialized.
  playbackparams_.PlaybackParams getPlaybackParams() =>
      playbackparams_.PlaybackParams.fromRef(jniAccessors.callMethodWithArgs(
          reference, _id_getPlaybackParams, jni.JniType.objectType, []).object);

  static final _id_setSyncParams = jniAccessors.getMethodIDOf(
      _classRef, "setSyncParams", "(Landroid/media/SyncParams;)V");

  /// from: public void setSyncParams(android.media.SyncParams params)
  ///
  /// Sets A/V sync mode.
  ///@param params the A/V sync params to apply
  ///
  /// This value must never be {@code null}.
  ///@throws IllegalStateException if the internal player engine has not been
  /// initialized.
  ///@throws IllegalArgumentException if params are not supported.
  void setSyncParams(syncparams_.SyncParams params) =>
      jniAccessors.callMethodWithArgs(reference, _id_setSyncParams,
          jni.JniType.voidType, [params.reference]).check();

  static final _id_getSyncParams = jniAccessors.getMethodIDOf(
      _classRef, "getSyncParams", "()Landroid/media/SyncParams;");

  /// from: public native android.media.SyncParams getSyncParams()
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// Gets the A/V sync mode.
  ///@return the A/V sync params
  ///
  /// This value will never be {@code null}.
  ///@throws IllegalStateException if the internal player engine has not been
  /// initialized.
  syncparams_.SyncParams getSyncParams() =>
      syncparams_.SyncParams.fromRef(jniAccessors.callMethodWithArgs(
          reference, _id_getSyncParams, jni.JniType.objectType, []).object);

  static final _id_flush =
      jniAccessors.getMethodIDOf(_classRef, "flush", "()V");

  /// from: public void flush()
  ///
  /// Flushes all buffers from the sync object.
  ///
  /// All pending unprocessed audio and video buffers are discarded. If an audio track was
  /// configured, it is flushed and stopped. If a video output surface was configured, the
  /// last frame queued to it is left on the frame. Queue a blank video frame to clear the
  /// surface,
  ///
  /// No callbacks are received for the flushed buffers.
  ///@throws IllegalStateException if the internal player engine has not been
  /// initialized.
  void flush() => jniAccessors.callMethodWithArgs(
      reference, _id_flush, jni.JniType.voidType, []).check();

  static final _id_getTimestamp = jniAccessors.getMethodIDOf(
      _classRef, "getTimestamp", "()Landroid/media/MediaTimestamp;");

  /// from: public android.media.MediaTimestamp getTimestamp()
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// Get current playback position.
  ///
  /// The MediaTimestamp represents how the media time correlates to the system time in
  /// a linear fashion using an anchor and a clock rate. During regular playback, the media
  /// time moves fairly constantly (though the anchor frame may be rebased to a current
  /// system time, the linear correlation stays steady). Therefore, this method does not
  /// need to be called often.
  ///
  /// To help users get current playback position, this method always anchors the timestamp
  /// to the current System\#nanoTime system time, so
  /// MediaTimestamp\#getAnchorMediaTimeUs can be used as current playback position.
  ///@return a MediaTimestamp object if a timestamp is available, or {@code null} if no timestamp
  ///         is available, e.g. because the media player has not been initialized.
  ///@see MediaTimestamp
  mediatimestamp_.MediaTimestamp getTimestamp() =>
      mediatimestamp_.MediaTimestamp.fromRef(jniAccessors.callMethodWithArgs(
          reference, _id_getTimestamp, jni.JniType.objectType, []).object);

  static final _id_queueAudio = jniAccessors.getMethodIDOf(
      _classRef, "queueAudio", "(Ljava/nio/ByteBuffer;IJ)V");

  /// from: public void queueAudio(java.nio.ByteBuffer audioData, int bufferId, long presentationTimeUs)
  ///
  /// Queues the audio data asynchronously for playback (AudioTrack must be in streaming mode).
  /// If the audio track was flushed as a result of \#flush, it will be restarted.
  ///@param audioData the buffer that holds the data to play. This buffer will be returned
  ///     to the client via registered callback.
  /// This value must never be {@code null}.
  ///@param bufferId an integer used to identify audioData. It will be returned to
  ///     the client along with audioData. This helps applications to keep track of audioData,
  ///     e.g., it can be used to store the output buffer index used by the audio codec.
  ///@param presentationTimeUs the presentation timestamp in microseconds for the first frame
  ///     in the buffer.
  ///@throws IllegalStateException if audio track is not set or internal configureation
  ///     has not been done correctly.
  void queueAudio(
          jni.JniObject audioData, int bufferId, int presentationTimeUs) =>
      jniAccessors.callMethodWithArgs(
          reference,
          _id_queueAudio,
          jni.JniType.voidType,
          [audioData.reference, bufferId, presentationTimeUs]).check();
}

/// from: android.media.MediaSync$OnErrorListener
///
/// Interface definition of a callback to be invoked when there
/// has been an error during an asynchronous operation (other errors
/// will throw exceptions at method call time).
class MediaSync_OnErrorListener extends jni.JniObject {
  static final _classRef =
      jniAccessors.getClassOf("android/media/MediaSync\$OnErrorListener");
  MediaSync_OnErrorListener.fromRef(jni.JObject ref) : super.fromRef(ref);

  static final _id_onError = jniAccessors.getMethodIDOf(
      _classRef, "onError", "(Landroid/media/MediaSync;II)V");

  /// from: public abstract void onError(android.media.MediaSync sync, int what, int extra)
  ///
  /// Called to indicate an error.
  ///@param sync The MediaSync the error pertains to
  /// This value must never be {@code null}.
  ///@param what The type of error that has occurred:
  /// <ul>
  /// <li>\#MEDIASYNC_ERROR_AUDIOTRACK_FAIL
  /// <li>\#MEDIASYNC_ERROR_SURFACE_FAIL
  /// </ul>
  ///@param extra an extra code, specific to the error. Typically
  /// implementation dependent.
  void onError(MediaSync sync0, int what, int extra) =>
      jniAccessors.callMethodWithArgs(reference, _id_onError,
          jni.JniType.voidType, [sync0.reference, what, extra]).check();
}

/// from: android.media.MediaSync$Callback
///
/// MediaSync callback interface. Used to notify the user asynchronously
/// of various MediaSync events.
class MediaSync_Callback extends jni.JniObject {
  static final _classRef =
      jniAccessors.getClassOf("android/media/MediaSync\$Callback");
  MediaSync_Callback.fromRef(jni.JObject ref) : super.fromRef(ref);

  static final _id_ctor =
      jniAccessors.getMethodIDOf(_classRef, "<init>", "()V");

  /// from: public void <init>()
  /// The returned object must be deleted after use, by calling the `delete` method.
  MediaSync_Callback()
      : super.fromRef(
            jniAccessors.newObjectWithArgs(_classRef, _id_ctor, []).object);

  static final _id_onAudioBufferConsumed = jniAccessors.getMethodIDOf(
      _classRef,
      "onAudioBufferConsumed",
      "(Landroid/media/MediaSync;Ljava/nio/ByteBuffer;I)V");

  /// from: public abstract void onAudioBufferConsumed(android.media.MediaSync sync, java.nio.ByteBuffer audioBuffer, int bufferId)
  ///
  /// Called when returning an audio buffer which has been consumed.
  ///@param sync The MediaSync object.
  /// This value must never be {@code null}.
  ///@param audioBuffer The returned audio buffer.
  /// This value must never be {@code null}.
  ///@param bufferId The ID associated with audioBuffer as passed into
  ///     MediaSync\#queueAudio.
  void onAudioBufferConsumed(
          MediaSync sync0, jni.JniObject audioBuffer, int bufferId) =>
      jniAccessors.callMethodWithArgs(
          reference,
          _id_onAudioBufferConsumed,
          jni.JniType.voidType,
          [sync0.reference, audioBuffer.reference, bufferId]).check();
}
