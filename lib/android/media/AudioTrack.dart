// Autogenerated by jnigen. DO NOT EDIT!

// ignore_for_file: camel_case_types
// ignore_for_file: file_names
// ignore_for_file: non_constant_identifier_names
// ignore_for_file: constant_identifier_names
// ignore_for_file: unused_shown_name
// ignore_for_file: annotate_overrides
// ignore_for_file: no_leading_underscores_for_local_identifiers
// ignore_for_file: unused_import
// ignore_for_file: unused_element
// ignore_for_file: unused_field

import "package:jni/jni.dart" as jni;

import "package:jni/internal_helpers_for_jnigen.dart";

import "AudioAttributes.dart" as audioattributes_;

import "AudioFormat.dart" as audioformat_;

import "PlaybackParams.dart" as playbackparams_;

import "AudioTimestamp.dart" as audiotimestamp_;

import "../os/PersistableBundle.dart" as persistablebundle_;

import "../os/Handler.dart" as handler_;

import "VolumeShaper.dart" as volumeshaper_;

import "AudioPresentation.dart" as audiopresentation_;

import "AudioDeviceInfo.dart" as audiodeviceinfo_;

import "AudioRouting.dart" as audiorouting_;
import "../../_init.dart" show jniEnv, jniAccessors;

/// from: android.media.AudioTrack
///
/// The AudioTrack class manages and plays a single audio resource for Java applications.
/// It allows streaming of PCM audio buffers to the audio sink for playback. This is
/// achieved by "pushing" the data to the AudioTrack object using one of the
///  \#write(byte[], int, int), \#write(short[], int, int),
///  and \#write(float[], int, int, int) methods.
///
/// An AudioTrack instance can operate under two modes: static or streaming.<br>
/// In Streaming mode, the application writes a continuous stream of data to the AudioTrack, using
/// one of the {@code write()} methods. These are blocking and return when the data has been
/// transferred from the Java layer to the native layer and queued for playback. The streaming
/// mode is most useful when playing blocks of audio data that for instance are:
///
/// <ul>
///   <li>too big to fit in memory because of the duration of the sound to play,</li>
///   <li>too big to fit in memory because of the characteristics of the audio data
///         (high sampling rate, bits per sample ...)</li>
///   <li>received or generated while previously queued audio is playing.</li>
/// </ul>
///
/// The static mode should be chosen when dealing with short sounds that fit in memory and
/// that need to be played with the smallest latency possible. The static mode will
/// therefore be preferred for UI and game sounds that are played often, and with the
/// smallest overhead possible.
///
/// Upon creation, an AudioTrack object initializes its associated audio buffer.
/// The size of this buffer, specified during the construction, determines how long an AudioTrack
/// can play before running out of data.<br>
/// For an AudioTrack using the static mode, this size is the maximum size of the sound that can
/// be played from it.<br>
/// For the streaming mode, data will be written to the audio sink in chunks of
/// sizes less than or equal to the total buffer size.
///
/// AudioTrack is not final and thus permits subclasses, but such use is not recommended.
class AudioTrack extends jni.JniObject {
  static final _classRef = jniAccessors.getClassOf("android/media/AudioTrack");
  AudioTrack.fromRef(jni.JObject ref) : super.fromRef(ref);

  /// from: static public final int ERROR
  ///
  /// Denotes a generic operation failure.
  static const ERROR = -1;

  /// from: static public final int ERROR_BAD_VALUE
  ///
  /// Denotes a failure due to the use of an invalid value.
  static const ERROR_BAD_VALUE = -2;

  /// from: static public final int ERROR_DEAD_OBJECT
  ///
  /// An error code indicating that the object reporting it is no longer valid and needs to
  /// be recreated.
  static const ERROR_DEAD_OBJECT = -6;

  /// from: static public final int ERROR_INVALID_OPERATION
  ///
  /// Denotes a failure due to the improper use of a method.
  static const ERROR_INVALID_OPERATION = -3;

  /// from: static public final int MODE_STATIC
  ///
  /// Creation mode where audio data is transferred from Java to the native layer
  /// only once before the audio starts playing.
  static const MODE_STATIC = 0;

  /// from: static public final int MODE_STREAM
  ///
  /// Creation mode where audio data is streamed from Java to the native layer
  /// as the audio is playing.
  static const MODE_STREAM = 1;

  /// from: static public final int PERFORMANCE_MODE_LOW_LATENCY
  ///
  /// Low latency performance mode for an AudioTrack.
  /// If the device supports it, this mode
  /// enables a lower latency path through to the audio output sink.
  /// Effects may no longer work with such an {@code AudioTrack} and
  /// the sample rate must match that of the output sink.
  ///
  /// Applications should be aware that low latency requires careful
  /// buffer management, with smaller chunks of audio data written by each
  /// {@code write()} call.
  ///
  /// If this flag is used without specifying a {@code bufferSizeInBytes} then the
  /// {@code AudioTrack}'s actual buffer size may be too small.
  /// It is recommended that a fairly
  /// large buffer should be specified when the {@code AudioTrack} is created.
  /// Then the actual size can be reduced by calling
  /// \#setBufferSizeInFrames(int). The buffer size can be optimized
  /// by lowering it after each {@code write()} call until the audio glitches,
  /// which is detected by calling
  /// \#getUnderrunCount(). Then the buffer size can be increased
  /// until there are no glitches.
  /// This tuning step should be done while playing silence.
  /// This technique provides a compromise between latency and glitch rate.
  static const PERFORMANCE_MODE_LOW_LATENCY = 1;

  /// from: static public final int PERFORMANCE_MODE_NONE
  ///
  /// Default performance mode for an AudioTrack.
  static const PERFORMANCE_MODE_NONE = 0;

  /// from: static public final int PERFORMANCE_MODE_POWER_SAVING
  ///
  /// Power saving performance mode for an AudioTrack.
  /// If the device supports it, this
  /// mode will enable a lower power path to the audio output sink.
  /// In addition, this lower power path typically will have
  /// deeper internal buffers and better underrun resistance,
  /// with a tradeoff of higher latency.
  ///
  /// In this mode, applications should attempt to use a larger buffer size
  /// and deliver larger chunks of audio data per {@code write()} call.
  /// Use \#getBufferSizeInFrames() to determine
  /// the actual buffer size of the {@code AudioTrack} as it may have increased
  /// to accommodate a deeper buffer.
  static const PERFORMANCE_MODE_POWER_SAVING = 2;

  /// from: static public final int PLAYSTATE_PAUSED
  ///
  /// indicates AudioTrack state is paused
  static const PLAYSTATE_PAUSED = 2;

  /// from: static public final int PLAYSTATE_PLAYING
  ///
  /// indicates AudioTrack state is playing
  static const PLAYSTATE_PLAYING = 3;

  /// from: static public final int PLAYSTATE_STOPPED
  ///
  /// indicates AudioTrack state is stopped
  static const PLAYSTATE_STOPPED = 1;

  /// from: static public final int STATE_INITIALIZED
  ///
  /// State of an AudioTrack that is ready to be used.
  static const STATE_INITIALIZED = 1;

  /// from: static public final int STATE_NO_STATIC_DATA
  ///
  /// State of a successfully initialized AudioTrack that uses static data,
  /// but that hasn't received that data yet.
  static const STATE_NO_STATIC_DATA = 2;

  /// from: static public final int STATE_UNINITIALIZED
  ///
  /// State of an AudioTrack that was not successfully initialized upon creation.
  static const STATE_UNINITIALIZED = 0;

  /// from: static public final int SUCCESS
  ///
  /// Denotes a successful operation.
  static const SUCCESS = 0;

  /// from: static public final int WRITE_BLOCKING
  ///
  /// The write mode indicating the write operation will block until all data has been written,
  /// to be used as the actual value of the writeMode parameter in
  /// \#write(byte[], int, int, int), \#write(short[], int, int, int),
  /// \#write(float[], int, int, int), \#write(ByteBuffer, int, int), and
  /// \#write(ByteBuffer, int, int, long).
  static const WRITE_BLOCKING = 0;

  /// from: static public final int WRITE_NON_BLOCKING
  ///
  /// The write mode indicating the write operation will return immediately after
  /// queuing as much audio data for playback as possible without blocking,
  /// to be used as the actual value of the writeMode parameter in
  /// \#write(ByteBuffer, int, int), \#write(short[], int, int, int),
  /// \#write(float[], int, int, int), \#write(ByteBuffer, int, int), and
  /// \#write(ByteBuffer, int, int, long).
  static const WRITE_NON_BLOCKING = 1;

  static final _id_ctor =
      jniAccessors.getMethodIDOf(_classRef, "<init>", "(IIIIII)V");

  /// from: public void <init>(int streamType, int sampleRateInHz, int channelConfig, int audioFormat, int bufferSizeInBytes, int mode)
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// Class constructor.
  ///@param streamType the type of the audio stream. See
  ///   AudioManager\#STREAM_VOICE_CALL, AudioManager\#STREAM_SYSTEM,
  ///   AudioManager\#STREAM_RING, AudioManager\#STREAM_MUSIC,
  ///   AudioManager\#STREAM_ALARM, and AudioManager\#STREAM_NOTIFICATION.
  ///@param sampleRateInHz the initial source sample rate expressed in Hz.
  ///   AudioFormat\#SAMPLE_RATE_UNSPECIFIED means to use a route-dependent value
  ///   which is usually the sample rate of the sink.
  ///   \#getSampleRate() can be used to retrieve the actual sample rate chosen.
  ///@param channelConfig describes the configuration of the audio channels.
  ///   See AudioFormat\#CHANNEL_OUT_MONO and
  ///   AudioFormat\#CHANNEL_OUT_STEREO
  ///@param audioFormat the format in which the audio data is represented.
  ///   See AudioFormat\#ENCODING_PCM_16BIT,
  ///   AudioFormat\#ENCODING_PCM_8BIT,
  ///   and AudioFormat\#ENCODING_PCM_FLOAT.
  ///@param bufferSizeInBytes the total size (in bytes) of the internal buffer where audio data is
  ///   read from for playback. This should be a nonzero multiple of the frame size in bytes.
  ///    If the track's creation mode is \#MODE_STATIC,
  ///   this is the maximum length sample, or audio clip, that can be played by this instance.
  ///    If the track's creation mode is \#MODE_STREAM,
  ///   this should be the desired buffer size
  ///   for the <code>AudioTrack</code> to satisfy the application's
  ///   latency requirements.
  ///   If <code>bufferSizeInBytes</code> is less than the
  ///   minimum buffer size for the output sink, it is increased to the minimum
  ///   buffer size.
  ///   The method \#getBufferSizeInFrames() returns the
  ///   actual size in frames of the buffer created, which
  ///   determines the minimum frequency to write
  ///   to the streaming <code>AudioTrack</code> to avoid underrun.
  ///   See \#getMinBufferSize(int, int, int) to determine the estimated minimum buffer size
  ///   for an AudioTrack instance in streaming mode.
  ///@param mode streaming or static buffer. See \#MODE_STATIC and \#MODE_STREAM
  ///@throws java.lang.IllegalArgumentException
  ///@deprecated use Builder or
  ///   \#AudioTrack(AudioAttributes, AudioFormat, int, int, int) to specify the
  ///   AudioAttributes instead of the stream type which is only for volume control.
  AudioTrack(int streamType, int sampleRateInHz, int channelConfig,
      int audioFormat, int bufferSizeInBytes, int mode)
      : super.fromRef(jniAccessors.newObjectWithArgs(_classRef, _id_ctor, [
          streamType,
          sampleRateInHz,
          channelConfig,
          audioFormat,
          bufferSizeInBytes,
          mode
        ]).object);

  static final _id_ctor1 =
      jniAccessors.getMethodIDOf(_classRef, "<init>", "(IIIIIII)V");

  /// from: public void <init>(int streamType, int sampleRateInHz, int channelConfig, int audioFormat, int bufferSizeInBytes, int mode, int sessionId)
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// Class constructor with audio session. Use this constructor when the AudioTrack must be
  /// attached to a particular audio session. The primary use of the audio session ID is to
  /// associate audio effects to a particular instance of AudioTrack: if an audio session ID
  /// is provided when creating an AudioEffect, this effect will be applied only to audio tracks
  /// and media players in the same session and not to the output mix.
  /// When an AudioTrack is created without specifying a session, it will create its own session
  /// which can be retrieved by calling the \#getAudioSessionId() method.
  /// If a non-zero session ID is provided, this AudioTrack will share effects attached to this
  /// session
  /// with all other media players or audio tracks in the same session, otherwise a new session
  /// will be created for this track if none is supplied.
  ///@param streamType the type of the audio stream. See
  ///   AudioManager\#STREAM_VOICE_CALL, AudioManager\#STREAM_SYSTEM,
  ///   AudioManager\#STREAM_RING, AudioManager\#STREAM_MUSIC,
  ///   AudioManager\#STREAM_ALARM, and AudioManager\#STREAM_NOTIFICATION.
  ///@param sampleRateInHz the initial source sample rate expressed in Hz.
  ///   AudioFormat\#SAMPLE_RATE_UNSPECIFIED means to use a route-dependent value
  ///   which is usually the sample rate of the sink.
  ///@param channelConfig describes the configuration of the audio channels.
  ///   See AudioFormat\#CHANNEL_OUT_MONO and
  ///   AudioFormat\#CHANNEL_OUT_STEREO
  ///@param audioFormat the format in which the audio data is represented.
  ///   See AudioFormat\#ENCODING_PCM_16BIT and
  ///   AudioFormat\#ENCODING_PCM_8BIT,
  ///   and AudioFormat\#ENCODING_PCM_FLOAT.
  ///@param bufferSizeInBytes the total size (in bytes) of the internal buffer where audio data is
  ///   read from for playback. This should be a nonzero multiple of the frame size in bytes.
  ///    If the track's creation mode is \#MODE_STATIC,
  ///   this is the maximum length sample, or audio clip, that can be played by this instance.
  ///    If the track's creation mode is \#MODE_STREAM,
  ///   this should be the desired buffer size
  ///   for the <code>AudioTrack</code> to satisfy the application's
  ///   latency requirements.
  ///   If <code>bufferSizeInBytes</code> is less than the
  ///   minimum buffer size for the output sink, it is increased to the minimum
  ///   buffer size.
  ///   The method \#getBufferSizeInFrames() returns the
  ///   actual size in frames of the buffer created, which
  ///   determines the minimum frequency to write
  ///   to the streaming <code>AudioTrack</code> to avoid underrun.
  ///   You can write data into this buffer in smaller chunks than this size.
  ///   See \#getMinBufferSize(int, int, int) to determine the estimated minimum buffer size
  ///   for an AudioTrack instance in streaming mode.
  ///@param mode streaming or static buffer. See \#MODE_STATIC and \#MODE_STREAM
  ///@param sessionId Id of audio session the AudioTrack must be attached to
  ///@throws java.lang.IllegalArgumentException
  ///@deprecated use Builder or
  ///   \#AudioTrack(AudioAttributes, AudioFormat, int, int, int) to specify the
  ///   AudioAttributes instead of the stream type which is only for volume control.
  AudioTrack.ctor1(int streamType, int sampleRateInHz, int channelConfig,
      int audioFormat, int bufferSizeInBytes, int mode, int sessionId)
      : super.fromRef(jniAccessors.newObjectWithArgs(_classRef, _id_ctor1, [
          streamType,
          sampleRateInHz,
          channelConfig,
          audioFormat,
          bufferSizeInBytes,
          mode,
          sessionId
        ]).object);

  static final _id_ctor2 = jniAccessors.getMethodIDOf(_classRef, "<init>",
      "(Landroid/media/AudioAttributes;Landroid/media/AudioFormat;III)V");

  /// from: public void <init>(android.media.AudioAttributes attributes, android.media.AudioFormat format, int bufferSizeInBytes, int mode, int sessionId)
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// Class constructor with AudioAttributes and AudioFormat.
  ///@param attributes a non-null AudioAttributes instance.
  ///@param format a non-null AudioFormat instance describing the format of the data
  ///     that will be played through this AudioTrack. See AudioFormat.Builder for
  ///     configuring the audio format parameters such as encoding, channel mask and sample rate.
  ///@param bufferSizeInBytes the total size (in bytes) of the internal buffer where audio data is
  ///   read from for playback. This should be a nonzero multiple of the frame size in bytes.
  ///    If the track's creation mode is \#MODE_STATIC,
  ///   this is the maximum length sample, or audio clip, that can be played by this instance.
  ///    If the track's creation mode is \#MODE_STREAM,
  ///   this should be the desired buffer size
  ///   for the <code>AudioTrack</code> to satisfy the application's
  ///   latency requirements.
  ///   If <code>bufferSizeInBytes</code> is less than the
  ///   minimum buffer size for the output sink, it is increased to the minimum
  ///   buffer size.
  ///   The method \#getBufferSizeInFrames() returns the
  ///   actual size in frames of the buffer created, which
  ///   determines the minimum frequency to write
  ///   to the streaming <code>AudioTrack</code> to avoid underrun.
  ///   See \#getMinBufferSize(int, int, int) to determine the estimated minimum buffer size
  ///   for an AudioTrack instance in streaming mode.
  ///@param mode streaming or static buffer. See \#MODE_STATIC and \#MODE_STREAM.
  ///@param sessionId ID of audio session the AudioTrack must be attached to, or
  ///   AudioManager\#AUDIO_SESSION_ID_GENERATE if the session isn't known at construction
  ///   time. See also AudioManager\#generateAudioSessionId() to obtain a session ID before
  ///   construction.
  ///@throws IllegalArgumentException
  AudioTrack.ctor2(
      audioattributes_.AudioAttributes attributes,
      audioformat_.AudioFormat format,
      int bufferSizeInBytes,
      int mode,
      int sessionId)
      : super.fromRef(jniAccessors.newObjectWithArgs(_classRef, _id_ctor2, [
          attributes.reference,
          format.reference,
          bufferSizeInBytes,
          mode,
          sessionId
        ]).object);

  static final _id_release =
      jniAccessors.getMethodIDOf(_classRef, "release", "()V");

  /// from: public void release()
  ///
  /// Releases the native AudioTrack resources.
  void release() => jniAccessors.callMethodWithArgs(
      reference, _id_release, jni.JniType.voidType, []).check();

  static final _id_finalize =
      jniAccessors.getMethodIDOf(_classRef, "finalize", "()V");

  /// from: protected void finalize()
  void finalize() => jniAccessors.callMethodWithArgs(
      reference, _id_finalize, jni.JniType.voidType, []).check();

  static final _id_getMinVolume =
      jniAccessors.getStaticMethodIDOf(_classRef, "getMinVolume", "()F");

  /// from: static public float getMinVolume()
  ///
  /// Returns the minimum gain value, which is the constant 0.0.
  /// Gain values less than 0.0 will be clamped to 0.0.
  /// The word "volume" in the API name is historical; this is actually a linear gain.
  ///@return the minimum value, which is the constant 0.0.
  static double getMinVolume() => jniAccessors.callStaticMethodWithArgs(
      _classRef, _id_getMinVolume, jni.JniType.floatType, []).float;

  static final _id_getMaxVolume =
      jniAccessors.getStaticMethodIDOf(_classRef, "getMaxVolume", "()F");

  /// from: static public float getMaxVolume()
  ///
  /// Returns the maximum gain value, which is greater than or equal to 1.0.
  /// Gain values greater than the maximum will be clamped to the maximum.
  /// The word "volume" in the API name is historical; this is actually a gain.
  /// expressed as a linear multiplier on sample values, where a maximum value of 1.0
  /// corresponds to a gain of 0 dB (sample values left unmodified).
  ///@return the maximum value, which is greater than or equal to 1.0.
  static double getMaxVolume() => jniAccessors.callStaticMethodWithArgs(
      _classRef, _id_getMaxVolume, jni.JniType.floatType, []).float;

  static final _id_getSampleRate =
      jniAccessors.getMethodIDOf(_classRef, "getSampleRate", "()I");

  /// from: public int getSampleRate()
  ///
  /// Returns the configured audio source sample rate in Hz.
  /// The initial source sample rate depends on the constructor parameters,
  /// but the source sample rate may change if \#setPlaybackRate(int) is called.
  /// If the constructor had a specific sample rate, then the initial sink sample rate is that
  /// value.
  /// If the constructor had AudioFormat\#SAMPLE_RATE_UNSPECIFIED,
  /// then the initial sink sample rate is a route-dependent default value based on the source [sic].
  int getSampleRate() => jniAccessors.callMethodWithArgs(
      reference, _id_getSampleRate, jni.JniType.intType, []).integer;

  static final _id_getPlaybackRate =
      jniAccessors.getMethodIDOf(_classRef, "getPlaybackRate", "()I");

  /// from: public int getPlaybackRate()
  ///
  /// Returns the current playback sample rate rate in Hz.
  int getPlaybackRate() => jniAccessors.callMethodWithArgs(
      reference, _id_getPlaybackRate, jni.JniType.intType, []).integer;

  static final _id_getPlaybackParams = jniAccessors.getMethodIDOf(
      _classRef, "getPlaybackParams", "()Landroid/media/PlaybackParams;");

  /// from: public android.media.PlaybackParams getPlaybackParams()
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// Returns the current playback parameters.
  /// See \#setPlaybackParams(PlaybackParams) to set playback parameters
  ///@return current PlaybackParams.
  /// This value will never be {@code null}.
  ///@throws IllegalStateException if track is not initialized.
  playbackparams_.PlaybackParams getPlaybackParams() =>
      playbackparams_.PlaybackParams.fromRef(jniAccessors.callMethodWithArgs(
          reference, _id_getPlaybackParams, jni.JniType.objectType, []).object);

  static final _id_getAudioFormat =
      jniAccessors.getMethodIDOf(_classRef, "getAudioFormat", "()I");

  /// from: public int getAudioFormat()
  ///
  /// Returns the configured audio data encoding. See AudioFormat\#ENCODING_PCM_8BIT,
  /// AudioFormat\#ENCODING_PCM_16BIT, and AudioFormat\#ENCODING_PCM_FLOAT.
  int getAudioFormat() => jniAccessors.callMethodWithArgs(
      reference, _id_getAudioFormat, jni.JniType.intType, []).integer;

  static final _id_getStreamType =
      jniAccessors.getMethodIDOf(_classRef, "getStreamType", "()I");

  /// from: public int getStreamType()
  ///
  /// Returns the volume stream type of this AudioTrack.
  /// Compare the result against AudioManager\#STREAM_VOICE_CALL,
  /// AudioManager\#STREAM_SYSTEM, AudioManager\#STREAM_RING,
  /// AudioManager\#STREAM_MUSIC, AudioManager\#STREAM_ALARM,
  /// AudioManager\#STREAM_NOTIFICATION, AudioManager\#STREAM_DTMF or
  /// AudioManager\#STREAM_ACCESSIBILITY.
  int getStreamType() => jniAccessors.callMethodWithArgs(
      reference, _id_getStreamType, jni.JniType.intType, []).integer;

  static final _id_getChannelConfiguration =
      jniAccessors.getMethodIDOf(_classRef, "getChannelConfiguration", "()I");

  /// from: public int getChannelConfiguration()
  ///
  /// Returns the configured channel position mask.
  ///  For example, refer to AudioFormat\#CHANNEL_OUT_MONO,
  /// AudioFormat\#CHANNEL_OUT_STEREO, AudioFormat\#CHANNEL_OUT_5POINT1.
  /// This method may return AudioFormat\#CHANNEL_INVALID if
  /// a channel index mask was used. Consider
  /// \#getFormat() instead, to obtain an AudioFormat,
  /// which contains both the channel position mask and the channel index mask.
  int getChannelConfiguration() => jniAccessors.callMethodWithArgs(
      reference, _id_getChannelConfiguration, jni.JniType.intType, []).integer;

  static final _id_getFormat = jniAccessors.getMethodIDOf(
      _classRef, "getFormat", "()Landroid/media/AudioFormat;");

  /// from: public android.media.AudioFormat getFormat()
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// Returns the configured <code>AudioTrack</code> format.
  ///@return an AudioFormat containing the
  /// <code>AudioTrack</code> parameters at the time of configuration.
  ///
  /// This value will never be {@code null}.
  audioformat_.AudioFormat getFormat() =>
      audioformat_.AudioFormat.fromRef(jniAccessors.callMethodWithArgs(
          reference, _id_getFormat, jni.JniType.objectType, []).object);

  static final _id_getChannelCount =
      jniAccessors.getMethodIDOf(_classRef, "getChannelCount", "()I");

  /// from: public int getChannelCount()
  ///
  /// Returns the configured number of channels.
  int getChannelCount() => jniAccessors.callMethodWithArgs(
      reference, _id_getChannelCount, jni.JniType.intType, []).integer;

  static final _id_getState =
      jniAccessors.getMethodIDOf(_classRef, "getState", "()I");

  /// from: public int getState()
  ///
  /// Returns the state of the AudioTrack instance. This is useful after the
  /// AudioTrack instance has been created to check if it was initialized
  /// properly. This ensures that the appropriate resources have been acquired.
  ///@see \#STATE_UNINITIALIZED
  ///@see \#STATE_INITIALIZED
  ///@see \#STATE_NO_STATIC_DATA
  int getState() => jniAccessors.callMethodWithArgs(
      reference, _id_getState, jni.JniType.intType, []).integer;

  static final _id_getPlayState =
      jniAccessors.getMethodIDOf(_classRef, "getPlayState", "()I");

  /// from: public int getPlayState()
  ///
  /// Returns the playback state of the AudioTrack instance.
  ///@see \#PLAYSTATE_STOPPED
  ///@see \#PLAYSTATE_PAUSED
  ///@see \#PLAYSTATE_PLAYING
  int getPlayState() => jniAccessors.callMethodWithArgs(
      reference, _id_getPlayState, jni.JniType.intType, []).integer;

  static final _id_getBufferSizeInFrames =
      jniAccessors.getMethodIDOf(_classRef, "getBufferSizeInFrames", "()I");

  /// from: public int getBufferSizeInFrames()
  ///
  /// Returns the effective size of the <code>AudioTrack</code> buffer
  /// that the application writes to.
  ///  This will be less than or equal to the result of
  /// \#getBufferCapacityInFrames().
  /// It will be equal if \#setBufferSizeInFrames(int) has never been called.
  ///  If the track is subsequently routed to a different output sink, the buffer
  /// size and capacity may enlarge to accommodate.
  ///  If the <code>AudioTrack</code> encoding indicates compressed data,
  /// e.g. AudioFormat\#ENCODING_AC3, then the frame count returned is
  /// the size of the <code>AudioTrack</code> buffer in bytes.
  ///  See also AudioManager\#getProperty(String) for key
  /// AudioManager\#PROPERTY_OUTPUT_FRAMES_PER_BUFFER.
  ///@return current size in frames of the <code>AudioTrack</code> buffer.
  ///@throws IllegalStateException if track is not initialized.
  int getBufferSizeInFrames() => jniAccessors.callMethodWithArgs(
      reference, _id_getBufferSizeInFrames, jni.JniType.intType, []).integer;

  static final _id_setBufferSizeInFrames =
      jniAccessors.getMethodIDOf(_classRef, "setBufferSizeInFrames", "(I)I");

  /// from: public int setBufferSizeInFrames(int bufferSizeInFrames)
  ///
  /// Limits the effective size of the <code>AudioTrack</code> buffer
  /// that the application writes to.
  ///  A write to this AudioTrack will not fill the buffer beyond this limit.
  /// If a blocking write is used then the write will block until the data
  /// can fit within this limit.
  /// Changing this limit modifies the latency associated with
  /// the buffer for this track. A smaller size will give lower latency
  /// but there may be more glitches due to buffer underruns.
  /// The actual size used may not be equal to this requested size.
  /// It will be limited to a valid range with a maximum of
  /// \#getBufferCapacityInFrames().
  /// It may also be adjusted slightly for internal reasons.
  /// If bufferSizeInFrames is less than zero then \#ERROR_BAD_VALUE
  /// will be returned.
  /// This method is only supported for PCM audio.
  /// It is not supported for compressed audio tracks.
  ///@param bufferSizeInFrames requested buffer size in frames
  ///@return the actual buffer size in frames or an error code,
  ///    \#ERROR_BAD_VALUE, \#ERROR_INVALID_OPERATION
  ///@throws IllegalStateException if track is not initialized.
  int setBufferSizeInFrames(int bufferSizeInFrames) =>
      jniAccessors.callMethodWithArgs(reference, _id_setBufferSizeInFrames,
          jni.JniType.intType, [bufferSizeInFrames]).integer;

  static final _id_getBufferCapacityInFrames =
      jniAccessors.getMethodIDOf(_classRef, "getBufferCapacityInFrames", "()I");

  /// from: public int getBufferCapacityInFrames()
  ///
  /// Returns the maximum size of the <code>AudioTrack</code> buffer in frames.
  ///   If the track's creation mode is \#MODE_STATIC,
  ///  it is equal to the specified bufferSizeInBytes on construction, converted to frame units.
  ///  A static track's frame count will not change.
  ///   If the track's creation mode is \#MODE_STREAM,
  ///  it is greater than or equal to the specified bufferSizeInBytes converted to frame units.
  ///  For streaming tracks, this value may be rounded up to a larger value if needed by
  ///  the target output sink, and
  ///  if the track is subsequently routed to a different output sink, the
  ///  frame count may enlarge to accommodate.
  ///   If the <code>AudioTrack</code> encoding indicates compressed data,
  ///  e.g. AudioFormat\#ENCODING_AC3, then the frame count returned is
  ///  the size of the <code>AudioTrack</code> buffer in bytes.
  ///   See also AudioManager\#getProperty(String) for key
  ///  AudioManager\#PROPERTY_OUTPUT_FRAMES_PER_BUFFER.
  ///@return maximum size in frames of the <code>AudioTrack</code> buffer.
  ///@throws IllegalStateException if track is not initialized.
  int getBufferCapacityInFrames() => jniAccessors.callMethodWithArgs(reference,
      _id_getBufferCapacityInFrames, jni.JniType.intType, []).integer;

  static final _id_getNativeFrameCount =
      jniAccessors.getMethodIDOf(_classRef, "getNativeFrameCount", "()I");

  /// from: protected int getNativeFrameCount()
  ///
  /// Returns the frame count of the native <code>AudioTrack</code> buffer.
  ///@return current size in frames of the <code>AudioTrack</code> buffer.
  ///@throws IllegalStateException
  ///@deprecated Use the identical public method \#getBufferSizeInFrames() instead.
  int getNativeFrameCount() => jniAccessors.callMethodWithArgs(
      reference, _id_getNativeFrameCount, jni.JniType.intType, []).integer;

  static final _id_getNotificationMarkerPosition = jniAccessors.getMethodIDOf(
      _classRef, "getNotificationMarkerPosition", "()I");

  /// from: public int getNotificationMarkerPosition()
  ///
  /// Returns marker position expressed in frames.
  ///@return marker position in wrapping frame units similar to \#getPlaybackHeadPosition,
  /// or zero if marker is disabled.
  int getNotificationMarkerPosition() => jniAccessors.callMethodWithArgs(
      reference,
      _id_getNotificationMarkerPosition,
      jni.JniType.intType, []).integer;

  static final _id_getPositionNotificationPeriod = jniAccessors.getMethodIDOf(
      _classRef, "getPositionNotificationPeriod", "()I");

  /// from: public int getPositionNotificationPeriod()
  ///
  /// Returns the notification update period expressed in frames.
  /// Zero means that no position update notifications are being delivered.
  int getPositionNotificationPeriod() => jniAccessors.callMethodWithArgs(
      reference,
      _id_getPositionNotificationPeriod,
      jni.JniType.intType, []).integer;

  static final _id_getPlaybackHeadPosition =
      jniAccessors.getMethodIDOf(_classRef, "getPlaybackHeadPosition", "()I");

  /// from: public int getPlaybackHeadPosition()
  ///
  /// Returns the playback head position expressed in frames.
  /// Though the "int" type is signed 32-bits, the value should be reinterpreted as if it is
  /// unsigned 32-bits.  That is, the next position after 0x7FFFFFFF is (int) 0x80000000.
  /// This is a continuously advancing counter.  It will wrap (overflow) periodically,
  /// for example approximately once every 27:03:11 hours:minutes:seconds at 44.1 kHz.
  /// It is reset to zero by \#flush(), \#reloadStaticData(), and \#stop().
  /// If the track's creation mode is \#MODE_STATIC, the return value indicates
  /// the total number of frames played since reset,
  /// <i>not</i> the current offset within the buffer.
  int getPlaybackHeadPosition() => jniAccessors.callMethodWithArgs(
      reference, _id_getPlaybackHeadPosition, jni.JniType.intType, []).integer;

  static final _id_getUnderrunCount =
      jniAccessors.getMethodIDOf(_classRef, "getUnderrunCount", "()I");

  /// from: public int getUnderrunCount()
  ///
  /// Returns the number of underrun occurrences in the application-level write buffer
  /// since the AudioTrack was created.
  /// An underrun occurs if the application does not write audio
  /// data quickly enough, causing the buffer to underflow
  /// and a potential audio glitch or pop.
  ///
  /// Underruns are less likely when buffer sizes are large.
  /// It may be possible to eliminate underruns by recreating the AudioTrack with
  /// a larger buffer.
  /// Or by using \#setBufferSizeInFrames(int) to dynamically increase the
  /// effective size of the buffer.
  int getUnderrunCount() => jniAccessors.callMethodWithArgs(
      reference, _id_getUnderrunCount, jni.JniType.intType, []).integer;

  static final _id_getPerformanceMode =
      jniAccessors.getMethodIDOf(_classRef, "getPerformanceMode", "()I");

  /// from: public int getPerformanceMode()
  ///
  /// Returns the current performance mode of the AudioTrack.
  ///@return one of AudioTrack\#PERFORMANCE_MODE_NONE,
  /// AudioTrack\#PERFORMANCE_MODE_LOW_LATENCY,
  /// or AudioTrack\#PERFORMANCE_MODE_POWER_SAVING.
  /// Use AudioTrack.Builder\#setPerformanceMode
  /// in the AudioTrack.Builder to enable a performance mode.
  /// Value is android.media.AudioTrack\#PERFORMANCE_MODE_NONE, android.media.AudioTrack\#PERFORMANCE_MODE_LOW_LATENCY, or android.media.AudioTrack\#PERFORMANCE_MODE_POWER_SAVING
  ///@throws IllegalStateException if track is not initialized.
  int getPerformanceMode() => jniAccessors.callMethodWithArgs(
      reference, _id_getPerformanceMode, jni.JniType.intType, []).integer;

  static final _id_getNativeOutputSampleRate = jniAccessors.getStaticMethodIDOf(
      _classRef, "getNativeOutputSampleRate", "(I)I");

  /// from: static public int getNativeOutputSampleRate(int streamType)
  ///
  /// Returns the output sample rate in Hz for the specified stream type.
  static int getNativeOutputSampleRate(int streamType) =>
      jniAccessors.callStaticMethodWithArgs(
          _classRef,
          _id_getNativeOutputSampleRate,
          jni.JniType.intType,
          [streamType]).integer;

  static final _id_getMinBufferSize =
      jniAccessors.getStaticMethodIDOf(_classRef, "getMinBufferSize", "(III)I");

  /// from: static public int getMinBufferSize(int sampleRateInHz, int channelConfig, int audioFormat)
  ///
  /// Returns the estimated minimum buffer size required for an AudioTrack
  /// object to be created in the \#MODE_STREAM mode.
  /// The size is an estimate because it does not consider either the route or the sink,
  /// since neither is known yet.  Note that this size doesn't
  /// guarantee a smooth playback under load, and higher values should be chosen according to
  /// the expected frequency at which the buffer will be refilled with additional data to play.
  /// For example, if you intend to dynamically set the source sample rate of an AudioTrack
  /// to a higher value than the initial source sample rate, be sure to configure the buffer size
  /// based on the highest planned sample rate.
  ///@param sampleRateInHz the source sample rate expressed in Hz.
  ///   AudioFormat\#SAMPLE_RATE_UNSPECIFIED is not permitted.
  ///@param channelConfig describes the configuration of the audio channels.
  ///   See AudioFormat\#CHANNEL_OUT_MONO and
  ///   AudioFormat\#CHANNEL_OUT_STEREO
  ///@param audioFormat the format in which the audio data is represented.
  ///   See AudioFormat\#ENCODING_PCM_16BIT and
  ///   AudioFormat\#ENCODING_PCM_8BIT,
  ///   and AudioFormat\#ENCODING_PCM_FLOAT.
  ///@return \#ERROR_BAD_VALUE if an invalid parameter was passed,
  ///   or \#ERROR if unable to query for output properties,
  ///   or the minimum buffer size expressed in bytes.
  static int getMinBufferSize(
          int sampleRateInHz, int channelConfig, int audioFormat) =>
      jniAccessors.callStaticMethodWithArgs(
          _classRef,
          _id_getMinBufferSize,
          jni.JniType.intType,
          [sampleRateInHz, channelConfig, audioFormat]).integer;

  static final _id_getAudioSessionId =
      jniAccessors.getMethodIDOf(_classRef, "getAudioSessionId", "()I");

  /// from: public int getAudioSessionId()
  ///
  /// Returns the audio session ID.
  ///@return the ID of the audio session this AudioTrack belongs to.
  int getAudioSessionId() => jniAccessors.callMethodWithArgs(
      reference, _id_getAudioSessionId, jni.JniType.intType, []).integer;

  static final _id_getTimestamp = jniAccessors.getMethodIDOf(
      _classRef, "getTimestamp", "(Landroid/media/AudioTimestamp;)Z");

  /// from: public boolean getTimestamp(android.media.AudioTimestamp timestamp)
  ///
  /// Poll for a timestamp on demand.
  ///
  /// If you need to track timestamps during initial warmup or after a routing or mode change,
  /// you should request a new timestamp periodically until the reported timestamps
  /// show that the frame position is advancing, or until it becomes clear that
  /// timestamps are unavailable for this route.
  ///
  /// After the clock is advancing at a stable rate,
  /// query for a new timestamp approximately once every 10 seconds to once per minute.
  /// Calling this method more often is inefficient.
  /// It is also counter-productive to call this method more often than recommended,
  /// because the short-term differences between successive timestamp reports are not meaningful.
  /// If you need a high-resolution mapping between frame position and presentation time,
  /// consider implementing that at application level, based on low-resolution timestamps.
  ///
  /// The audio data at the returned position may either already have been
  /// presented, or may have not yet been presented but is committed to be presented.
  /// It is not possible to request the time corresponding to a particular position,
  /// or to request the (fractional) position corresponding to a particular time.
  /// If you need such features, consider implementing them at application level.
  ///@param timestamp a reference to a non-null AudioTimestamp instance allocated
  ///        and owned by caller.
  ///@return true if a timestamp is available, or false if no timestamp is available.
  ///         If a timestamp if available,
  ///         the AudioTimestamp instance is filled in with a position in frame units, together
  ///         with the estimated time when that frame was presented or is committed to
  ///         be presented.
  ///         In the case that no timestamp is available, any supplied instance is left unaltered.
  ///         A timestamp may be temporarily unavailable while the audio clock is stabilizing,
  ///         or during and immediately after a route change.
  ///         A timestamp is permanently unavailable for a given route if the route does not support
  ///         timestamps.  In this case, the approximate frame position can be obtained
  ///         using \#getPlaybackHeadPosition.
  ///         However, it may be useful to continue to query for
  ///         timestamps occasionally, to recover after a route change.
  bool getTimestamp(audiotimestamp_.AudioTimestamp timestamp) =>
      jniAccessors.callMethodWithArgs(reference, _id_getTimestamp,
          jni.JniType.booleanType, [timestamp.reference]).boolean;

  static final _id_getMetrics = jniAccessors.getMethodIDOf(
      _classRef, "getMetrics", "()Landroid/os/PersistableBundle;");

  /// from: public android.os.PersistableBundle getMetrics()
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// Return Metrics data about the current AudioTrack instance.
  ///@return a PersistableBundle containing the set of attributes and values
  /// available for the media being handled by this instance of AudioTrack
  /// The attributes are descibed in MetricsConstants.
  ///
  /// Additional vendor-specific fields may also be present in
  /// the return value.
  persistablebundle_.PersistableBundle getMetrics() =>
      persistablebundle_.PersistableBundle.fromRef(jniAccessors
          .callMethodWithArgs(
              reference, _id_getMetrics, jni.JniType.objectType, []).object);

  static final _id_setPlaybackPositionUpdateListener =
      jniAccessors.getMethodIDOf(_classRef, "setPlaybackPositionUpdateListener",
          "(Landroid/media/AudioTrack\$OnPlaybackPositionUpdateListener;)V");

  /// from: public void setPlaybackPositionUpdateListener(android.media.AudioTrack.OnPlaybackPositionUpdateListener listener)
  ///
  /// Sets the listener the AudioTrack notifies when a previously set marker is reached or
  /// for each periodic playback head position update.
  /// Notifications will be received in the same thread as the one in which the AudioTrack
  /// instance was created.
  ///@param listener
  void setPlaybackPositionUpdateListener(
          AudioTrack_OnPlaybackPositionUpdateListener listener) =>
      jniAccessors.callMethodWithArgs(
          reference,
          _id_setPlaybackPositionUpdateListener,
          jni.JniType.voidType,
          [listener.reference]).check();

  static final _id_setPlaybackPositionUpdateListener1 = jniAccessors.getMethodIDOf(
      _classRef,
      "setPlaybackPositionUpdateListener",
      "(Landroid/media/AudioTrack\$OnPlaybackPositionUpdateListener;Landroid/os/Handler;)V");

  /// from: public void setPlaybackPositionUpdateListener(android.media.AudioTrack.OnPlaybackPositionUpdateListener listener, android.os.Handler handler)
  ///
  /// Sets the listener the AudioTrack notifies when a previously set marker is reached or
  /// for each periodic playback head position update.
  /// Use this method to receive AudioTrack events in the Handler associated with another
  /// thread than the one in which you created the AudioTrack instance.
  ///@param listener
  ///@param handler the Handler that will receive the event notification messages.
  void setPlaybackPositionUpdateListener1(
          AudioTrack_OnPlaybackPositionUpdateListener listener,
          handler_.Handler handler) =>
      jniAccessors.callMethodWithArgs(
          reference,
          _id_setPlaybackPositionUpdateListener1,
          jni.JniType.voidType,
          [listener.reference, handler.reference]).check();

  static final _id_setStereoVolume =
      jniAccessors.getMethodIDOf(_classRef, "setStereoVolume", "(FF)I");

  /// from: public int setStereoVolume(float leftGain, float rightGain)
  ///
  /// Sets the specified left and right output gain values on the AudioTrack.
  /// Gain values are clamped to the closed interval [0.0, max] where
  /// max is the value of \#getMaxVolume.
  /// A value of 0.0 results in zero gain (silence), and
  /// a value of 1.0 means unity gain (signal unchanged).
  /// The default value is 1.0 meaning unity gain.
  /// The word "volume" in the API name is historical; this is actually a linear gain.
  ///@param leftGain output gain for the left channel.
  ///@param rightGain output gain for the right channel
  ///@return error code or success, see \#SUCCESS,
  ///    \#ERROR_INVALID_OPERATION
  ///@deprecated Applications should use \#setVolume instead, as it
  /// more gracefully scales down to mono, and up to multi-channel content beyond stereo.
  int setStereoVolume(double leftGain, double rightGain) =>
      jniAccessors.callMethodWithArgs(reference, _id_setStereoVolume,
          jni.JniType.intType, [leftGain, rightGain]).integer;

  static final _id_setVolume =
      jniAccessors.getMethodIDOf(_classRef, "setVolume", "(F)I");

  /// from: public int setVolume(float gain)
  ///
  /// Sets the specified output gain value on all channels of this track.
  /// Gain values are clamped to the closed interval [0.0, max] where
  /// max is the value of \#getMaxVolume.
  /// A value of 0.0 results in zero gain (silence), and
  /// a value of 1.0 means unity gain (signal unchanged).
  /// The default value is 1.0 meaning unity gain.
  /// This API is preferred over \#setStereoVolume, as it
  /// more gracefully scales down to mono, and up to multi-channel content beyond stereo.
  /// The word "volume" in the API name is historical; this is actually a linear gain.
  ///@param gain output gain for all channels.
  ///@return error code or success, see \#SUCCESS,
  ///    \#ERROR_INVALID_OPERATION
  int setVolume(double gain) => jniAccessors.callMethodWithArgs(
      reference, _id_setVolume, jni.JniType.intType, [gain]).integer;

  static final _id_createVolumeShaper = jniAccessors.getMethodIDOf(
      _classRef,
      "createVolumeShaper",
      "(Landroid/media/VolumeShaper\$Configuration;)Landroid/media/VolumeShaper;");

  /// from: public android.media.VolumeShaper createVolumeShaper(android.media.VolumeShaper.Configuration configuration)
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// @param configuration This value must never be {@code null}.
  ///@return This value will never be {@code null}.
  volumeshaper_.VolumeShaper createVolumeShaper(
          volumeshaper_.VolumeShaper_Configuration configuration) =>
      volumeshaper_.VolumeShaper.fromRef(jniAccessors.callMethodWithArgs(
          reference,
          _id_createVolumeShaper,
          jni.JniType.objectType,
          [configuration.reference]).object);

  static final _id_setPlaybackRate =
      jniAccessors.getMethodIDOf(_classRef, "setPlaybackRate", "(I)I");

  /// from: public int setPlaybackRate(int sampleRateInHz)
  ///
  /// Sets the playback sample rate for this track. This sets the sampling rate at which
  /// the audio data will be consumed and played back
  /// (as set by the sampleRateInHz parameter in the
  /// \#AudioTrack(int, int, int, int, int, int) constructor),
  /// not the original sampling rate of the
  /// content. For example, setting it to half the sample rate of the content will cause the
  /// playback to last twice as long, but will also result in a pitch shift down by one octave.
  /// The valid sample rate range is from 1 Hz to twice the value returned by
  /// \#getNativeOutputSampleRate(int).
  /// Use \#setPlaybackParams(PlaybackParams) for speed control.
  ///  This method may also be used to repurpose an existing <code>AudioTrack</code>
  /// for playback of content of differing sample rate,
  /// but with identical encoding and channel mask.
  ///@param sampleRateInHz the sample rate expressed in Hz
  ///@return error code or success, see \#SUCCESS, \#ERROR_BAD_VALUE,
  ///    \#ERROR_INVALID_OPERATION
  int setPlaybackRate(int sampleRateInHz) => jniAccessors.callMethodWithArgs(
      reference,
      _id_setPlaybackRate,
      jni.JniType.intType,
      [sampleRateInHz]).integer;

  static final _id_setPlaybackParams = jniAccessors.getMethodIDOf(
      _classRef, "setPlaybackParams", "(Landroid/media/PlaybackParams;)V");

  /// from: public void setPlaybackParams(android.media.PlaybackParams params)
  ///
  /// Sets the playback parameters.
  /// This method returns failure if it cannot apply the playback parameters.
  /// One possible cause is that the parameters for speed or pitch are out of range.
  /// Another possible cause is that the <code>AudioTrack</code> is streaming
  /// (see \#MODE_STREAM) and the
  /// buffer size is too small. For speeds greater than 1.0f, the <code>AudioTrack</code> buffer
  /// on configuration must be larger than the speed multiplied by the minimum size
  /// \#getMinBufferSize(int, int, int)) to allow proper playback.
  ///@param params see PlaybackParams. In particular,
  /// speed, pitch, and audio mode should be set.
  /// This value must never be {@code null}.
  ///@throws IllegalArgumentException if the parameters are invalid or not accepted.
  ///@throws IllegalStateException if track is not initialized.
  void setPlaybackParams(playbackparams_.PlaybackParams params) =>
      jniAccessors.callMethodWithArgs(reference, _id_setPlaybackParams,
          jni.JniType.voidType, [params.reference]).check();

  static final _id_setNotificationMarkerPosition = jniAccessors.getMethodIDOf(
      _classRef, "setNotificationMarkerPosition", "(I)I");

  /// from: public int setNotificationMarkerPosition(int markerInFrames)
  ///
  /// Sets the position of the notification marker.  At most one marker can be active.
  ///@param markerInFrames marker position in wrapping frame units similar to
  /// \#getPlaybackHeadPosition, or zero to disable the marker.
  /// To set a marker at a position which would appear as zero due to wraparound,
  /// a workaround is to use a non-zero position near zero, such as -1 or 1.
  ///@return error code or success, see \#SUCCESS, \#ERROR_BAD_VALUE,
  ///  \#ERROR_INVALID_OPERATION
  int setNotificationMarkerPosition(int markerInFrames) =>
      jniAccessors.callMethodWithArgs(
          reference,
          _id_setNotificationMarkerPosition,
          jni.JniType.intType,
          [markerInFrames]).integer;

  static final _id_setPositionNotificationPeriod = jniAccessors.getMethodIDOf(
      _classRef, "setPositionNotificationPeriod", "(I)I");

  /// from: public int setPositionNotificationPeriod(int periodInFrames)
  ///
  /// Sets the period for the periodic notification event.
  ///@param periodInFrames update period expressed in frames.
  /// Zero period means no position updates.  A negative period is not allowed.
  ///@return error code or success, see \#SUCCESS, \#ERROR_INVALID_OPERATION
  int setPositionNotificationPeriod(int periodInFrames) =>
      jniAccessors.callMethodWithArgs(
          reference,
          _id_setPositionNotificationPeriod,
          jni.JniType.intType,
          [periodInFrames]).integer;

  static final _id_setPlaybackHeadPosition =
      jniAccessors.getMethodIDOf(_classRef, "setPlaybackHeadPosition", "(I)I");

  /// from: public int setPlaybackHeadPosition(int positionInFrames)
  ///
  /// Sets the playback head position within the static buffer.
  /// The track must be stopped or paused for the position to be changed,
  /// and must use the \#MODE_STATIC mode.
  ///@param positionInFrames playback head position within buffer, expressed in frames.
  /// Zero corresponds to start of buffer.
  /// The position must not be greater than the buffer size in frames, or negative.
  /// Though this method and \#getPlaybackHeadPosition() have similar names,
  /// the position values have different meanings.
  /// <br>
  /// If looping is currently enabled and the new position is greater than or equal to the
  /// loop end marker, the behavior varies by API level:
  /// as of android.os.Build.VERSION_CODES\#M,
  /// the looping is first disabled and then the position is set.
  /// For earlier API levels, the behavior is unspecified.
  ///@return error code or success, see \#SUCCESS, \#ERROR_BAD_VALUE,
  ///    \#ERROR_INVALID_OPERATION
  int setPlaybackHeadPosition(int positionInFrames) =>
      jniAccessors.callMethodWithArgs(reference, _id_setPlaybackHeadPosition,
          jni.JniType.intType, [positionInFrames]).integer;

  static final _id_setLoopPoints =
      jniAccessors.getMethodIDOf(_classRef, "setLoopPoints", "(III)I");

  /// from: public int setLoopPoints(int startInFrames, int endInFrames, int loopCount)
  ///
  /// Sets the loop points and the loop count. The loop can be infinite.
  /// Similarly to setPlaybackHeadPosition,
  /// the track must be stopped or paused for the loop points to be changed,
  /// and must use the \#MODE_STATIC mode.
  ///@param startInFrames loop start marker expressed in frames.
  /// Zero corresponds to start of buffer.
  /// The start marker must not be greater than or equal to the buffer size in frames, or negative.
  ///@param endInFrames loop end marker expressed in frames.
  /// The total buffer size in frames corresponds to end of buffer.
  /// The end marker must not be greater than the buffer size in frames.
  /// For looping, the end marker must not be less than or equal to the start marker,
  /// but to disable looping
  /// it is permitted for start marker, end marker, and loop count to all be 0.
  /// If any input parameters are out of range, this method returns \#ERROR_BAD_VALUE.
  /// If the loop period (endInFrames - startInFrames) is too small for the implementation to
  /// support,
  /// \#ERROR_BAD_VALUE is returned.
  /// The loop range is the interval [startInFrames, endInFrames).
  /// <br>
  /// As of android.os.Build.VERSION_CODES\#M, the position is left unchanged,
  /// unless it is greater than or equal to the loop end marker, in which case
  /// it is forced to the loop start marker.
  /// For earlier API levels, the effect on position is unspecified.
  ///@param loopCount the number of times the loop is looped; must be greater than or equal to -1.
  ///    A value of -1 means infinite looping, and 0 disables looping.
  ///    A value of positive N means to "loop" (go back) N times.  For example,
  ///    a value of one means to play the region two times in total.
  ///@return error code or success, see \#SUCCESS, \#ERROR_BAD_VALUE,
  ///    \#ERROR_INVALID_OPERATION
  int setLoopPoints(int startInFrames, int endInFrames, int loopCount) =>
      jniAccessors.callMethodWithArgs(reference, _id_setLoopPoints,
          jni.JniType.intType, [startInFrames, endInFrames, loopCount]).integer;

  static final _id_setPresentation = jniAccessors.getMethodIDOf(
      _classRef, "setPresentation", "(Landroid/media/AudioPresentation;)I");

  /// from: public int setPresentation(android.media.AudioPresentation presentation)
  ///
  /// Sets the audio presentation.
  /// If the audio presentation is invalid then \#ERROR_BAD_VALUE will be returned.
  /// If a multi-stream decoder (MSD) is not present, or the format does not support
  /// multiple presentations, then \#ERROR_INVALID_OPERATION will be returned.
  /// \#ERROR is returned in case of any other error.
  ///@param presentation see AudioPresentation. In particular, id should be set.
  /// This value must never be {@code null}.
  ///@return error code or success, see \#SUCCESS, \#ERROR,
  ///    \#ERROR_BAD_VALUE, \#ERROR_INVALID_OPERATION
  ///@throws IllegalArgumentException if the audio presentation is null.
  ///@throws IllegalStateException if track is not initialized.
  int setPresentation(audiopresentation_.AudioPresentation presentation) =>
      jniAccessors.callMethodWithArgs(reference, _id_setPresentation,
          jni.JniType.intType, [presentation.reference]).integer;

  static final _id_setState =
      jniAccessors.getMethodIDOf(_classRef, "setState", "(I)V");

  /// from: protected void setState(int state)
  ///
  /// Sets the initialization state of the instance. This method was originally intended to be used
  /// in an AudioTrack subclass constructor to set a subclass-specific post-initialization state.
  /// However, subclasses of AudioTrack are no longer recommended, so this method is obsolete.
  ///@param state the state of the AudioTrack instance
  ///@deprecated Only accessible by subclasses, which are not recommended for AudioTrack.
  void setState(int state) => jniAccessors.callMethodWithArgs(
      reference, _id_setState, jni.JniType.voidType, [state]).check();

  static final _id_play = jniAccessors.getMethodIDOf(_classRef, "play", "()V");

  /// from: public void play()
  ///
  /// Starts playing an AudioTrack.
  ///
  /// If track's creation mode is \#MODE_STATIC, you must have called one of
  /// the write methods (\#write(byte[], int, int), \#write(byte[], int, int, int),
  /// \#write(short[], int, int), \#write(short[], int, int, int),
  /// \#write(float[], int, int, int), or \#write(ByteBuffer, int, int)) prior to
  /// play().
  ///
  /// If the mode is \#MODE_STREAM, you can optionally prime the data path prior to
  /// calling play(), by writing up to <code>bufferSizeInBytes</code> (from constructor).
  /// If you don't call write() first, or if you call write() but with an insufficient amount of
  /// data, then the track will be in underrun state at play().  In this case,
  /// playback will not actually start playing until the data path is filled to a
  /// device-specific minimum level.  This requirement for the path to be filled
  /// to a minimum level is also true when resuming audio playback after calling stop().
  /// Similarly the buffer will need to be filled up again after
  /// the track underruns due to failure to call write() in a timely manner with sufficient data.
  /// For portability, an application should prime the data path to the maximum allowed
  /// by writing data until the write() method returns a short transfer count.
  /// This allows play() to start immediately, and reduces the chance of underrun.
  ///@throws IllegalStateException if the track isn't properly initialized
  void play() => jniAccessors.callMethodWithArgs(
      reference, _id_play, jni.JniType.voidType, []).check();

  static final _id_stop = jniAccessors.getMethodIDOf(_classRef, "stop", "()V");

  /// from: public void stop()
  ///
  /// Stops playing the audio data.
  /// When used on an instance created in \#MODE_STREAM mode, audio will stop playing
  /// after the last buffer that was written has been played. For an immediate stop, use
  /// \#pause(), followed by \#flush() to discard audio data that hasn't been played
  /// back yet.
  ///@throws IllegalStateException
  void stop() => jniAccessors.callMethodWithArgs(
      reference, _id_stop, jni.JniType.voidType, []).check();

  static final _id_pause =
      jniAccessors.getMethodIDOf(_classRef, "pause", "()V");

  /// from: public void pause()
  ///
  /// Pauses the playback of the audio data. Data that has not been played
  /// back will not be discarded. Subsequent calls to \#play will play
  /// this data back. See \#flush() to discard this data.
  ///@throws IllegalStateException
  void pause() => jniAccessors.callMethodWithArgs(
      reference, _id_pause, jni.JniType.voidType, []).check();

  static final _id_flush =
      jniAccessors.getMethodIDOf(_classRef, "flush", "()V");

  /// from: public void flush()
  ///
  /// Flushes the audio data currently queued for playback. Any data that has
  /// been written but not yet presented will be discarded.  No-op if not stopped or paused,
  /// or if the track's creation mode is not \#MODE_STREAM.
  /// <BR> Note that although data written but not yet presented is discarded, there is no
  /// guarantee that all of the buffer space formerly used by that data
  /// is available for a subsequent write.
  /// For example, a call to \#write(byte[], int, int) with <code>sizeInBytes</code>
  /// less than or equal to the total buffer size
  /// may return a short actual transfer count.
  void flush() => jniAccessors.callMethodWithArgs(
      reference, _id_flush, jni.JniType.voidType, []).check();

  static final _id_write =
      jniAccessors.getMethodIDOf(_classRef, "write", "([BII)I");

  /// from: public int write(byte[] audioData, int offsetInBytes, int sizeInBytes)
  ///
  /// Writes the audio data to the audio sink for playback (streaming mode),
  /// or copies audio data for later playback (static buffer mode).
  /// The format specified in the AudioTrack constructor should be
  /// AudioFormat\#ENCODING_PCM_8BIT to correspond to the data in the array.
  /// The format can be AudioFormat\#ENCODING_PCM_16BIT, but this is deprecated.
  ///
  /// In streaming mode, the write will normally block until all the data has been enqueued for
  /// playback, and will return a full transfer count.  However, if the track is stopped or paused
  /// on entry, or another thread interrupts the write by calling stop or pause, or an I/O error
  /// occurs during the write, then the write may return a short transfer count.
  ///
  /// In static buffer mode, copies the data to the buffer starting at offset 0.
  /// Note that the actual playback of this data might occur after this function returns.
  ///@param audioData the array that holds the data to play.
  /// This value must never be {@code null}.
  ///@param offsetInBytes the offset expressed in bytes in audioData where the data to write
  ///    starts.
  ///    Must not be negative, or cause the data access to go out of bounds of the array.
  ///@param sizeInBytes the number of bytes to write in audioData after the offset.
  ///    Must not be negative, or cause the data access to go out of bounds of the array.
  ///@return zero or the positive number of bytes that were written, or one of the following
  ///    error codes. The number of bytes will be a multiple of the frame size in bytes
  ///    not to exceed sizeInBytes.
  /// <ul>
  /// <li>\#ERROR_INVALID_OPERATION if the track isn't properly initialized</li>
  /// <li>\#ERROR_BAD_VALUE if the parameters don't resolve to valid data and indexes</li>
  /// <li>\#ERROR_DEAD_OBJECT if the AudioTrack is not valid anymore and
  ///    needs to be recreated. The dead object error code is not returned if some data was
  ///    successfully transferred. In this case, the error is returned at the next write()</li>
  /// <li>\#ERROR in case of other error</li>
  /// </ul>
  /// This is equivalent to \#write(byte[], int, int, int) with <code>writeMode</code>
  /// set to  \#WRITE_BLOCKING.
  int write(jni.JniObject audioData, int offsetInBytes, int sizeInBytes) =>
      jniAccessors.callMethodWithArgs(reference, _id_write, jni.JniType.intType,
          [audioData.reference, offsetInBytes, sizeInBytes]).integer;

  static final _id_write1 =
      jniAccessors.getMethodIDOf(_classRef, "write", "([BIII)I");

  /// from: public int write(byte[] audioData, int offsetInBytes, int sizeInBytes, int writeMode)
  ///
  /// Writes the audio data to the audio sink for playback (streaming mode),
  /// or copies audio data for later playback (static buffer mode).
  /// The format specified in the AudioTrack constructor should be
  /// AudioFormat\#ENCODING_PCM_8BIT to correspond to the data in the array.
  /// The format can be AudioFormat\#ENCODING_PCM_16BIT, but this is deprecated.
  ///
  /// In streaming mode, the blocking behavior depends on the write mode.  If the write mode is
  /// \#WRITE_BLOCKING, the write will normally block until all the data has been enqueued
  /// for playback, and will return a full transfer count.  However, if the write mode is
  /// \#WRITE_NON_BLOCKING, or the track is stopped or paused on entry, or another thread
  /// interrupts the write by calling stop or pause, or an I/O error
  /// occurs during the write, then the write may return a short transfer count.
  ///
  /// In static buffer mode, copies the data to the buffer starting at offset 0,
  /// and the write mode is ignored.
  /// Note that the actual playback of this data might occur after this function returns.
  ///@param audioData the array that holds the data to play.
  /// This value must never be {@code null}.
  ///@param offsetInBytes the offset expressed in bytes in audioData where the data to write
  ///    starts.
  ///    Must not be negative, or cause the data access to go out of bounds of the array.
  ///@param sizeInBytes the number of bytes to write in audioData after the offset.
  ///    Must not be negative, or cause the data access to go out of bounds of the array.
  ///@param writeMode one of \#WRITE_BLOCKING, \#WRITE_NON_BLOCKING. It has no
  ///     effect in static mode.
  ///     <br>With \#WRITE_BLOCKING, the write will block until all data has been written
  ///         to the audio sink.
  ///     <br>With \#WRITE_NON_BLOCKING, the write will return immediately after
  ///     queuing as much audio data for playback as possible without blocking.
  /// Value is android.media.AudioTrack\#WRITE_BLOCKING, or android.media.AudioTrack\#WRITE_NON_BLOCKING
  ///@return zero or the positive number of bytes that were written, or one of the following
  ///    error codes. The number of bytes will be a multiple of the frame size in bytes
  ///    not to exceed sizeInBytes.
  /// <ul>
  /// <li>\#ERROR_INVALID_OPERATION if the track isn't properly initialized</li>
  /// <li>\#ERROR_BAD_VALUE if the parameters don't resolve to valid data and indexes</li>
  /// <li>\#ERROR_DEAD_OBJECT if the AudioTrack is not valid anymore and
  ///    needs to be recreated. The dead object error code is not returned if some data was
  ///    successfully transferred. In this case, the error is returned at the next write()</li>
  /// <li>\#ERROR in case of other error</li>
  /// </ul>
  int write1(jni.JniObject audioData, int offsetInBytes, int sizeInBytes,
          int writeMode) =>
      jniAccessors.callMethodWithArgs(
          reference,
          _id_write1,
          jni.JniType.intType,
          [audioData.reference, offsetInBytes, sizeInBytes, writeMode]).integer;

  static final _id_write2 =
      jniAccessors.getMethodIDOf(_classRef, "write", "([SII)I");

  /// from: public int write(short[] audioData, int offsetInShorts, int sizeInShorts)
  ///
  /// Writes the audio data to the audio sink for playback (streaming mode),
  /// or copies audio data for later playback (static buffer mode).
  /// The format specified in the AudioTrack constructor should be
  /// AudioFormat\#ENCODING_PCM_16BIT to correspond to the data in the array.
  ///
  /// In streaming mode, the write will normally block until all the data has been enqueued for
  /// playback, and will return a full transfer count.  However, if the track is stopped or paused
  /// on entry, or another thread interrupts the write by calling stop or pause, or an I/O error
  /// occurs during the write, then the write may return a short transfer count.
  ///
  /// In static buffer mode, copies the data to the buffer starting at offset 0.
  /// Note that the actual playback of this data might occur after this function returns.
  ///@param audioData the array that holds the data to play.
  /// This value must never be {@code null}.
  ///@param offsetInShorts the offset expressed in shorts in audioData where the data to play
  ///     starts.
  ///    Must not be negative, or cause the data access to go out of bounds of the array.
  ///@param sizeInShorts the number of shorts to read in audioData after the offset.
  ///    Must not be negative, or cause the data access to go out of bounds of the array.
  ///@return zero or the positive number of shorts that were written, or one of the following
  ///    error codes. The number of shorts will be a multiple of the channel count not to
  ///    exceed sizeInShorts.
  /// <ul>
  /// <li>\#ERROR_INVALID_OPERATION if the track isn't properly initialized</li>
  /// <li>\#ERROR_BAD_VALUE if the parameters don't resolve to valid data and indexes</li>
  /// <li>\#ERROR_DEAD_OBJECT if the AudioTrack is not valid anymore and
  ///    needs to be recreated. The dead object error code is not returned if some data was
  ///    successfully transferred. In this case, the error is returned at the next write()</li>
  /// <li>\#ERROR in case of other error</li>
  /// </ul>
  /// This is equivalent to \#write(short[], int, int, int) with <code>writeMode</code>
  /// set to  \#WRITE_BLOCKING.
  int write2(jni.JniObject audioData, int offsetInShorts, int sizeInShorts) =>
      jniAccessors.callMethodWithArgs(
          reference,
          _id_write2,
          jni.JniType.intType,
          [audioData.reference, offsetInShorts, sizeInShorts]).integer;

  static final _id_write3 =
      jniAccessors.getMethodIDOf(_classRef, "write", "([SIII)I");

  /// from: public int write(short[] audioData, int offsetInShorts, int sizeInShorts, int writeMode)
  ///
  /// Writes the audio data to the audio sink for playback (streaming mode),
  /// or copies audio data for later playback (static buffer mode).
  /// The format specified in the AudioTrack constructor should be
  /// AudioFormat\#ENCODING_PCM_16BIT to correspond to the data in the array.
  ///
  /// In streaming mode, the blocking behavior depends on the write mode.  If the write mode is
  /// \#WRITE_BLOCKING, the write will normally block until all the data has been enqueued
  /// for playback, and will return a full transfer count.  However, if the write mode is
  /// \#WRITE_NON_BLOCKING, or the track is stopped or paused on entry, or another thread
  /// interrupts the write by calling stop or pause, or an I/O error
  /// occurs during the write, then the write may return a short transfer count.
  ///
  /// In static buffer mode, copies the data to the buffer starting at offset 0.
  /// Note that the actual playback of this data might occur after this function returns.
  ///@param audioData the array that holds the data to write.
  /// This value must never be {@code null}.
  ///@param offsetInShorts the offset expressed in shorts in audioData where the data to write
  ///     starts.
  ///    Must not be negative, or cause the data access to go out of bounds of the array.
  ///@param sizeInShorts the number of shorts to read in audioData after the offset.
  ///    Must not be negative, or cause the data access to go out of bounds of the array.
  ///@param writeMode one of \#WRITE_BLOCKING, \#WRITE_NON_BLOCKING. It has no
  ///     effect in static mode.
  ///     <br>With \#WRITE_BLOCKING, the write will block until all data has been written
  ///         to the audio sink.
  ///     <br>With \#WRITE_NON_BLOCKING, the write will return immediately after
  ///     queuing as much audio data for playback as possible without blocking.
  /// Value is android.media.AudioTrack\#WRITE_BLOCKING, or android.media.AudioTrack\#WRITE_NON_BLOCKING
  ///@return zero or the positive number of shorts that were written, or one of the following
  ///    error codes. The number of shorts will be a multiple of the channel count not to
  ///    exceed sizeInShorts.
  /// <ul>
  /// <li>\#ERROR_INVALID_OPERATION if the track isn't properly initialized</li>
  /// <li>\#ERROR_BAD_VALUE if the parameters don't resolve to valid data and indexes</li>
  /// <li>\#ERROR_DEAD_OBJECT if the AudioTrack is not valid anymore and
  ///    needs to be recreated. The dead object error code is not returned if some data was
  ///    successfully transferred. In this case, the error is returned at the next write()</li>
  /// <li>\#ERROR in case of other error</li>
  /// </ul>
  int write3(jni.JniObject audioData, int offsetInShorts, int sizeInShorts,
          int writeMode) =>
      jniAccessors.callMethodWithArgs(
          reference, _id_write3, jni.JniType.intType, [
        audioData.reference,
        offsetInShorts,
        sizeInShorts,
        writeMode
      ]).integer;

  static final _id_write4 =
      jniAccessors.getMethodIDOf(_classRef, "write", "([FIII)I");

  /// from: public int write(float[] audioData, int offsetInFloats, int sizeInFloats, int writeMode)
  ///
  /// Writes the audio data to the audio sink for playback (streaming mode),
  /// or copies audio data for later playback (static buffer mode).
  /// The format specified in the AudioTrack constructor should be
  /// AudioFormat\#ENCODING_PCM_FLOAT to correspond to the data in the array.
  ///
  /// In streaming mode, the blocking behavior depends on the write mode.  If the write mode is
  /// \#WRITE_BLOCKING, the write will normally block until all the data has been enqueued
  /// for playback, and will return a full transfer count.  However, if the write mode is
  /// \#WRITE_NON_BLOCKING, or the track is stopped or paused on entry, or another thread
  /// interrupts the write by calling stop or pause, or an I/O error
  /// occurs during the write, then the write may return a short transfer count.
  ///
  /// In static buffer mode, copies the data to the buffer starting at offset 0,
  /// and the write mode is ignored.
  /// Note that the actual playback of this data might occur after this function returns.
  ///@param audioData the array that holds the data to write.
  ///     The implementation does not clip for sample values within the nominal range
  ///     [-1.0f, 1.0f], provided that all gains in the audio pipeline are
  ///     less than or equal to unity (1.0f), and in the absence of post-processing effects
  ///     that could add energy, such as reverb.  For the convenience of applications
  ///     that compute samples using filters with non-unity gain,
  ///     sample values +3 dB beyond the nominal range are permitted.
  ///     However such values may eventually be limited or clipped, depending on various gains
  ///     and later processing in the audio path.  Therefore applications are encouraged
  ///     to provide samples values within the nominal range.
  /// This value must never be {@code null}.
  ///@param offsetInFloats the offset, expressed as a number of floats,
  ///     in audioData where the data to write starts.
  ///    Must not be negative, or cause the data access to go out of bounds of the array.
  ///@param sizeInFloats the number of floats to write in audioData after the offset.
  ///    Must not be negative, or cause the data access to go out of bounds of the array.
  ///@param writeMode one of \#WRITE_BLOCKING, \#WRITE_NON_BLOCKING. It has no
  ///     effect in static mode.
  ///     <br>With \#WRITE_BLOCKING, the write will block until all data has been written
  ///         to the audio sink.
  ///     <br>With \#WRITE_NON_BLOCKING, the write will return immediately after
  ///     queuing as much audio data for playback as possible without blocking.
  /// Value is android.media.AudioTrack\#WRITE_BLOCKING, or android.media.AudioTrack\#WRITE_NON_BLOCKING
  ///@return zero or the positive number of floats that were written, or one of the following
  ///    error codes. The number of floats will be a multiple of the channel count not to
  ///    exceed sizeInFloats.
  /// <ul>
  /// <li>\#ERROR_INVALID_OPERATION if the track isn't properly initialized</li>
  /// <li>\#ERROR_BAD_VALUE if the parameters don't resolve to valid data and indexes</li>
  /// <li>\#ERROR_DEAD_OBJECT if the AudioTrack is not valid anymore and
  ///    needs to be recreated. The dead object error code is not returned if some data was
  ///    successfully transferred. In this case, the error is returned at the next write()</li>
  /// <li>\#ERROR in case of other error</li>
  /// </ul>
  int write4(jni.JniObject audioData, int offsetInFloats, int sizeInFloats,
          int writeMode) =>
      jniAccessors.callMethodWithArgs(
          reference, _id_write4, jni.JniType.intType, [
        audioData.reference,
        offsetInFloats,
        sizeInFloats,
        writeMode
      ]).integer;

  static final _id_write5 = jniAccessors.getMethodIDOf(
      _classRef, "write", "(Ljava/nio/ByteBuffer;II)I");

  /// from: public int write(java.nio.ByteBuffer audioData, int sizeInBytes, int writeMode)
  ///
  /// Writes the audio data to the audio sink for playback (streaming mode),
  /// or copies audio data for later playback (static buffer mode).
  /// The audioData in ByteBuffer should match the format specified in the AudioTrack constructor.
  ///
  /// In streaming mode, the blocking behavior depends on the write mode.  If the write mode is
  /// \#WRITE_BLOCKING, the write will normally block until all the data has been enqueued
  /// for playback, and will return a full transfer count.  However, if the write mode is
  /// \#WRITE_NON_BLOCKING, or the track is stopped or paused on entry, or another thread
  /// interrupts the write by calling stop or pause, or an I/O error
  /// occurs during the write, then the write may return a short transfer count.
  ///
  /// In static buffer mode, copies the data to the buffer starting at offset 0,
  /// and the write mode is ignored.
  /// Note that the actual playback of this data might occur after this function returns.
  ///@param audioData the buffer that holds the data to write, starting at the position reported
  ///     by <code>audioData.position()</code>.
  ///     <BR>Note that upon return, the buffer position (<code>audioData.position()</code>) will
  ///     have been advanced to reflect the amount of data that was successfully written to
  ///     the AudioTrack.
  /// This value must never be {@code null}.
  ///@param sizeInBytes number of bytes to write.  It is recommended but not enforced
  ///     that the number of bytes requested be a multiple of the frame size (sample size in
  ///     bytes multiplied by the channel count).
  ///     <BR>Note this may differ from <code>audioData.remaining()</code>, but cannot exceed it.
  ///@param writeMode one of \#WRITE_BLOCKING, \#WRITE_NON_BLOCKING. It has no
  ///     effect in static mode.
  ///     <BR>With \#WRITE_BLOCKING, the write will block until all data has been written
  ///         to the audio sink.
  ///     <BR>With \#WRITE_NON_BLOCKING, the write will return immediately after
  ///     queuing as much audio data for playback as possible without blocking.
  /// Value is android.media.AudioTrack\#WRITE_BLOCKING, or android.media.AudioTrack\#WRITE_NON_BLOCKING
  ///@return zero or the positive number of bytes that were written, or one of the following
  ///    error codes.
  /// <ul>
  /// <li>\#ERROR_INVALID_OPERATION if the track isn't properly initialized</li>
  /// <li>\#ERROR_BAD_VALUE if the parameters don't resolve to valid data and indexes</li>
  /// <li>\#ERROR_DEAD_OBJECT if the AudioTrack is not valid anymore and
  ///    needs to be recreated. The dead object error code is not returned if some data was
  ///    successfully transferred. In this case, the error is returned at the next write()</li>
  /// <li>\#ERROR in case of other error</li>
  /// </ul>
  int write5(jni.JniObject audioData, int sizeInBytes, int writeMode) =>
      jniAccessors.callMethodWithArgs(
          reference,
          _id_write5,
          jni.JniType.intType,
          [audioData.reference, sizeInBytes, writeMode]).integer;

  static final _id_write6 = jniAccessors.getMethodIDOf(
      _classRef, "write", "(Ljava/nio/ByteBuffer;IIJ)I");

  /// from: public int write(java.nio.ByteBuffer audioData, int sizeInBytes, int writeMode, long timestamp)
  ///
  /// Writes the audio data to the audio sink for playback in streaming mode on a HW_AV_SYNC track.
  /// The blocking behavior will depend on the write mode.
  ///@param audioData the buffer that holds the data to write, starting at the position reported
  ///     by <code>audioData.position()</code>.
  ///     <BR>Note that upon return, the buffer position (<code>audioData.position()</code>) will
  ///     have been advanced to reflect the amount of data that was successfully written to
  ///     the AudioTrack.
  /// This value must never be {@code null}.
  ///@param sizeInBytes number of bytes to write.  It is recommended but not enforced
  ///     that the number of bytes requested be a multiple of the frame size (sample size in
  ///     bytes multiplied by the channel count).
  ///     <BR>Note this may differ from <code>audioData.remaining()</code>, but cannot exceed it.
  ///@param writeMode one of \#WRITE_BLOCKING, \#WRITE_NON_BLOCKING.
  ///     <BR>With \#WRITE_BLOCKING, the write will block until all data has been written
  ///         to the audio sink.
  ///     <BR>With \#WRITE_NON_BLOCKING, the write will return immediately after
  ///     queuing as much audio data for playback as possible without blocking.
  /// Value is android.media.AudioTrack\#WRITE_BLOCKING, or android.media.AudioTrack\#WRITE_NON_BLOCKING
  ///@param timestamp The timestamp of the first decodable audio frame in the provided audioData.
  ///@return zero or the positive number of bytes that were written, or one of the following
  ///    error codes.
  /// <ul>
  /// <li>\#ERROR_INVALID_OPERATION if the track isn't properly initialized</li>
  /// <li>\#ERROR_BAD_VALUE if the parameters don't resolve to valid data and indexes</li>
  /// <li>\#ERROR_DEAD_OBJECT if the AudioTrack is not valid anymore and
  ///    needs to be recreated. The dead object error code is not returned if some data was
  ///    successfully transferred. In this case, the error is returned at the next write()</li>
  /// <li>\#ERROR in case of other error</li>
  /// </ul>
  int write6(jni.JniObject audioData, int sizeInBytes, int writeMode,
          int timestamp) =>
      jniAccessors.callMethodWithArgs(
          reference,
          _id_write6,
          jni.JniType.intType,
          [audioData.reference, sizeInBytes, writeMode, timestamp]).integer;

  static final _id_reloadStaticData =
      jniAccessors.getMethodIDOf(_classRef, "reloadStaticData", "()I");

  /// from: public int reloadStaticData()
  ///
  /// Sets the playback head position within the static buffer to zero,
  /// that is it rewinds to start of static buffer.
  /// The track must be stopped or paused, and
  /// the track's creation mode must be \#MODE_STATIC.
  ///
  /// As of android.os.Build.VERSION_CODES\#M, also resets the value returned by
  /// \#getPlaybackHeadPosition() to zero.
  /// For earlier API levels, the reset behavior is unspecified.
  ///
  /// Use \#setPlaybackHeadPosition(int) with a zero position
  /// if the reset of <code>getPlaybackHeadPosition()</code> is not needed.
  ///@return error code or success, see \#SUCCESS, \#ERROR_BAD_VALUE,
  ///  \#ERROR_INVALID_OPERATION
  int reloadStaticData() => jniAccessors.callMethodWithArgs(
      reference, _id_reloadStaticData, jni.JniType.intType, []).integer;

  static final _id_attachAuxEffect =
      jniAccessors.getMethodIDOf(_classRef, "attachAuxEffect", "(I)I");

  /// from: public int attachAuxEffect(int effectId)
  ///
  /// Attaches an auxiliary effect to the audio track. A typical auxiliary
  /// effect is a reverberation effect which can be applied on any sound source
  /// that directs a certain amount of its energy to this effect. This amount
  /// is defined by setAuxEffectSendLevel().
  /// {@see \#setAuxEffectSendLevel(float)}.
  /// After creating an auxiliary effect (e.g.
  /// android.media.audiofx.EnvironmentalReverb), retrieve its ID with
  /// android.media.audiofx.AudioEffect\#getId() and use it when calling
  /// this method to attach the audio track to the effect.
  /// To detach the effect from the audio track, call this method with a
  /// null effect id.
  ///@param effectId system wide unique id of the effect to attach
  ///@return error code or success, see \#SUCCESS,
  ///    \#ERROR_INVALID_OPERATION, \#ERROR_BAD_VALUE
  int attachAuxEffect(int effectId) => jniAccessors.callMethodWithArgs(
      reference, _id_attachAuxEffect, jni.JniType.intType, [effectId]).integer;

  static final _id_setAuxEffectSendLevel =
      jniAccessors.getMethodIDOf(_classRef, "setAuxEffectSendLevel", "(F)I");

  /// from: public int setAuxEffectSendLevel(float level)
  ///
  /// Sets the send level of the audio track to the attached auxiliary effect
  /// \#attachAuxEffect(int).  Effect levels
  /// are clamped to the closed interval [0.0, max] where
  /// max is the value of \#getMaxVolume.
  /// A value of 0.0 results in no effect, and a value of 1.0 is full send.
  /// By default the send level is 0.0f, so even if an effect is attached to the player
  /// this method must be called for the effect to be applied.
  /// Note that the passed level value is a linear scalar. UI controls should be scaled
  /// logarithmically: the gain applied by audio framework ranges from -72dB to at least 0dB,
  /// so an appropriate conversion from linear UI input x to level is:
  /// x == 0 -&gt; level = 0
  /// 0 &lt; x &lt;= R -&gt; level = 10^(72*(x-R)/20/R)
  ///@param level linear send level
  ///@return error code or success, see \#SUCCESS,
  ///    \#ERROR_INVALID_OPERATION, \#ERROR
  int setAuxEffectSendLevel(double level) => jniAccessors.callMethodWithArgs(
      reference,
      _id_setAuxEffectSendLevel,
      jni.JniType.intType,
      [level]).integer;

  static final _id_setPreferredDevice = jniAccessors.getMethodIDOf(
      _classRef, "setPreferredDevice", "(Landroid/media/AudioDeviceInfo;)Z");

  /// from: public boolean setPreferredDevice(android.media.AudioDeviceInfo deviceInfo)
  ///
  /// Specifies an audio device (via an AudioDeviceInfo object) to route
  /// the output from this AudioTrack.
  ///@param deviceInfo The AudioDeviceInfo specifying the audio sink.
  ///  If deviceInfo is null, default routing is restored.
  ///@return true if succesful, false if the specified AudioDeviceInfo is non-null and
  /// does not correspond to a valid audio output device.
  bool setPreferredDevice(audiodeviceinfo_.AudioDeviceInfo deviceInfo) =>
      jniAccessors.callMethodWithArgs(reference, _id_setPreferredDevice,
          jni.JniType.booleanType, [deviceInfo.reference]).boolean;

  static final _id_getPreferredDevice = jniAccessors.getMethodIDOf(
      _classRef, "getPreferredDevice", "()Landroid/media/AudioDeviceInfo;");

  /// from: public android.media.AudioDeviceInfo getPreferredDevice()
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// Returns the selected output specified by \#setPreferredDevice. Note that this
  /// is not guaranteed to correspond to the actual device being used for playback.
  audiodeviceinfo_.AudioDeviceInfo getPreferredDevice() =>
      audiodeviceinfo_.AudioDeviceInfo.fromRef(jniAccessors.callMethodWithArgs(
          reference,
          _id_getPreferredDevice,
          jni.JniType.objectType, []).object);

  static final _id_getRoutedDevice = jniAccessors.getMethodIDOf(
      _classRef, "getRoutedDevice", "()Landroid/media/AudioDeviceInfo;");

  /// from: public android.media.AudioDeviceInfo getRoutedDevice()
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// Returns an AudioDeviceInfo identifying the current routing of this AudioTrack.
  /// Note: The query is only valid if the AudioTrack is currently playing. If it is not,
  /// <code>getRoutedDevice()</code> will return null.
  audiodeviceinfo_.AudioDeviceInfo getRoutedDevice() =>
      audiodeviceinfo_.AudioDeviceInfo.fromRef(jniAccessors.callMethodWithArgs(
          reference, _id_getRoutedDevice, jni.JniType.objectType, []).object);

  static final _id_addOnRoutingChangedListener = jniAccessors.getMethodIDOf(
      _classRef,
      "addOnRoutingChangedListener",
      "(Landroid/media/AudioRouting\$OnRoutingChangedListener;Landroid/os/Handler;)V");

  /// from: public void addOnRoutingChangedListener(android.media.AudioRouting.OnRoutingChangedListener listener, android.os.Handler handler)
  ///
  /// Adds an AudioRouting.OnRoutingChangedListener to receive notifications of routing
  /// changes on this AudioTrack.
  ///@param listener The AudioRouting.OnRoutingChangedListener interface to receive
  /// notifications of rerouting events.
  ///@param handler Specifies the Handler object for the thread on which to execute
  /// the callback. If <code>null</code>, the Handler associated with the main
  /// Looper will be used.
  void addOnRoutingChangedListener(
          audiorouting_.AudioRouting_OnRoutingChangedListener listener,
          handler_.Handler handler) =>
      jniAccessors.callMethodWithArgs(
          reference,
          _id_addOnRoutingChangedListener,
          jni.JniType.voidType,
          [listener.reference, handler.reference]).check();

  static final _id_removeOnRoutingChangedListener = jniAccessors.getMethodIDOf(
      _classRef,
      "removeOnRoutingChangedListener",
      "(Landroid/media/AudioRouting\$OnRoutingChangedListener;)V");

  /// from: public void removeOnRoutingChangedListener(android.media.AudioRouting.OnRoutingChangedListener listener)
  ///
  /// Removes an AudioRouting.OnRoutingChangedListener which has been previously added
  /// to receive rerouting notifications.
  ///@param listener The previously added AudioRouting.OnRoutingChangedListener interface
  /// to remove.
  void removeOnRoutingChangedListener(
          audiorouting_.AudioRouting_OnRoutingChangedListener listener) =>
      jniAccessors.callMethodWithArgs(
          reference,
          _id_removeOnRoutingChangedListener,
          jni.JniType.voidType,
          [listener.reference]).check();

  static final _id_addOnRoutingChangedListener1 = jniAccessors.getMethodIDOf(
      _classRef,
      "addOnRoutingChangedListener",
      "(Landroid/media/AudioTrack\$OnRoutingChangedListener;Landroid/os/Handler;)V");

  /// from: public void addOnRoutingChangedListener(android.media.AudioTrack.OnRoutingChangedListener listener, android.os.Handler handler)
  ///
  /// Adds an OnRoutingChangedListener to receive notifications of routing changes
  /// on this AudioTrack.
  ///@param listener The OnRoutingChangedListener interface to receive notifications
  /// of rerouting events.
  ///@param handler Specifies the Handler object for the thread on which to execute
  /// the callback. If <code>null</code>, the Handler associated with the main
  /// Looper will be used.
  ///@deprecated users should switch to the general purpose
  ///             AudioRouting.OnRoutingChangedListener class instead.
  void addOnRoutingChangedListener1(
          AudioTrack_OnRoutingChangedListener listener,
          handler_.Handler handler) =>
      jniAccessors.callMethodWithArgs(
          reference,
          _id_addOnRoutingChangedListener1,
          jni.JniType.voidType,
          [listener.reference, handler.reference]).check();

  static final _id_removeOnRoutingChangedListener1 = jniAccessors.getMethodIDOf(
      _classRef,
      "removeOnRoutingChangedListener",
      "(Landroid/media/AudioTrack\$OnRoutingChangedListener;)V");

  /// from: public void removeOnRoutingChangedListener(android.media.AudioTrack.OnRoutingChangedListener listener)
  ///
  /// Removes an OnRoutingChangedListener which has been previously added
  /// to receive rerouting notifications.
  ///@param listener The previously added OnRoutingChangedListener interface to remove.
  ///@deprecated users should switch to the general purpose
  ///             AudioRouting.OnRoutingChangedListener class instead.
  void removeOnRoutingChangedListener1(
          AudioTrack_OnRoutingChangedListener listener) =>
      jniAccessors.callMethodWithArgs(
          reference,
          _id_removeOnRoutingChangedListener1,
          jni.JniType.voidType,
          [listener.reference]).check();
}

/// from: android.media.AudioTrack$OnRoutingChangedListener
///
/// Defines the interface by which applications can receive notifications of
/// routing changes for the associated AudioTrack.
///@deprecated users should switch to the general purpose
///             AudioRouting.OnRoutingChangedListener class instead.
class AudioTrack_OnRoutingChangedListener extends jni.JniObject {
  static final _classRef = jniAccessors
      .getClassOf("android/media/AudioTrack\$OnRoutingChangedListener");
  AudioTrack_OnRoutingChangedListener.fromRef(jni.JObject ref)
      : super.fromRef(ref);

  static final _id_onRoutingChanged = jniAccessors.getMethodIDOf(
      _classRef, "onRoutingChanged", "(Landroid/media/AudioTrack;)V");

  /// from: public abstract void onRoutingChanged(android.media.AudioTrack audioTrack)
  ///
  /// Called when the routing of an AudioTrack changes from either and
  /// explicit or policy rerouting. Use \#getRoutedDevice() to
  /// retrieve the newly routed-to device.
  void onRoutingChanged(AudioTrack audioTrack) =>
      jniAccessors.callMethodWithArgs(reference, _id_onRoutingChanged,
          jni.JniType.voidType, [audioTrack.reference]).check();

  static final _id_onRoutingChanged1 = jniAccessors.getMethodIDOf(
      _classRef, "onRoutingChanged", "(Landroid/media/AudioRouting;)V");

  /// from: default public void onRoutingChanged(android.media.AudioRouting router)
  void onRoutingChanged1(audiorouting_.AudioRouting router) =>
      jniAccessors.callMethodWithArgs(reference, _id_onRoutingChanged1,
          jni.JniType.voidType, [router.reference]).check();
}

/// from: android.media.AudioTrack$OnPlaybackPositionUpdateListener
///
/// Interface definition for a callback to be invoked when the playback head position of
/// an AudioTrack has reached a notification marker or has increased by a certain period.
class AudioTrack_OnPlaybackPositionUpdateListener extends jni.JniObject {
  static final _classRef = jniAccessors
      .getClassOf("android/media/AudioTrack\$OnPlaybackPositionUpdateListener");
  AudioTrack_OnPlaybackPositionUpdateListener.fromRef(jni.JObject ref)
      : super.fromRef(ref);

  static final _id_onMarkerReached = jniAccessors.getMethodIDOf(
      _classRef, "onMarkerReached", "(Landroid/media/AudioTrack;)V");

  /// from: public abstract void onMarkerReached(android.media.AudioTrack track)
  ///
  /// Called on the listener to notify it that the previously set marker has been reached
  /// by the playback head.
  void onMarkerReached(AudioTrack track) => jniAccessors.callMethodWithArgs(
      reference,
      _id_onMarkerReached,
      jni.JniType.voidType,
      [track.reference]).check();

  static final _id_onPeriodicNotification = jniAccessors.getMethodIDOf(
      _classRef, "onPeriodicNotification", "(Landroid/media/AudioTrack;)V");

  /// from: public abstract void onPeriodicNotification(android.media.AudioTrack track)
  ///
  /// Called on the listener to periodically notify it that the playback head has reached
  /// a multiple of the notification period.
  void onPeriodicNotification(AudioTrack track) =>
      jniAccessors.callMethodWithArgs(reference, _id_onPeriodicNotification,
          jni.JniType.voidType, [track.reference]).check();
}

/// from: android.media.AudioTrack$MetricsConstants
class AudioTrack_MetricsConstants extends jni.JniObject {
  static final _classRef =
      jniAccessors.getClassOf("android/media/AudioTrack\$MetricsConstants");
  AudioTrack_MetricsConstants.fromRef(jni.JObject ref) : super.fromRef(ref);

  /// from: static public final java.lang.String CHANNELMASK
  ///
  /// Key to extract the channel mask information for this track
  /// from the AudioTrack\#getMetrics return value.
  ///
  /// The value is a Long integer.
  static const CHANNELMASK = "android.media.audiorecord.channelmask";

  /// from: static public final java.lang.String CONTENTTYPE
  ///
  /// Key to extract the Content Type for this track
  /// from the AudioTrack\#getMetrics return value.
  /// The value is a String.
  static const CONTENTTYPE = "android.media.audiotrack.type";

  /// from: static public final java.lang.String SAMPLERATE
  ///
  /// Key to extract the sample rate for this track in Hz
  /// from the AudioTrack\#getMetrics return value.
  /// The value is an integer.
  static const SAMPLERATE = "android.media.audiorecord.samplerate";

  /// from: static public final java.lang.String STREAMTYPE
  ///
  /// Key to extract the Stream Type for this track
  /// from the AudioTrack\#getMetrics return value.
  /// The value is a String.
  static const STREAMTYPE = "android.media.audiotrack.streamtype";

  /// from: static public final java.lang.String USAGE
  ///
  /// Key to extract the Content Type for this track
  /// from the AudioTrack\#getMetrics return value.
  /// The value is a String.
  static const USAGE = "android.media.audiotrack.usage";

  static final _id_ctor =
      jniAccessors.getMethodIDOf(_classRef, "<init>", "()V");

  /// from: void <init>()
  /// The returned object must be deleted after use, by calling the `delete` method.
  AudioTrack_MetricsConstants()
      : super.fromRef(
            jniAccessors.newObjectWithArgs(_classRef, _id_ctor, []).object);
}

/// from: android.media.AudioTrack$Builder
///
/// Builder class for AudioTrack objects.
/// Use this class to configure and create an <code>AudioTrack</code> instance. By setting audio
/// attributes and audio format parameters, you indicate which of those vary from the default
/// behavior on the device.
///  Here is an example where <code>Builder</code> is used to specify all AudioFormat
/// parameters, to be used by a new <code>AudioTrack</code> instance:
///
/// <pre class="prettyprint">
/// AudioTrack player = new AudioTrack.Builder()
///         .setAudioAttributes(new AudioAttributes.Builder()
///                  .setUsage(AudioAttributes.USAGE_ALARM)
///                  .setContentType(AudioAttributes.CONTENT_TYPE_MUSIC)
///                  .build())
///         .setAudioFormat(new AudioFormat.Builder()
///                 .setEncoding(AudioFormat.ENCODING_PCM_16BIT)
///                 .setSampleRate(44100)
///                 .setChannelMask(AudioFormat.CHANNEL_OUT_STEREO)
///                 .build())
///         .setBufferSizeInBytes(minBuffSize)
///         .build();
/// </pre>
///
/// If the audio attributes are not set with \#setAudioAttributes(AudioAttributes),
/// attributes comprising AudioAttributes\#USAGE_MEDIA will be used.
/// <br>If the audio format is not specified or is incomplete, its channel configuration will be
/// AudioFormat\#CHANNEL_OUT_STEREO and the encoding will be
/// AudioFormat\#ENCODING_PCM_16BIT.
/// The sample rate will depend on the device actually selected for playback and can be queried
/// with \#getSampleRate() method.
/// <br>If the buffer size is not specified with \#setBufferSizeInBytes(int),
/// and the mode is AudioTrack\#MODE_STREAM, the minimum buffer size is used.
/// <br>If the transfer mode is not specified with \#setTransferMode(int),
/// <code>MODE_STREAM</code> will be used.
/// <br>If the session ID is not specified with \#setSessionId(int), a new one will
/// be generated.
/// <br>Offload is false by default.
class AudioTrack_Builder extends jni.JniObject {
  static final _classRef =
      jniAccessors.getClassOf("android/media/AudioTrack\$Builder");
  AudioTrack_Builder.fromRef(jni.JObject ref) : super.fromRef(ref);

  static final _id_ctor =
      jniAccessors.getMethodIDOf(_classRef, "<init>", "()V");

  /// from: public void <init>()
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// Constructs a new Builder with the default values as described above.
  AudioTrack_Builder()
      : super.fromRef(
            jniAccessors.newObjectWithArgs(_classRef, _id_ctor, []).object);

  static final _id_setAudioAttributes = jniAccessors.getMethodIDOf(
      _classRef,
      "setAudioAttributes",
      "(Landroid/media/AudioAttributes;)Landroid/media/AudioTrack\$Builder;");

  /// from: public android.media.AudioTrack.Builder setAudioAttributes(android.media.AudioAttributes attributes)
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// Sets the AudioAttributes.
  ///@param attributes a non-null AudioAttributes instance that describes the audio
  ///     data to be played.
  /// This value must never be {@code null}.
  ///@return the same Builder instance.
  ///@throws IllegalArgumentException
  AudioTrack_Builder setAudioAttributes(
          audioattributes_.AudioAttributes attributes) =>
      AudioTrack_Builder.fromRef(jniAccessors.callMethodWithArgs(
          reference,
          _id_setAudioAttributes,
          jni.JniType.objectType,
          [attributes.reference]).object);

  static final _id_setAudioFormat = jniAccessors.getMethodIDOf(
      _classRef,
      "setAudioFormat",
      "(Landroid/media/AudioFormat;)Landroid/media/AudioTrack\$Builder;");

  /// from: public android.media.AudioTrack.Builder setAudioFormat(android.media.AudioFormat format)
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// Sets the format of the audio data to be played by the AudioTrack.
  /// See AudioFormat.Builder for configuring the audio format parameters such
  /// as encoding, channel mask and sample rate.
  ///@param format a non-null AudioFormat instance.
  /// This value must never be {@code null}.
  ///@return the same Builder instance.
  ///@throws IllegalArgumentException
  AudioTrack_Builder setAudioFormat(audioformat_.AudioFormat format) =>
      AudioTrack_Builder.fromRef(jniAccessors.callMethodWithArgs(
          reference,
          _id_setAudioFormat,
          jni.JniType.objectType,
          [format.reference]).object);

  static final _id_setBufferSizeInBytes = jniAccessors.getMethodIDOf(_classRef,
      "setBufferSizeInBytes", "(I)Landroid/media/AudioTrack\$Builder;");

  /// from: public android.media.AudioTrack.Builder setBufferSizeInBytes(int bufferSizeInBytes)
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// Sets the total size (in bytes) of the buffer where audio data is read from for playback.
  /// If using the AudioTrack in streaming mode
  /// (see AudioTrack\#MODE_STREAM, you can write data into this buffer in smaller
  /// chunks than this size. See \#getMinBufferSize(int, int, int) to determine
  /// the estimated minimum buffer size for the creation of an AudioTrack instance
  /// in streaming mode.
  /// <br>If using the <code>AudioTrack</code> in static mode (see
  /// AudioTrack\#MODE_STATIC), this is the maximum size of the sound that will be
  /// played by this instance.
  ///@param bufferSizeInBytes
  ///@return the same Builder instance.
  /// This value will never be {@code null}.
  ///@throws IllegalArgumentException
  AudioTrack_Builder setBufferSizeInBytes(int bufferSizeInBytes) =>
      AudioTrack_Builder.fromRef(jniAccessors.callMethodWithArgs(
          reference,
          _id_setBufferSizeInBytes,
          jni.JniType.objectType,
          [bufferSizeInBytes]).object);

  static final _id_setTransferMode = jniAccessors.getMethodIDOf(
      _classRef, "setTransferMode", "(I)Landroid/media/AudioTrack\$Builder;");

  /// from: public android.media.AudioTrack.Builder setTransferMode(int mode)
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// Sets the mode under which buffers of audio data are transferred from the
  /// AudioTrack to the framework.
  ///@param mode one of AudioTrack\#MODE_STREAM, AudioTrack\#MODE_STATIC.
  /// Value is android.media.AudioTrack\#MODE_STATIC, or android.media.AudioTrack\#MODE_STREAM
  ///@return the same Builder instance.
  /// This value will never be {@code null}.
  ///@throws IllegalArgumentException
  AudioTrack_Builder setTransferMode(int mode) =>
      AudioTrack_Builder.fromRef(jniAccessors.callMethodWithArgs(reference,
          _id_setTransferMode, jni.JniType.objectType, [mode]).object);

  static final _id_setSessionId = jniAccessors.getMethodIDOf(
      _classRef, "setSessionId", "(I)Landroid/media/AudioTrack\$Builder;");

  /// from: public android.media.AudioTrack.Builder setSessionId(int sessionId)
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// Sets the session ID the AudioTrack will be attached to.
  ///@param sessionId a strictly positive ID number retrieved from another
  ///     <code>AudioTrack</code> via AudioTrack\#getAudioSessionId() or allocated by
  ///     AudioManager via AudioManager\#generateAudioSessionId(), or
  ///     AudioManager\#AUDIO_SESSION_ID_GENERATE.
  ///@return the same Builder instance.
  /// This value will never be {@code null}.
  ///@throws IllegalArgumentException
  AudioTrack_Builder setSessionId(int sessionId) =>
      AudioTrack_Builder.fromRef(jniAccessors.callMethodWithArgs(reference,
          _id_setSessionId, jni.JniType.objectType, [sessionId]).object);

  static final _id_setPerformanceMode = jniAccessors.getMethodIDOf(_classRef,
      "setPerformanceMode", "(I)Landroid/media/AudioTrack\$Builder;");

  /// from: public android.media.AudioTrack.Builder setPerformanceMode(int performanceMode)
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// Sets the AudioTrack performance mode.  This is an advisory request which
  /// may not be supported by the particular device, and the framework is free
  /// to ignore such request if it is incompatible with other requests or hardware.
  ///@param performanceMode one of
  /// AudioTrack\#PERFORMANCE_MODE_NONE,
  /// AudioTrack\#PERFORMANCE_MODE_LOW_LATENCY,
  /// or AudioTrack\#PERFORMANCE_MODE_POWER_SAVING.
  /// Value is android.media.AudioTrack\#PERFORMANCE_MODE_NONE, android.media.AudioTrack\#PERFORMANCE_MODE_LOW_LATENCY, or android.media.AudioTrack\#PERFORMANCE_MODE_POWER_SAVING
  ///@return the same Builder instance.
  /// This value will never be {@code null}.
  ///@throws IllegalArgumentException if {@code performanceMode} is not valid.
  AudioTrack_Builder setPerformanceMode(int performanceMode) =>
      AudioTrack_Builder.fromRef(jniAccessors.callMethodWithArgs(
          reference,
          _id_setPerformanceMode,
          jni.JniType.objectType,
          [performanceMode]).object);

  static final _id_build = jniAccessors.getMethodIDOf(
      _classRef, "build", "()Landroid/media/AudioTrack;");

  /// from: public android.media.AudioTrack build()
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// Builds an AudioTrack instance initialized with all the parameters set
  /// on this <code>Builder</code>.
  ///@return a new successfully initialized AudioTrack instance.
  /// This value will never be {@code null}.
  ///@throws UnsupportedOperationException if the parameters set on the <code>Builder</code>
  ///     were incompatible, or if they are not supported by the device,
  ///     or if the device was not available.
  AudioTrack build() => AudioTrack.fromRef(jniAccessors.callMethodWithArgs(
      reference, _id_build, jni.JniType.objectType, []).object);
}
