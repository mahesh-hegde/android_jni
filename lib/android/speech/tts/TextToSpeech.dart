// Autogenerated by jnigen. DO NOT EDIT!

// ignore_for_file: annotate_overrides
// ignore_for_file: camel_case_types
// ignore_for_file: constant_identifier_names
// ignore_for_file: file_names
// ignore_for_file: no_leading_underscores_for_local_identifiers
// ignore_for_file: non_constant_identifier_names
// ignore_for_file: unused_element
// ignore_for_file: unused_field
// ignore_for_file: unused_import
// ignore_for_file: unused_shown_name

import "package:jni/jni.dart" as jni;

import "package:jni/internal_helpers_for_jnigen.dart";

import "../../content/Context.dart" as context_;

import "../../os/Bundle.dart" as bundle_;

import "../../media/AudioAttributes.dart" as audioattributes_;

import "Voice.dart" as voice_;

import "UtteranceProgressListener.dart" as utteranceprogresslistener_;
import "../../../_init.dart" show jniEnv, jniAccessors;

/// from: android.speech.tts.TextToSpeech
///
/// Synthesizes speech from text for immediate playback or to create a sound file.
/// A TextToSpeech instance can only be used to synthesize text once it has completed its
/// initialization. Implement the TextToSpeech.OnInitListener to be
/// notified of the completion of the initialization.<br>
/// When you are done using the TextToSpeech instance, call the \#shutdown() method
/// to release the native resources used by the TextToSpeech engine.
class TextToSpeech extends jni.JniObject {
  static final _classRef =
      jniAccessors.getClassOf("android/speech/tts/TextToSpeech");
  TextToSpeech.fromRef(jni.JObject ref) : super.fromRef(ref);

  /// from: static public final java.lang.String ACTION_TTS_QUEUE_PROCESSING_COMPLETED
  ///
  /// Broadcast Action: The TextToSpeech synthesizer has completed processing
  /// of all the text in the speech queue.
  ///
  /// Note that this notifies callers when the __engine__ has finished has
  /// processing text data. Audio playback might not have completed (or even started)
  /// at this point. If you wish to be notified when this happens, see
  /// OnUtteranceCompletedListener.
  static const ACTION_TTS_QUEUE_PROCESSING_COMPLETED =
      "android.speech.tts.TTS_QUEUE_PROCESSING_COMPLETED";

  /// from: static public final int ERROR
  ///
  /// Denotes a generic operation failure.
  static const ERROR = -1;

  /// from: static public final int ERROR_INVALID_REQUEST
  ///
  /// Denotes a failure caused by an invalid request.
  static const ERROR_INVALID_REQUEST = -8;

  /// from: static public final int ERROR_NETWORK
  ///
  /// Denotes a failure caused by a network connectivity problems.
  static const ERROR_NETWORK = -6;

  /// from: static public final int ERROR_NETWORK_TIMEOUT
  ///
  /// Denotes a failure caused by network timeout.
  static const ERROR_NETWORK_TIMEOUT = -7;

  /// from: static public final int ERROR_NOT_INSTALLED_YET
  ///
  /// Denotes a failure caused by an unfinished download of the voice data.
  ///@see Engine\#KEY_FEATURE_NOT_INSTALLED
  static const ERROR_NOT_INSTALLED_YET = -9;

  /// from: static public final int ERROR_OUTPUT
  ///
  /// Denotes a failure related to the output (audio device or a file).
  static const ERROR_OUTPUT = -5;

  /// from: static public final int ERROR_SERVICE
  ///
  /// Denotes a failure of a TTS service.
  static const ERROR_SERVICE = -4;

  /// from: static public final int ERROR_SYNTHESIS
  ///
  /// Denotes a failure of a TTS engine to synthesize the given input.
  static const ERROR_SYNTHESIS = -3;

  /// from: static public final int LANG_AVAILABLE
  ///
  /// Denotes the language is available for the language by the locale,
  /// but not the country and variant.
  static const LANG_AVAILABLE = 0;

  /// from: static public final int LANG_COUNTRY_AVAILABLE
  ///
  /// Denotes the language is available for the language and country specified
  /// by the locale, but not the variant.
  static const LANG_COUNTRY_AVAILABLE = 1;

  /// from: static public final int LANG_COUNTRY_VAR_AVAILABLE
  ///
  /// Denotes the language is available exactly as specified by the locale.
  static const LANG_COUNTRY_VAR_AVAILABLE = 2;

  /// from: static public final int LANG_MISSING_DATA
  ///
  /// Denotes the language data is missing.
  static const LANG_MISSING_DATA = -1;

  /// from: static public final int LANG_NOT_SUPPORTED
  ///
  /// Denotes the language is not supported.
  static const LANG_NOT_SUPPORTED = -2;

  /// from: static public final int QUEUE_ADD
  ///
  /// Queue mode where the new entry is added at the end of the playback queue.
  static const QUEUE_ADD = 1;

  /// from: static public final int QUEUE_FLUSH
  ///
  /// Queue mode where all entries in the playback queue (media to be played
  /// and text to be synthesized) are dropped and replaced by the new entry.
  /// Queues are flushed with respect to a given calling app. Entries in the queue
  /// from other callees are not discarded.
  static const QUEUE_FLUSH = 0;

  /// from: static public final int STOPPED
  ///
  /// Denotes a stop requested by a client. It's used only on the service side of the API,
  /// client should never expect to see this result code.
  static const STOPPED = -2;

  /// from: static public final int SUCCESS
  ///
  /// Denotes a successful operation.
  static const SUCCESS = 0;

  static final _id_ctor = jniAccessors.getMethodIDOf(_classRef, "<init>",
      "(Landroid/content/Context;Landroid/speech/tts/TextToSpeech\$OnInitListener;)V");

  /// from: public void <init>(android.content.Context context, android.speech.tts.TextToSpeech.OnInitListener listener)
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// The constructor for the TextToSpeech class, using the default TTS engine.
  /// This will also initialize the associated TextToSpeech engine if it isn't already running.
  ///@param context The context this instance is running in.
  ///@param listener The TextToSpeech.OnInitListener that will be called when the
  ///            TextToSpeech engine has initialized. In a case of a failure the listener
  ///            may be called immediately, before TextToSpeech instance is fully constructed.
  TextToSpeech(context_.Context context, TextToSpeech_OnInitListener listener)
      : super.fromRef(jniAccessors.newObjectWithArgs(_classRef, _id_ctor,
            [context.reference, listener.reference]).object);

  static final _id_ctor1 = jniAccessors.getMethodIDOf(_classRef, "<init>",
      "(Landroid/content/Context;Landroid/speech/tts/TextToSpeech\$OnInitListener;Ljava/lang/String;)V");

  /// from: public void <init>(android.content.Context context, android.speech.tts.TextToSpeech.OnInitListener listener, java.lang.String engine)
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// The constructor for the TextToSpeech class, using the given TTS engine.
  /// This will also initialize the associated TextToSpeech engine if it isn't already running.
  ///@param context The context this instance is running in.
  ///@param listener The TextToSpeech.OnInitListener that will be called when the
  ///            TextToSpeech engine has initialized. In a case of a failure the listener
  ///            may be called immediately, before TextToSpeech instance is fully constructed.
  ///@param engine Package name of the TTS engine to use.
  TextToSpeech.ctor1(context_.Context context,
      TextToSpeech_OnInitListener listener, jni.JniString engine)
      : super.fromRef(jniAccessors.newObjectWithArgs(_classRef, _id_ctor1,
            [context.reference, listener.reference, engine.reference]).object);

  static final _id_shutdown =
      jniAccessors.getMethodIDOf(_classRef, "shutdown", "()V");

  /// from: public void shutdown()
  ///
  /// Releases the resources used by the TextToSpeech engine.
  /// It is good practice for instance to call this method in the onDestroy() method of an Activity
  /// so the TextToSpeech engine can be cleanly stopped.
  void shutdown() => jniAccessors.callMethodWithArgs(
      reference, _id_shutdown, jni.JniType.voidType, []).check();

  static final _id_addSpeech = jniAccessors.getMethodIDOf(
      _classRef, "addSpeech", "(Ljava/lang/String;Ljava/lang/String;I)I");

  /// from: public int addSpeech(java.lang.String text, java.lang.String packagename, int resourceId)
  ///
  /// Adds a mapping between a string of text and a sound resource in a
  /// package. After a call to this method, subsequent calls to
  /// \#speak(String, int, HashMap) will play the specified sound resource
  /// if it is available, or synthesize the text it is missing.
  ///@param text The string of text. Example: <code>"south_south_east"</code>
  ///@param packagename Pass the packagename of the application that contains the
  ///            resource. If the resource is in your own application (this is
  ///            the most common case), then put the packagename of your
  ///            application here.<br/>
  ///            Example: __"com.google.marvin.compass"__<br/>
  ///            The packagename can be found in the AndroidManifest.xml of
  ///            your application.
  ///
  ///            <code>&lt;manifest xmlns:android=&quot;...&quot;
  ///      package=&quot;__com.google.marvin.compass__&quot;&gt;</code>
  ///
  ///
  ///@param resourceId Example: <code>R.raw.south_south_east</code>
  ///@return Code indicating success or failure. See \#ERROR and \#SUCCESS.
  int addSpeech(
          jni.JniString text, jni.JniString packagename, int resourceId) =>
      jniAccessors.callMethodWithArgs(
          reference,
          _id_addSpeech,
          jni.JniType.intType,
          [text.reference, packagename.reference, resourceId]).integer;

  static final _id_addSpeech1 = jniAccessors.getMethodIDOf(
      _classRef, "addSpeech", "(Ljava/lang/CharSequence;Ljava/lang/String;I)I");

  /// from: public int addSpeech(java.lang.CharSequence text, java.lang.String packagename, int resourceId)
  ///
  /// Adds a mapping between a CharSequence (may be spanned with TtsSpans) of text
  /// and a sound resource in a package. After a call to this method, subsequent calls to
  /// \#speak(String, int, HashMap) will play the specified sound resource
  /// if it is available, or synthesize the text it is missing.
  ///@param text The string of text. Example: <code>"south_south_east"</code>
  ///@param packagename Pass the packagename of the application that contains the
  ///            resource. If the resource is in your own application (this is
  ///            the most common case), then put the packagename of your
  ///            application here.<br/>
  ///            Example: __"com.google.marvin.compass"__<br/>
  ///            The packagename can be found in the AndroidManifest.xml of
  ///            your application.
  ///
  ///            <code>&lt;manifest xmlns:android=&quot;...&quot;
  ///      package=&quot;__com.google.marvin.compass__&quot;&gt;</code>
  ///
  ///
  ///@param resourceId Example: <code>R.raw.south_south_east</code>
  ///@return Code indicating success or failure. See \#ERROR and \#SUCCESS.
  int addSpeech1(
          jni.JniObject text, jni.JniString packagename, int resourceId) =>
      jniAccessors.callMethodWithArgs(
          reference,
          _id_addSpeech1,
          jni.JniType.intType,
          [text.reference, packagename.reference, resourceId]).integer;

  static final _id_addSpeech2 = jniAccessors.getMethodIDOf(
      _classRef, "addSpeech", "(Ljava/lang/String;Ljava/lang/String;)I");

  /// from: public int addSpeech(java.lang.String text, java.lang.String filename)
  ///
  /// Adds a mapping between a string of text and a sound file. Using this, it
  /// is possible to add custom pronounciations for a string of text.
  /// After a call to this method, subsequent calls to \#speak(String, int, HashMap)
  /// will play the specified sound resource if it is available, or synthesize the text it is
  /// missing.
  ///@param text The string of text. Example: <code>"south_south_east"</code>
  ///@param filename The full path to the sound file (for example:
  ///            "/sdcard/mysounds/hello.wav")
  ///@return Code indicating success or failure. See \#ERROR and \#SUCCESS.
  int addSpeech2(jni.JniString text, jni.JniString filename) =>
      jniAccessors.callMethodWithArgs(reference, _id_addSpeech2,
          jni.JniType.intType, [text.reference, filename.reference]).integer;

  static final _id_addSpeech3 = jniAccessors.getMethodIDOf(
      _classRef, "addSpeech", "(Ljava/lang/CharSequence;Ljava/io/File;)I");

  /// from: public int addSpeech(java.lang.CharSequence text, java.io.File file)
  ///
  /// Adds a mapping between a CharSequence (may be spanned with TtsSpans and a sound file.
  /// Using this, it is possible to add custom pronounciations for a string of text.
  /// After a call to this method, subsequent calls to \#speak(String, int, HashMap)
  /// will play the specified sound resource if it is available, or synthesize the text it is
  /// missing.
  ///@param text The string of text. Example: <code>"south_south_east"</code>
  ///@param file File object pointing to the sound file.
  ///@return Code indicating success or failure. See \#ERROR and \#SUCCESS.
  int addSpeech3(jni.JniObject text, jni.JniObject file) =>
      jniAccessors.callMethodWithArgs(reference, _id_addSpeech3,
          jni.JniType.intType, [text.reference, file.reference]).integer;

  static final _id_addEarcon = jniAccessors.getMethodIDOf(
      _classRef, "addEarcon", "(Ljava/lang/String;Ljava/lang/String;I)I");

  /// from: public int addEarcon(java.lang.String earcon, java.lang.String packagename, int resourceId)
  ///
  /// Adds a mapping between a string of text and a sound resource in a
  /// package. Use this to add custom earcons.
  ///@see \#playEarcon(String, int, HashMap)
  ///@param earcon The name of the earcon.
  ///            Example: <code>"[tick]"</code><br/>
  ///@param packagename the package name of the application that contains the
  ///            resource. This can for instance be the package name of your own application.
  ///            Example: __"com.google.marvin.compass"__<br/>
  ///            The package name can be found in the AndroidManifest.xml of
  ///            the application containing the resource.
  ///
  ///            <code>&lt;manifest xmlns:android=&quot;...&quot;
  ///      package=&quot;__com.google.marvin.compass__&quot;&gt;</code>
  ///
  ///
  ///@param resourceId Example: <code>R.raw.tick_snd</code>
  ///@return Code indicating success or failure. See \#ERROR and \#SUCCESS.
  int addEarcon(
          jni.JniString earcon, jni.JniString packagename, int resourceId) =>
      jniAccessors.callMethodWithArgs(
          reference,
          _id_addEarcon,
          jni.JniType.intType,
          [earcon.reference, packagename.reference, resourceId]).integer;

  static final _id_addEarcon1 = jniAccessors.getMethodIDOf(
      _classRef, "addEarcon", "(Ljava/lang/String;Ljava/lang/String;)I");

  /// from: public int addEarcon(java.lang.String earcon, java.lang.String filename)
  ///
  /// Adds a mapping between a string of text and a sound file.
  /// Use this to add custom earcons.
  ///@see \#playEarcon(String, int, HashMap)
  ///@param earcon The name of the earcon.
  ///            Example: <code>"[tick]"</code>
  ///@param filename The full path to the sound file (for example:
  ///            "/sdcard/mysounds/tick.wav")
  ///@return Code indicating success or failure. See \#ERROR and \#SUCCESS.
  ///@deprecated As of API level 21, replaced by
  ///         \#addEarcon(String, File).
  int addEarcon1(jni.JniString earcon, jni.JniString filename) =>
      jniAccessors.callMethodWithArgs(reference, _id_addEarcon1,
          jni.JniType.intType, [earcon.reference, filename.reference]).integer;

  static final _id_addEarcon2 = jniAccessors.getMethodIDOf(
      _classRef, "addEarcon", "(Ljava/lang/String;Ljava/io/File;)I");

  /// from: public int addEarcon(java.lang.String earcon, java.io.File file)
  ///
  /// Adds a mapping between a string of text and a sound file.
  /// Use this to add custom earcons.
  ///@see \#playEarcon(String, int, HashMap)
  ///@param earcon The name of the earcon.
  ///            Example: <code>"[tick]"</code>
  ///@param file File object pointing to the sound file.
  ///@return Code indicating success or failure. See \#ERROR and \#SUCCESS.
  int addEarcon2(jni.JniString earcon, jni.JniObject file) =>
      jniAccessors.callMethodWithArgs(reference, _id_addEarcon2,
          jni.JniType.intType, [earcon.reference, file.reference]).integer;

  static final _id_speak = jniAccessors.getMethodIDOf(_classRef, "speak",
      "(Ljava/lang/CharSequence;ILandroid/os/Bundle;Ljava/lang/String;)I");

  /// from: public int speak(java.lang.CharSequence text, int queueMode, android.os.Bundle params, java.lang.String utteranceId)
  ///
  /// Speaks the text using the specified queuing strategy and speech parameters, the text may
  /// be spanned with TtsSpans.
  /// This method is asynchronous, i.e. the method just adds the request to the queue of TTS
  /// requests and then returns. The synthesis might not have finished (or even started!) at the
  /// time when this method returns. In order to reliably detect errors during synthesis,
  /// we recommend setting an utterance progress listener (see
  /// \#setOnUtteranceProgressListener) and using the
  /// Engine\#KEY_PARAM_UTTERANCE_ID parameter.
  ///@param text The string of text to be spoken. No longer than
  ///            \#getMaxSpeechInputLength() characters.
  ///@param queueMode The queuing strategy to use, \#QUEUE_ADD or \#QUEUE_FLUSH.
  ///@param params Parameters for the request. Can be null.
  ///            Supported parameter names:
  ///            Engine\#KEY_PARAM_STREAM,
  ///            Engine\#KEY_PARAM_VOLUME,
  ///            Engine\#KEY_PARAM_PAN.
  ///            Engine specific parameters may be passed in but the parameter keys
  ///            must be prefixed by the name of the engine they are intended for. For example
  ///            the keys "com.svox.pico_foo" and "com.svox.pico:bar" will be passed to the
  ///            engine named "com.svox.pico" if it is being used.
  ///@param utteranceId An unique identifier for this request.
  ///@return \#ERROR or \#SUCCESS of __queuing__ the speak operation.
  int speak(jni.JniObject text, int queueMode, bundle_.Bundle params,
          jni.JniString utteranceId) =>
      jniAccessors.callMethodWithArgs(
          reference, _id_speak, jni.JniType.intType, [
        text.reference,
        queueMode,
        params.reference,
        utteranceId.reference
      ]).integer;

  static final _id_speak1 = jniAccessors.getMethodIDOf(
      _classRef, "speak", "(Ljava/lang/String;ILjava/util/HashMap;)I");

  /// from: public int speak(java.lang.String text, int queueMode, java.util.HashMap<java.lang.String,java.lang.String> params)
  ///
  /// Speaks the string using the specified queuing strategy and speech parameters.
  /// This method is asynchronous, i.e. the method just adds the request to the queue of TTS
  /// requests and then returns. The synthesis might not have finished (or even started!) at the
  /// time when this method returns. In order to reliably detect errors during synthesis,
  /// we recommend setting an utterance progress listener (see
  /// \#setOnUtteranceProgressListener) and using the
  /// Engine\#KEY_PARAM_UTTERANCE_ID parameter.
  ///@param text The string of text to be spoken. No longer than
  ///            \#getMaxSpeechInputLength() characters.
  ///@param queueMode The queuing strategy to use, \#QUEUE_ADD or \#QUEUE_FLUSH.
  ///@param params Parameters for the request. Can be null.
  ///            Supported parameter names:
  ///            Engine\#KEY_PARAM_STREAM,
  ///            Engine\#KEY_PARAM_UTTERANCE_ID,
  ///            Engine\#KEY_PARAM_VOLUME,
  ///            Engine\#KEY_PARAM_PAN.
  ///            Engine specific parameters may be passed in but the parameter keys
  ///            must be prefixed by the name of the engine they are intended for. For example
  ///            the keys "com.svox.pico_foo" and "com.svox.pico:bar" will be passed to the
  ///            engine named "com.svox.pico" if it is being used.
  ///@return \#ERROR or \#SUCCESS of __queuing__ the speak operation.
  ///@deprecated As of API level 21, replaced by
  ///         \#speak(CharSequence, int, Bundle, String).
  int speak1(jni.JniString text, int queueMode, jni.JniObject params) =>
      jniAccessors.callMethodWithArgs(
          reference,
          _id_speak1,
          jni.JniType.intType,
          [text.reference, queueMode, params.reference]).integer;

  static final _id_playEarcon = jniAccessors.getMethodIDOf(
      _classRef,
      "playEarcon",
      "(Ljava/lang/String;ILandroid/os/Bundle;Ljava/lang/String;)I");

  /// from: public int playEarcon(java.lang.String earcon, int queueMode, android.os.Bundle params, java.lang.String utteranceId)
  ///
  /// Plays the earcon using the specified queueing mode and parameters.
  /// The earcon must already have been added with \#addEarcon(String, String) or
  /// \#addEarcon(String, String, int).
  /// This method is asynchronous, i.e. the method just adds the request to the queue of TTS
  /// requests and then returns. The synthesis might not have finished (or even started!) at the
  /// time when this method returns. In order to reliably detect errors during synthesis,
  /// we recommend setting an utterance progress listener (see
  /// \#setOnUtteranceProgressListener) and using the
  /// Engine\#KEY_PARAM_UTTERANCE_ID parameter.
  ///@param earcon The earcon that should be played
  ///@param queueMode \#QUEUE_ADD or \#QUEUE_FLUSH.
  ///@param params Parameters for the request. Can be null.
  ///            Supported parameter names:
  ///            Engine\#KEY_PARAM_STREAM,
  ///            Engine specific parameters may be passed in but the parameter keys
  ///            must be prefixed by the name of the engine they are intended for. For example
  ///            the keys "com.svox.pico_foo" and "com.svox.pico:bar" will be passed to the
  ///            engine named "com.svox.pico" if it is being used.
  ///@return \#ERROR or \#SUCCESS of __queuing__ the playEarcon operation.
  int playEarcon(jni.JniString earcon, int queueMode, bundle_.Bundle params,
          jni.JniString utteranceId) =>
      jniAccessors.callMethodWithArgs(
          reference, _id_playEarcon, jni.JniType.intType, [
        earcon.reference,
        queueMode,
        params.reference,
        utteranceId.reference
      ]).integer;

  static final _id_playEarcon1 = jniAccessors.getMethodIDOf(
      _classRef, "playEarcon", "(Ljava/lang/String;ILjava/util/HashMap;)I");

  /// from: public int playEarcon(java.lang.String earcon, int queueMode, java.util.HashMap<java.lang.String,java.lang.String> params)
  ///
  /// Plays the earcon using the specified queueing mode and parameters.
  /// The earcon must already have been added with \#addEarcon(String, String) or
  /// \#addEarcon(String, String, int).
  /// This method is asynchronous, i.e. the method just adds the request to the queue of TTS
  /// requests and then returns. The synthesis might not have finished (or even started!) at the
  /// time when this method returns. In order to reliably detect errors during synthesis,
  /// we recommend setting an utterance progress listener (see
  /// \#setOnUtteranceProgressListener) and using the
  /// Engine\#KEY_PARAM_UTTERANCE_ID parameter.
  ///@param earcon The earcon that should be played
  ///@param queueMode \#QUEUE_ADD or \#QUEUE_FLUSH.
  ///@param params Parameters for the request. Can be null.
  ///            Supported parameter names:
  ///            Engine\#KEY_PARAM_STREAM,
  ///            Engine\#KEY_PARAM_UTTERANCE_ID.
  ///            Engine specific parameters may be passed in but the parameter keys
  ///            must be prefixed by the name of the engine they are intended for. For example
  ///            the keys "com.svox.pico_foo" and "com.svox.pico:bar" will be passed to the
  ///            engine named "com.svox.pico" if it is being used.
  ///@return \#ERROR or \#SUCCESS of __queuing__ the playEarcon operation.
  ///@deprecated As of API level 21, replaced by
  ///         \#playEarcon(String, int, Bundle, String).
  int playEarcon1(jni.JniString earcon, int queueMode, jni.JniObject params) =>
      jniAccessors.callMethodWithArgs(
          reference,
          _id_playEarcon1,
          jni.JniType.intType,
          [earcon.reference, queueMode, params.reference]).integer;

  static final _id_playSilentUtterance = jniAccessors.getMethodIDOf(
      _classRef, "playSilentUtterance", "(JILjava/lang/String;)I");

  /// from: public int playSilentUtterance(long durationInMs, int queueMode, java.lang.String utteranceId)
  ///
  /// Plays silence for the specified amount of time using the specified
  /// queue mode.
  /// This method is asynchronous, i.e. the method just adds the request to the queue of TTS
  /// requests and then returns. The synthesis might not have finished (or even started!) at the
  /// time when this method returns. In order to reliably detect errors during synthesis,
  /// we recommend setting an utterance progress listener (see
  /// \#setOnUtteranceProgressListener) and using the
  /// Engine\#KEY_PARAM_UTTERANCE_ID parameter.
  ///@param durationInMs The duration of the silence.
  ///@param queueMode \#QUEUE_ADD or \#QUEUE_FLUSH.
  ///@param utteranceId An unique identifier for this request.
  ///@return \#ERROR or \#SUCCESS of __queuing__ the playSilentUtterance operation.
  int playSilentUtterance(
          int durationInMs, int queueMode, jni.JniString utteranceId) =>
      jniAccessors.callMethodWithArgs(
          reference,
          _id_playSilentUtterance,
          jni.JniType.intType,
          [durationInMs, queueMode, utteranceId.reference]).integer;

  static final _id_playSilence = jniAccessors.getMethodIDOf(
      _classRef, "playSilence", "(JILjava/util/HashMap;)I");

  /// from: public int playSilence(long durationInMs, int queueMode, java.util.HashMap<java.lang.String,java.lang.String> params)
  ///
  /// Plays silence for the specified amount of time using the specified
  /// queue mode.
  /// This method is asynchronous, i.e. the method just adds the request to the queue of TTS
  /// requests and then returns. The synthesis might not have finished (or even started!) at the
  /// time when this method returns. In order to reliably detect errors during synthesis,
  /// we recommend setting an utterance progress listener (see
  /// \#setOnUtteranceProgressListener) and using the
  /// Engine\#KEY_PARAM_UTTERANCE_ID parameter.
  ///@param durationInMs The duration of the silence.
  ///@param queueMode \#QUEUE_ADD or \#QUEUE_FLUSH.
  ///@param params Parameters for the request. Can be null.
  ///            Supported parameter names:
  ///            Engine\#KEY_PARAM_UTTERANCE_ID.
  ///            Engine specific parameters may be passed in but the parameter keys
  ///            must be prefixed by the name of the engine they are intended for. For example
  ///            the keys "com.svox.pico_foo" and "com.svox.pico:bar" will be passed to the
  ///            engine named "com.svox.pico" if it is being used.
  ///@return \#ERROR or \#SUCCESS of __queuing__ the playSilence operation.
  ///@deprecated As of API level 21, replaced by
  ///         \#playSilentUtterance(long, int, String).
  int playSilence(int durationInMs, int queueMode, jni.JniObject params) =>
      jniAccessors.callMethodWithArgs(
          reference,
          _id_playSilence,
          jni.JniType.intType,
          [durationInMs, queueMode, params.reference]).integer;

  static final _id_getFeatures = jniAccessors.getMethodIDOf(
      _classRef, "getFeatures", "(Ljava/util/Locale;)Ljava/util/Set;");

  /// from: public java.util.Set<java.lang.String> getFeatures(java.util.Locale locale)
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// Queries the engine for the set of features it supports for a given locale.
  /// Features can either be framework defined, e.g.
  /// TextToSpeech.Engine\#KEY_FEATURE_NETWORK_SYNTHESIS or engine specific.
  /// Engine specific keys must be prefixed by the name of the engine they
  /// are intended for. These keys can be used as parameters to
  /// TextToSpeech\#speak(String, int, java.util.HashMap) and
  /// TextToSpeech\#synthesizeToFile(String, java.util.HashMap, String).
  ///
  /// Features values are strings and their values must meet restrictions described in their
  /// documentation.
  ///@param locale The locale to query features for.
  ///@return Set instance. May return {@code null} on error.
  ///@deprecated As of API level 21, please use voices. In order to query features of the voice,
  /// call \#getVoices() to retrieve the list of available voices and
  /// Voice\#getFeatures() to retrieve the set of features.
  jni.JniObject getFeatures(jni.JniObject locale) =>
      jni.JniObject.fromRef(jniAccessors.callMethodWithArgs(reference,
          _id_getFeatures, jni.JniType.objectType, [locale.reference]).object);

  static final _id_isSpeaking =
      jniAccessors.getMethodIDOf(_classRef, "isSpeaking", "()Z");

  /// from: public boolean isSpeaking()
  ///
  /// Checks whether the TTS engine is busy speaking. Note that a speech item is
  /// considered complete once it's audio data has been sent to the audio mixer, or
  /// written to a file. There might be a finite lag between this point, and when
  /// the audio hardware completes playback.
  ///@return {@code true} if the TTS engine is speaking.
  bool isSpeaking() => jniAccessors.callMethodWithArgs(
      reference, _id_isSpeaking, jni.JniType.booleanType, []).boolean;

  static final _id_stop = jniAccessors.getMethodIDOf(_classRef, "stop", "()I");

  /// from: public int stop()
  ///
  /// Interrupts the current utterance (whether played or rendered to file) and discards other
  /// utterances in the queue.
  ///@return \#ERROR or \#SUCCESS.
  int stop() => jniAccessors
      .callMethodWithArgs(reference, _id_stop, jni.JniType.intType, []).integer;

  static final _id_setSpeechRate =
      jniAccessors.getMethodIDOf(_classRef, "setSpeechRate", "(F)I");

  /// from: public int setSpeechRate(float speechRate)
  ///
  /// Sets the speech rate.
  ///
  /// This has no effect on any pre-recorded speech.
  ///@param speechRate Speech rate. {@code 1.0} is the normal speech rate,
  ///            lower values slow down the speech ({@code 0.5} is half the normal speech rate),
  ///            greater values accelerate it ({@code 2.0} is twice the normal speech rate).
  ///@return \#ERROR or \#SUCCESS.
  int setSpeechRate(double speechRate) => jniAccessors.callMethodWithArgs(
      reference, _id_setSpeechRate, jni.JniType.intType, [speechRate]).integer;

  static final _id_setPitch =
      jniAccessors.getMethodIDOf(_classRef, "setPitch", "(F)I");

  /// from: public int setPitch(float pitch)
  ///
  /// Sets the speech pitch for the TextToSpeech engine.
  ///
  /// This has no effect on any pre-recorded speech.
  ///@param pitch Speech pitch. {@code 1.0} is the normal pitch,
  ///            lower values lower the tone of the synthesized voice,
  ///            greater values increase it.
  ///@return \#ERROR or \#SUCCESS.
  int setPitch(double pitch) => jniAccessors.callMethodWithArgs(
      reference, _id_setPitch, jni.JniType.intType, [pitch]).integer;

  static final _id_setAudioAttributes = jniAccessors.getMethodIDOf(
      _classRef, "setAudioAttributes", "(Landroid/media/AudioAttributes;)I");

  /// from: public int setAudioAttributes(android.media.AudioAttributes audioAttributes)
  ///
  /// Sets the audio attributes to be used when speaking text or playing
  /// back a file.
  ///@param audioAttributes Valid AudioAttributes instance.
  ///@return \#ERROR or \#SUCCESS.
  int setAudioAttributes(audioattributes_.AudioAttributes audioAttributes) =>
      jniAccessors.callMethodWithArgs(reference, _id_setAudioAttributes,
          jni.JniType.intType, [audioAttributes.reference]).integer;

  static final _id_getDefaultLanguage = jniAccessors.getMethodIDOf(
      _classRef, "getDefaultLanguage", "()Ljava/util/Locale;");

  /// from: public java.util.Locale getDefaultLanguage()
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// Returns a Locale instance describing the language currently being used as the default
  /// Text-to-speech language.
  ///
  /// The locale object returned by this method is NOT a valid one. It has identical form to the
  /// one in \#getLanguage(). Please refer to \#getLanguage() for more information.
  ///@return language, country (if any) and variant (if any) used by the client stored in a
  ///     Locale instance, or {@code null} on error.
  ///@deprecated As of API level 21, use <code>getDefaultVoice().getLocale()</code> (\#getDefaultVoice())
  jni.JniObject getDefaultLanguage() =>
      jni.JniObject.fromRef(jniAccessors.callMethodWithArgs(reference,
          _id_getDefaultLanguage, jni.JniType.objectType, []).object);

  static final _id_setLanguage = jniAccessors.getMethodIDOf(
      _classRef, "setLanguage", "(Ljava/util/Locale;)I");

  /// from: public int setLanguage(java.util.Locale loc)
  ///
  /// Sets the text-to-speech language.
  /// The TTS engine will try to use the closest match to the specified
  /// language as represented by the Locale, but there is no guarantee that the exact same Locale
  /// will be used. Use \#isLanguageAvailable(Locale) to check the level of support
  /// before choosing the language to use for the next utterances.
  ///
  /// This method sets the current voice to the default one for the given Locale;
  /// \#getVoice() can be used to retrieve it.
  ///@param loc The locale describing the language to be used.
  ///@return Code indicating the support status for the locale. See \#LANG_AVAILABLE,
  ///         \#LANG_COUNTRY_AVAILABLE, \#LANG_COUNTRY_VAR_AVAILABLE,
  ///         \#LANG_MISSING_DATA and \#LANG_NOT_SUPPORTED.
  int setLanguage(jni.JniObject loc) => jniAccessors.callMethodWithArgs(
      reference, _id_setLanguage, jni.JniType.intType, [loc.reference]).integer;

  static final _id_getLanguage = jniAccessors.getMethodIDOf(
      _classRef, "getLanguage", "()Ljava/util/Locale;");

  /// from: public java.util.Locale getLanguage()
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// Returns a Locale instance describing the language currently being used for synthesis
  /// requests sent to the TextToSpeech engine.
  ///
  /// In Android 4.2 and before (API <= 17) this function returns the language that is currently
  /// being used by the TTS engine. That is the last language set by this or any other
  /// client by a TextToSpeech\#setLanguage call to the same engine.
  ///
  /// In Android versions after 4.2 this function returns the language that is currently being
  /// used for the synthesis requests sent from this client. That is the last language set
  /// by a TextToSpeech\#setLanguage call on this instance.
  ///
  /// If a voice is set (by \#setVoice(Voice)), getLanguage will return the language of
  /// the currently set voice.
  ///
  /// Please note that the Locale object returned by this method is NOT a valid Locale object. Its
  /// language field contains a three-letter ISO 639-2/T code (where a proper Locale would use
  /// a two-letter ISO 639-1 code), and the country field contains a three-letter ISO 3166 country
  /// code (where a proper Locale would use a two-letter ISO 3166-1 code).
  ///@return language, country (if any) and variant (if any) used by the client stored in a
  ///     Locale instance, or {@code null} on error.
  ///@deprecated As of API level 21, please use <code>getVoice().getLocale()</code>
  /// (\#getVoice()).
  jni.JniObject getLanguage() =>
      jni.JniObject.fromRef(jniAccessors.callMethodWithArgs(
          reference, _id_getLanguage, jni.JniType.objectType, []).object);

  static final _id_getAvailableLanguages = jniAccessors.getMethodIDOf(
      _classRef, "getAvailableLanguages", "()Ljava/util/Set;");

  /// from: public java.util.Set<java.util.Locale> getAvailableLanguages()
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// Query the engine about the set of available languages.
  jni.JniObject getAvailableLanguages() =>
      jni.JniObject.fromRef(jniAccessors.callMethodWithArgs(reference,
          _id_getAvailableLanguages, jni.JniType.objectType, []).object);

  static final _id_getVoices =
      jniAccessors.getMethodIDOf(_classRef, "getVoices", "()Ljava/util/Set;");

  /// from: public java.util.Set<android.speech.tts.Voice> getVoices()
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// Query the engine about the set of available voices.
  ///
  /// Each TTS Engine can expose multiple voices for each locale, each with a different set of
  /// features.
  ///@see \#setVoice(Voice)
  ///@see Voice
  jni.JniObject getVoices() =>
      jni.JniObject.fromRef(jniAccessors.callMethodWithArgs(
          reference, _id_getVoices, jni.JniType.objectType, []).object);

  static final _id_setVoice = jniAccessors.getMethodIDOf(
      _classRef, "setVoice", "(Landroid/speech/tts/Voice;)I");

  /// from: public int setVoice(android.speech.tts.Voice voice)
  ///
  /// Sets the text-to-speech voice.
  ///@param voice One of objects returned by \#getVoices().
  ///@return \#ERROR or \#SUCCESS.
  ///@see \#getVoices
  ///@see Voice
  int setVoice(voice_.Voice voice) => jniAccessors.callMethodWithArgs(
      reference, _id_setVoice, jni.JniType.intType, [voice.reference]).integer;

  static final _id_getVoice = jniAccessors.getMethodIDOf(
      _classRef, "getVoice", "()Landroid/speech/tts/Voice;");

  /// from: public android.speech.tts.Voice getVoice()
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// Returns a Voice instance describing the voice currently being used for synthesis
  /// requests sent to the TextToSpeech engine.
  ///@return Voice instance used by the client, or {@code null} if not set or on error.
  ///@see \#getVoices
  ///@see \#setVoice
  ///@see Voice
  voice_.Voice getVoice() =>
      voice_.Voice.fromRef(jniAccessors.callMethodWithArgs(
          reference, _id_getVoice, jni.JniType.objectType, []).object);

  static final _id_getDefaultVoice = jniAccessors.getMethodIDOf(
      _classRef, "getDefaultVoice", "()Landroid/speech/tts/Voice;");

  /// from: public android.speech.tts.Voice getDefaultVoice()
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// Returns a Voice instance that's the default voice for the default Text-to-speech language.
  ///@return The default voice instance for the default language, or {@code null} if not set or
  ///     on error.
  voice_.Voice getDefaultVoice() =>
      voice_.Voice.fromRef(jniAccessors.callMethodWithArgs(
          reference, _id_getDefaultVoice, jni.JniType.objectType, []).object);

  static final _id_isLanguageAvailable = jniAccessors.getMethodIDOf(
      _classRef, "isLanguageAvailable", "(Ljava/util/Locale;)I");

  /// from: public int isLanguageAvailable(java.util.Locale loc)
  ///
  /// Checks if the specified language as represented by the Locale is available and supported.
  ///@param loc The Locale describing the language to be used.
  ///@return Code indicating the support status for the locale. See \#LANG_AVAILABLE,
  ///         \#LANG_COUNTRY_AVAILABLE, \#LANG_COUNTRY_VAR_AVAILABLE,
  ///         \#LANG_MISSING_DATA and \#LANG_NOT_SUPPORTED.
  int isLanguageAvailable(jni.JniObject loc) => jniAccessors.callMethodWithArgs(
      reference,
      _id_isLanguageAvailable,
      jni.JniType.intType,
      [loc.reference]).integer;

  static final _id_synthesizeToFile = jniAccessors.getMethodIDOf(
      _classRef,
      "synthesizeToFile",
      "(Ljava/lang/CharSequence;Landroid/os/Bundle;Ljava/io/File;Ljava/lang/String;)I");

  /// from: public int synthesizeToFile(java.lang.CharSequence text, android.os.Bundle params, java.io.File file, java.lang.String utteranceId)
  ///
  /// Synthesizes the given text to a file using the specified parameters.
  /// This method is asynchronous, i.e. the method just adds the request to the queue of TTS
  /// requests and then returns. The synthesis might not have finished (or even started!) at the
  /// time when this method returns. In order to reliably detect errors during synthesis,
  /// we recommend setting an utterance progress listener (see
  /// \#setOnUtteranceProgressListener).
  ///@param text The text that should be synthesized. No longer than
  ///            \#getMaxSpeechInputLength() characters.
  ///@param params Parameters for the request. Can be null.
  ///            Engine specific parameters may be passed in but the parameter keys
  ///            must be prefixed by the name of the engine they are intended for. For example
  ///            the keys "com.svox.pico_foo" and "com.svox.pico:bar" will be passed to the
  ///            engine named "com.svox.pico" if it is being used.
  ///@param file File to write the generated audio data to.
  ///@param utteranceId An unique identifier for this request.
  ///@return \#ERROR or \#SUCCESS of __queuing__ the synthesizeToFile operation.
  int synthesizeToFile(jni.JniObject text, bundle_.Bundle params,
          jni.JniObject file, jni.JniString utteranceId) =>
      jniAccessors.callMethodWithArgs(
          reference, _id_synthesizeToFile, jni.JniType.intType, [
        text.reference,
        params.reference,
        file.reference,
        utteranceId.reference
      ]).integer;

  static final _id_synthesizeToFile1 = jniAccessors.getMethodIDOf(
      _classRef,
      "synthesizeToFile",
      "(Ljava/lang/String;Ljava/util/HashMap;Ljava/lang/String;)I");

  /// from: public int synthesizeToFile(java.lang.String text, java.util.HashMap<java.lang.String,java.lang.String> params, java.lang.String filename)
  ///
  /// Synthesizes the given text to a file using the specified parameters.
  /// This method is asynchronous, i.e. the method just adds the request to the queue of TTS
  /// requests and then returns. The synthesis might not have finished (or even started!) at the
  /// time when this method returns. In order to reliably detect errors during synthesis,
  /// we recommend setting an utterance progress listener (see
  /// \#setOnUtteranceProgressListener) and using the
  /// Engine\#KEY_PARAM_UTTERANCE_ID parameter.
  ///@param text The text that should be synthesized. No longer than
  ///            \#getMaxSpeechInputLength() characters.
  ///@param params Parameters for the request. Can be null.
  ///            Supported parameter names:
  ///            Engine\#KEY_PARAM_UTTERANCE_ID.
  ///            Engine specific parameters may be passed in but the parameter keys
  ///            must be prefixed by the name of the engine they are intended for. For example
  ///            the keys "com.svox.pico_foo" and "com.svox.pico:bar" will be passed to the
  ///            engine named "com.svox.pico" if it is being used.
  ///@param filename Absolute file filename to write the generated audio data to.It should be
  ///            something like "/sdcard/myappsounds/mysound.wav".
  ///@return \#ERROR or \#SUCCESS of __queuing__ the synthesizeToFile operation.
  ///@deprecated As of API level 21, replaced by
  ///         \#synthesizeToFile(CharSequence, Bundle, File, String).
  int synthesizeToFile1(
          jni.JniString text, jni.JniObject params, jni.JniString filename) =>
      jniAccessors.callMethodWithArgs(
          reference,
          _id_synthesizeToFile1,
          jni.JniType.intType,
          [text.reference, params.reference, filename.reference]).integer;

  static final _id_setOnUtteranceCompletedListener = jniAccessors.getMethodIDOf(
      _classRef,
      "setOnUtteranceCompletedListener",
      "(Landroid/speech/tts/TextToSpeech\$OnUtteranceCompletedListener;)I");

  /// from: public int setOnUtteranceCompletedListener(android.speech.tts.TextToSpeech.OnUtteranceCompletedListener listener)
  ///
  /// Sets the listener that will be notified when synthesis of an utterance completes.
  ///@param listener The listener to use.
  ///@return \#ERROR or \#SUCCESS.
  ///@deprecated Use \#setOnUtteranceProgressListener(UtteranceProgressListener)
  ///        instead.
  int setOnUtteranceCompletedListener(
          TextToSpeech_OnUtteranceCompletedListener listener) =>
      jniAccessors.callMethodWithArgs(
          reference,
          _id_setOnUtteranceCompletedListener,
          jni.JniType.intType,
          [listener.reference]).integer;

  static final _id_setOnUtteranceProgressListener = jniAccessors.getMethodIDOf(
      _classRef,
      "setOnUtteranceProgressListener",
      "(Landroid/speech/tts/UtteranceProgressListener;)I");

  /// from: public int setOnUtteranceProgressListener(android.speech.tts.UtteranceProgressListener listener)
  ///
  /// Sets the listener that will be notified of various events related to the
  /// synthesis of a given utterance.
  ///
  /// See UtteranceProgressListener and
  /// TextToSpeech.Engine\#KEY_PARAM_UTTERANCE_ID.
  ///@param listener the listener to use.
  ///@return \#ERROR or \#SUCCESS
  int setOnUtteranceProgressListener(
          utteranceprogresslistener_.UtteranceProgressListener listener) =>
      jniAccessors.callMethodWithArgs(
          reference,
          _id_setOnUtteranceProgressListener,
          jni.JniType.intType,
          [listener.reference]).integer;

  static final _id_setEngineByPackageName = jniAccessors.getMethodIDOf(
      _classRef, "setEngineByPackageName", "(Ljava/lang/String;)I");

  /// from: public int setEngineByPackageName(java.lang.String enginePackageName)
  ///
  /// Sets the TTS engine to use.
  ///@deprecated This doesn't inform callers when the TTS engine has been
  ///        initialized. \#TextToSpeech(Context, OnInitListener, String)
  ///        can be used with the appropriate engine name. Also, there is no
  ///        guarantee that the engine specified will be loaded. If it isn't
  ///        installed or disabled, the user / system wide defaults will apply.
  ///@param enginePackageName The package name for the synthesis engine (e.g. "com.svox.pico")
  ///@return \#ERROR or \#SUCCESS.
  int setEngineByPackageName(jni.JniString enginePackageName) =>
      jniAccessors.callMethodWithArgs(reference, _id_setEngineByPackageName,
          jni.JniType.intType, [enginePackageName.reference]).integer;

  static final _id_getDefaultEngine = jniAccessors.getMethodIDOf(
      _classRef, "getDefaultEngine", "()Ljava/lang/String;");

  /// from: public java.lang.String getDefaultEngine()
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// Gets the package name of the default speech synthesis engine.
  ///@return Package name of the TTS engine that the user has chosen
  ///        as their default.
  jni.JniString getDefaultEngine() =>
      jni.JniString.fromRef(jniAccessors.callMethodWithArgs(
          reference, _id_getDefaultEngine, jni.JniType.objectType, []).object);

  static final _id_areDefaultsEnforced =
      jniAccessors.getMethodIDOf(_classRef, "areDefaultsEnforced", "()Z");

  /// from: public boolean areDefaultsEnforced()
  ///
  /// Checks whether the user's settings should override settings requested
  /// by the calling application. As of the Ice cream sandwich release,
  /// user settings never forcibly override the app's settings.
  bool areDefaultsEnforced() => jniAccessors.callMethodWithArgs(
      reference, _id_areDefaultsEnforced, jni.JniType.booleanType, []).boolean;

  static final _id_getEngines =
      jniAccessors.getMethodIDOf(_classRef, "getEngines", "()Ljava/util/List;");

  /// from: public java.util.List<android.speech.tts.TextToSpeech.EngineInfo> getEngines()
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// Gets a list of all installed TTS engines.
  ///@return A list of engine info objects. The list can be empty, but never {@code null}.
  jni.JniObject getEngines() =>
      jni.JniObject.fromRef(jniAccessors.callMethodWithArgs(
          reference, _id_getEngines, jni.JniType.objectType, []).object);

  static final _id_getMaxSpeechInputLength = jniAccessors.getStaticMethodIDOf(
      _classRef, "getMaxSpeechInputLength", "()I");

  /// from: static public int getMaxSpeechInputLength()
  ///
  /// Limit of length of input string passed to speak and synthesizeToFile.
  ///@see \#speak
  ///@see \#synthesizeToFile
  static int getMaxSpeechInputLength() => jniAccessors.callStaticMethodWithArgs(
      _classRef, _id_getMaxSpeechInputLength, jni.JniType.intType, []).integer;
}

/// from: android.speech.tts.TextToSpeech$OnUtteranceCompletedListener
///
/// Listener that will be called when the TTS service has
/// completed synthesizing an utterance. This is only called if the utterance
/// has an utterance ID (see TextToSpeech.Engine\#KEY_PARAM_UTTERANCE_ID).
///@deprecated Use UtteranceProgressListener instead.
class TextToSpeech_OnUtteranceCompletedListener extends jni.JniObject {
  static final _classRef = jniAccessors.getClassOf(
      "android/speech/tts/TextToSpeech\$OnUtteranceCompletedListener");
  TextToSpeech_OnUtteranceCompletedListener.fromRef(jni.JObject ref)
      : super.fromRef(ref);

  static final _id_onUtteranceCompleted = jniAccessors.getMethodIDOf(
      _classRef, "onUtteranceCompleted", "(Ljava/lang/String;)V");

  /// from: public abstract void onUtteranceCompleted(java.lang.String utteranceId)
  ///
  /// Called when an utterance has been synthesized.
  ///@param utteranceId the identifier of the utterance.
  void onUtteranceCompleted(jni.JniString utteranceId) =>
      jniAccessors.callMethodWithArgs(reference, _id_onUtteranceCompleted,
          jni.JniType.voidType, [utteranceId.reference]).check();
}

/// from: android.speech.tts.TextToSpeech$OnInitListener
///
/// Interface definition of a callback to be invoked indicating the completion of the
/// TextToSpeech engine initialization.
class TextToSpeech_OnInitListener extends jni.JniObject {
  static final _classRef = jniAccessors
      .getClassOf("android/speech/tts/TextToSpeech\$OnInitListener");
  TextToSpeech_OnInitListener.fromRef(jni.JObject ref) : super.fromRef(ref);

  static final _id_onInit =
      jniAccessors.getMethodIDOf(_classRef, "onInit", "(I)V");

  /// from: public abstract void onInit(int status)
  ///
  /// Called to signal the completion of the TextToSpeech engine initialization.
  ///@param status TextToSpeech\#SUCCESS or TextToSpeech\#ERROR.
  void onInit(int status) => jniAccessors.callMethodWithArgs(
      reference, _id_onInit, jni.JniType.voidType, [status]).check();
}

/// from: android.speech.tts.TextToSpeech$EngineInfo
///
/// Information about an installed text-to-speech engine.
///@see TextToSpeech\#getEngines
class TextToSpeech_EngineInfo extends jni.JniObject {
  static final _classRef =
      jniAccessors.getClassOf("android/speech/tts/TextToSpeech\$EngineInfo");
  TextToSpeech_EngineInfo.fromRef(jni.JObject ref) : super.fromRef(ref);

  static final _id_icon = jniAccessors.getFieldIDOf(_classRef, "icon", "I");

  /// from: public int icon
  ///
  /// Icon for the engine.
  int get icon =>
      jniAccessors.getField(reference, _id_icon, jni.JniType.intType).integer;

  /// from: public int icon
  ///
  /// Icon for the engine.
  set icon(int value) => jniEnv.SetIntField(reference, _id_icon, value);

  static final _id_label =
      jniAccessors.getFieldIDOf(_classRef, "label", "Ljava/lang/String;");

  /// from: public java.lang.String label
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// Localized label for the engine.
  jni.JniString get label => jni.JniString.fromRef(jniAccessors
      .getField(reference, _id_label, jni.JniType.objectType)
      .object);

  /// from: public java.lang.String label
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// Localized label for the engine.
  set label(jni.JniString value) =>
      jniEnv.SetObjectField(reference, _id_label, value.reference);

  static final _id_name =
      jniAccessors.getFieldIDOf(_classRef, "name", "Ljava/lang/String;");

  /// from: public java.lang.String name
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// Engine package name..
  jni.JniString get name => jni.JniString.fromRef(jniAccessors
      .getField(reference, _id_name, jni.JniType.objectType)
      .object);

  /// from: public java.lang.String name
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// Engine package name..
  set name(jni.JniString value) =>
      jniEnv.SetObjectField(reference, _id_name, value.reference);

  static final _id_ctor =
      jniAccessors.getMethodIDOf(_classRef, "<init>", "()V");

  /// from: public void <init>()
  /// The returned object must be deleted after use, by calling the `delete` method.
  TextToSpeech_EngineInfo()
      : super.fromRef(
            jniAccessors.newObjectWithArgs(_classRef, _id_ctor, []).object);

  static final _id_toString1 =
      jniAccessors.getMethodIDOf(_classRef, "toString", "()Ljava/lang/String;");

  /// from: public java.lang.String toString()
  /// The returned object must be deleted after use, by calling the `delete` method.
  jni.JniString toString1() =>
      jni.JniString.fromRef(jniAccessors.callMethodWithArgs(
          reference, _id_toString1, jni.JniType.objectType, []).object);
}

/// from: android.speech.tts.TextToSpeech$Engine
///
/// Constants and parameter names for controlling text-to-speech. These include:
///
/// <ul>
///     <li>
///         Intents to ask engine to install data or check its data and
///         extras for a TTS engine's check data activity.
///     </li>
///     <li>
///         Keys for the parameters passed with speak commands, e.g.
///         Engine\#KEY_PARAM_UTTERANCE_ID, Engine\#KEY_PARAM_STREAM.
///     </li>
///     <li>
///         A list of feature strings that engines might support, e.g
///         Engine\#KEY_FEATURE_NETWORK_SYNTHESIS. These values may be passed in to
///         TextToSpeech\#speak and TextToSpeech\#synthesizeToFile to modify
///         engine behaviour. The engine can be queried for the set of features it supports
///         through TextToSpeech\#getFeatures(java.util.Locale).
///     </li>
/// </ul>
class TextToSpeech_Engine extends jni.JniObject {
  static final _classRef =
      jniAccessors.getClassOf("android/speech/tts/TextToSpeech\$Engine");
  TextToSpeech_Engine.fromRef(jni.JObject ref) : super.fromRef(ref);

  /// from: static public final java.lang.String ACTION_CHECK_TTS_DATA
  ///
  /// Activity Action: Starts the activity from the platform TextToSpeech
  /// engine to verify the proper installation and availability of the
  /// resource files on the system. Upon completion, the activity will
  /// return one of the following codes:
  /// \#CHECK_VOICE_DATA_PASS,
  /// \#CHECK_VOICE_DATA_FAIL,
  ///  Moreover, the data received in the activity result will contain the following
  /// fields:
  /// <ul>
  ///   <li>\#EXTRA_AVAILABLE_VOICES which contains an ArrayList<String> of all the
  ///   available voices. The format of each voice is: lang-COUNTRY-variant where COUNTRY and
  ///   variant are optional (ie, "eng" or "eng-USA" or "eng-USA-FEMALE").</li>
  ///   <li>\#EXTRA_UNAVAILABLE_VOICES which contains an ArrayList<String> of all the
  ///   unavailable voices (ones that user can install). The format of each voice is:
  ///   lang-COUNTRY-variant where COUNTRY and variant are optional (ie, "eng" or
  ///   "eng-USA" or "eng-USA-FEMALE").</li>
  /// </ul>
  static const ACTION_CHECK_TTS_DATA =
      "android.speech.tts.engine.CHECK_TTS_DATA";

  /// from: static public final java.lang.String ACTION_GET_SAMPLE_TEXT
  ///
  /// Activity intent for getting some sample text to use for demonstrating TTS. Specific
  /// locale have to be requested by passing following extra parameters:
  /// <ul>
  ///   <li>language</li>
  ///   <li>country</li>
  ///   <li>variant</li>
  /// </ul>
  ///
  /// Upon completion, the activity result may contain the following fields:
  /// <ul>
  ///   <li>\#EXTRA_SAMPLE_TEXT which contains an String with sample text.</li>
  /// </ul>
  static const ACTION_GET_SAMPLE_TEXT =
      "android.speech.tts.engine.GET_SAMPLE_TEXT";

  /// from: static public final java.lang.String ACTION_INSTALL_TTS_DATA
  ///
  /// Activity Action: Triggers the platform TextToSpeech engine to
  /// start the activity that installs the resource files on the device
  /// that are required for TTS to be operational. Since the installation
  /// of the data can be interrupted or declined by the user, the application
  /// shouldn't expect successful installation upon return from that intent,
  /// and if need be, should check installation status with
  /// \#ACTION_CHECK_TTS_DATA.
  static const ACTION_INSTALL_TTS_DATA =
      "android.speech.tts.engine.INSTALL_TTS_DATA";

  /// from: static public final java.lang.String ACTION_TTS_DATA_INSTALLED
  ///
  /// Broadcast Action: broadcast to signal the change in the list of available
  /// languages or/and their features.
  static const ACTION_TTS_DATA_INSTALLED =
      "android.speech.tts.engine.TTS_DATA_INSTALLED";

  /// from: static public final int CHECK_VOICE_DATA_BAD_DATA
  ///
  /// Indicates erroneous data when checking the installation status of the resources used by
  /// the TextToSpeech engine with the \#ACTION_CHECK_TTS_DATA intent.
  ///@deprecated Use CHECK_VOICE_DATA_FAIL instead.
  static const CHECK_VOICE_DATA_BAD_DATA = -1;

  /// from: static public final int CHECK_VOICE_DATA_FAIL
  ///
  /// Indicates failure when checking the installation status of the resources used by the
  /// TextToSpeech engine with the \#ACTION_CHECK_TTS_DATA intent.
  static const CHECK_VOICE_DATA_FAIL = 0;

  /// from: static public final int CHECK_VOICE_DATA_MISSING_DATA
  ///
  /// Indicates missing resources when checking the installation status of the resources used
  /// by the TextToSpeech engine with the \#ACTION_CHECK_TTS_DATA intent.
  ///@deprecated Use CHECK_VOICE_DATA_FAIL instead.
  static const CHECK_VOICE_DATA_MISSING_DATA = -2;

  /// from: static public final int CHECK_VOICE_DATA_MISSING_VOLUME
  ///
  /// Indicates missing storage volume when checking the installation status of the resources
  /// used by the TextToSpeech engine with the \#ACTION_CHECK_TTS_DATA intent.
  ///@deprecated Use CHECK_VOICE_DATA_FAIL instead.
  static const CHECK_VOICE_DATA_MISSING_VOLUME = -3;

  /// from: static public final int CHECK_VOICE_DATA_PASS
  ///
  /// Indicates success when checking the installation status of the resources used by the
  /// TextToSpeech engine with the \#ACTION_CHECK_TTS_DATA intent.
  static const CHECK_VOICE_DATA_PASS = 1;

  /// from: static public final int DEFAULT_STREAM
  ///
  /// Default audio stream used when playing synthesized speech.
  static const DEFAULT_STREAM = 3;

  /// from: static public final java.lang.String EXTRA_AVAILABLE_VOICES
  ///
  /// Extra information received with the \#ACTION_CHECK_TTS_DATA intent result where
  /// the TextToSpeech engine returns an ArrayList<String> of all the available voices.
  /// The format of each voice is: lang-COUNTRY-variant where COUNTRY and variant are
  /// optional (ie, "eng" or "eng-USA" or "eng-USA-FEMALE").
  static const EXTRA_AVAILABLE_VOICES = "availableVoices";

  /// from: static public final java.lang.String EXTRA_CHECK_VOICE_DATA_FOR
  ///
  /// Extra information sent with the \#ACTION_CHECK_TTS_DATA intent where the
  /// caller indicates to the TextToSpeech engine which specific sets of voice data to
  /// check for by sending an ArrayList<String> of the voices that are of interest.
  /// The format of each voice is: lang-COUNTRY-variant where COUNTRY and variant are
  /// optional (ie, "eng" or "eng-USA" or "eng-USA-FEMALE").
  ///@deprecated Redundant functionality, checking for existence of specific sets of voice
  /// data can be done on client side.
  static const EXTRA_CHECK_VOICE_DATA_FOR = "checkVoiceDataFor";

  /// from: static public final java.lang.String EXTRA_SAMPLE_TEXT
  ///
  /// Extra information received with the \#ACTION_GET_SAMPLE_TEXT intent result where
  /// the TextToSpeech engine returns an String with sample text for requested voice
  static const EXTRA_SAMPLE_TEXT = "sampleText";

  /// from: static public final java.lang.String EXTRA_TTS_DATA_INSTALLED
  ///
  /// Extra information received with the \#ACTION_TTS_DATA_INSTALLED intent result.
  /// It indicates whether the data files for the synthesis engine were successfully
  /// installed. The installation was initiated with the  \#ACTION_INSTALL_TTS_DATA
  /// intent. The possible values for this extra are
  /// TextToSpeech\#SUCCESS and TextToSpeech\#ERROR.
  ///@deprecated No longer in use. If client is interested in information about what
  /// changed, it should use the ACTION_CHECK_TTS_DATA
  /// intent to discover available voices.
  static const EXTRA_TTS_DATA_INSTALLED = "dataInstalled";

  /// from: static public final java.lang.String EXTRA_UNAVAILABLE_VOICES
  ///
  /// Extra information received with the \#ACTION_CHECK_TTS_DATA intent result where
  /// the TextToSpeech engine returns an ArrayList<String> of all the unavailable voices.
  /// The format of each voice is: lang-COUNTRY-variant where COUNTRY and variant are
  /// optional (ie, "eng" or "eng-USA" or "eng-USA-FEMALE").
  static const EXTRA_UNAVAILABLE_VOICES = "unavailableVoices";

  /// from: static public final java.lang.String EXTRA_VOICE_DATA_FILES
  ///
  /// Extra information received with the \#ACTION_CHECK_TTS_DATA intent result where
  /// the TextToSpeech engine specifies the file names of its resources under the
  /// resource path.
  ///@deprecated TTS engine implementation detail, this information has no use for
  /// text-to-speech API client.
  static const EXTRA_VOICE_DATA_FILES = "dataFiles";

  /// from: static public final java.lang.String EXTRA_VOICE_DATA_FILES_INFO
  ///
  /// Extra information received with the \#ACTION_CHECK_TTS_DATA intent result where
  /// the TextToSpeech engine specifies the locale associated with each resource file.
  ///@deprecated TTS engine implementation detail, this information has no use for
  /// text-to-speech API client.
  static const EXTRA_VOICE_DATA_FILES_INFO = "dataFilesInfo";

  /// from: static public final java.lang.String EXTRA_VOICE_DATA_ROOT_DIRECTORY
  ///
  /// Extra information received with the \#ACTION_CHECK_TTS_DATA intent result where
  /// the TextToSpeech engine specifies the path to its resources.
  ///
  /// It may be used by language packages to find out where to put their data.
  ///@deprecated TTS engine implementation detail, this information has no use for
  /// text-to-speech API client.
  static const EXTRA_VOICE_DATA_ROOT_DIRECTORY = "dataRoot";

  /// from: static public final java.lang.String INTENT_ACTION_TTS_SERVICE
  ///
  /// Intent for starting a TTS service. Services that handle this intent must
  /// extend TextToSpeechService. Normal applications should not use this intent
  /// directly, instead they should talk to the TTS service using the the methods in this
  /// class.
  static const INTENT_ACTION_TTS_SERVICE = "android.intent.action.TTS_SERVICE";

  /// from: static public final java.lang.String KEY_FEATURE_EMBEDDED_SYNTHESIS
  ///
  /// Feature key for embedded synthesis. See TextToSpeech\#getFeatures(Locale)
  /// for a description of how feature keys work. If set and supported by the engine
  /// as per TextToSpeech\#getFeatures(Locale), the engine must synthesize
  /// text on-device (without making network requests).
  ///@see TextToSpeech\#speak(String, int, java.util.HashMap)
  ///@see TextToSpeech\#synthesizeToFile(String, java.util.HashMap, String)
  ///@see TextToSpeech\#getFeatures(java.util.Locale)
  ///@deprecated Starting from API level 21, to select embedded synthesis, call
  /// (TextToSpeech\#getVoices(), find a suitable embedded voice
  /// (Voice\#isNetworkConnectionRequired()) and pass it
  /// to TextToSpeech\#setVoice(Voice)).
  static const KEY_FEATURE_EMBEDDED_SYNTHESIS = "embeddedTts";

  /// from: static public final java.lang.String KEY_FEATURE_NETWORK_RETRIES_COUNT
  ///
  /// Feature key that indicates that network request retries count can be set for the request.
  /// If set and supported as per TextToSpeech\#getFeatures(Locale) or
  /// Voice\#getFeatures(), it can be used as a request parameter to set the
  /// number of network request retries that are attempted in case of failure. When used as
  /// a key of a request parameter, its value should be a string with an integer value.
  ///@see TextToSpeech\#getFeatures(java.util.Locale)
  ///@see Voice\#getFeatures()
  static const KEY_FEATURE_NETWORK_RETRIES_COUNT = "networkRetriesCount";

  /// from: static public final java.lang.String KEY_FEATURE_NETWORK_SYNTHESIS
  ///
  /// Feature key for network synthesis. See TextToSpeech\#getFeatures(Locale)
  /// for a description of how feature keys work. If set (and supported by the engine
  /// as per TextToSpeech\#getFeatures(Locale), the engine must
  /// use network based synthesis.
  ///@see TextToSpeech\#speak(String, int, java.util.HashMap)
  ///@see TextToSpeech\#synthesizeToFile(String, java.util.HashMap, String)
  ///@see TextToSpeech\#getFeatures(java.util.Locale)
  ///@deprecated Starting from API level 21, to select network synthesis, call
  /// TextToSpeech\#getVoices(), find a suitable network voice
  /// (Voice\#isNetworkConnectionRequired()) and pass it
  /// to TextToSpeech\#setVoice(Voice).
  static const KEY_FEATURE_NETWORK_SYNTHESIS = "networkTts";

  /// from: static public final java.lang.String KEY_FEATURE_NETWORK_TIMEOUT_MS
  ///
  /// Feature key that indicate that a network timeout can be set for the request. If set and
  /// supported as per TextToSpeech\#getFeatures(Locale) or Voice\#getFeatures(),
  /// it can be used as request parameter to set the maximum allowed time for a single
  /// request attempt, in milliseconds, before synthesis fails. When used as a key of
  /// a request parameter, its value should be a string with an integer value.
  ///@see TextToSpeech\#getFeatures(java.util.Locale)
  ///@see Voice\#getFeatures()
  static const KEY_FEATURE_NETWORK_TIMEOUT_MS = "networkTimeoutMs";

  /// from: static public final java.lang.String KEY_FEATURE_NOT_INSTALLED
  ///
  /// Feature key that indicates that the voice may need to download additional data to be fully
  /// functional. The download will be triggered by calling
  /// TextToSpeech\#setVoice(Voice) or TextToSpeech\#setLanguage(Locale).
  /// Until download is complete, each synthesis request will either report
  /// TextToSpeech\#ERROR_NOT_INSTALLED_YET error, or use a different voice to synthesize
  /// the request. This feature should NOT be used as a key of a request parameter.
  ///@see TextToSpeech\#getFeatures(java.util.Locale)
  ///@see Voice\#getFeatures()
  static const KEY_FEATURE_NOT_INSTALLED = "notInstalled";

  /// from: static public final java.lang.String KEY_PARAM_PAN
  ///
  /// Parameter key to specify how the speech is panned from left to right when speaking text.
  /// Pan is specified as a float ranging from -1 to +1 where -1 maps to a hard-left pan,
  /// 0 to center (the default behavior), and +1 to hard-right.
  ///@see TextToSpeech\#speak(String, int, HashMap)
  ///@see TextToSpeech\#playEarcon(String, int, HashMap)
  static const KEY_PARAM_PAN = "pan";

  /// from: static public final java.lang.String KEY_PARAM_SESSION_ID
  ///
  /// Parameter key to specify an audio session identifier (obtained from
  /// AudioManager\#generateAudioSessionId()) that will be used by the request audio
  /// output. It can be used to associate one of the android.media.audiofx.AudioEffect
  /// objects with the synthesis (or earcon) output.
  ///@see TextToSpeech\#speak(String, int, HashMap)
  ///@see TextToSpeech\#playEarcon(String, int, HashMap)
  static const KEY_PARAM_SESSION_ID = "sessionId";

  /// from: static public final java.lang.String KEY_PARAM_STREAM
  ///
  /// Parameter key to specify the audio stream type to be used when speaking text
  /// or playing back a file. The value should be one of the STREAM_ constants
  /// defined in AudioManager.
  ///@see TextToSpeech\#speak(String, int, HashMap)
  ///@see TextToSpeech\#playEarcon(String, int, HashMap)
  static const KEY_PARAM_STREAM = "streamType";

  /// from: static public final java.lang.String KEY_PARAM_UTTERANCE_ID
  ///
  /// Parameter key to identify an utterance in the
  /// TextToSpeech.OnUtteranceCompletedListener after text has been
  /// spoken, a file has been played back or a silence duration has elapsed.
  ///@see TextToSpeech\#speak(String, int, HashMap)
  ///@see TextToSpeech\#playEarcon(String, int, HashMap)
  ///@see TextToSpeech\#synthesizeToFile(String, HashMap, String)
  static const KEY_PARAM_UTTERANCE_ID = "utteranceId";

  /// from: static public final java.lang.String KEY_PARAM_VOLUME
  ///
  /// Parameter key to specify the speech volume relative to the current stream type
  /// volume used when speaking text. Volume is specified as a float ranging from 0 to 1
  /// where 0 is silence, and 1 is the maximum volume (the default behavior).
  ///@see TextToSpeech\#speak(String, int, HashMap)
  ///@see TextToSpeech\#playEarcon(String, int, HashMap)
  static const KEY_PARAM_VOLUME = "volume";

  /// from: static public final java.lang.String SERVICE_META_DATA
  ///
  /// Name under which a text to speech engine publishes information about itself.
  /// This meta-data should reference an XML resource containing a
  /// <code>&lt;android.R.styleable\#TextToSpeechEngine tts-engine&gt;</code>
  /// tag.
  static const SERVICE_META_DATA = "android.speech.tts";

  static final _id_ctor =
      jniAccessors.getMethodIDOf(_classRef, "<init>", "()V");

  /// from: public void <init>()
  /// The returned object must be deleted after use, by calling the `delete` method.
  TextToSpeech_Engine()
      : super.fromRef(
            jniAccessors.newObjectWithArgs(_classRef, _id_ctor, []).object);
}
