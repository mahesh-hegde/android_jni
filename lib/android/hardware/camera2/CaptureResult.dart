// Autogenerated by jnigen. DO NOT EDIT!

// ignore_for_file: camel_case_types
// ignore_for_file: file_names
// ignore_for_file: non_constant_identifier_names
// ignore_for_file: constant_identifier_names
// ignore_for_file: unused_shown_name
// ignore_for_file: annotate_overrides
// ignore_for_file: no_leading_underscores_for_local_identifiers
// ignore_for_file: unused_import
// ignore_for_file: unused_element
// ignore_for_file: unused_field

import "package:jni/jni.dart" as jni;

import "package:jni/internal_helpers_for_jnigen.dart";

import "CameraMetadata.dart" as camerametadata_;

import "CaptureRequest.dart" as capturerequest_;
import "../../../_init.dart" show jniEnv, jniAccessors;

/// from: android.hardware.camera2.CaptureResult
///
/// The subset of the results of a single image capture from the image sensor.
///
///
/// Contains a subset of the final configuration for the capture hardware (sensor, lens,
/// flash), the processing pipeline, the control algorithms, and the output
/// buffers.
///
///
/// CaptureResults are produced by a CameraDevice after processing a
/// CaptureRequest. All properties listed for capture requests can also
/// be queried on the capture result, to determine the final values used for
/// capture. The result also includes additional metadata about the state of the
/// camera device during the capture.
///
///
/// Not all properties returned by CameraCharacteristics\#getAvailableCaptureResultKeys()
/// are necessarily available. Some results are CaptureResult partial and will
/// not have every key set. Only TotalCaptureResult total results are guaranteed to have
/// every key available that was enabled by the request.
///
///
/// CaptureResult objects are immutable.
///
class CaptureResult extends camerametadata_.CameraMetadata {
  static final _classRef =
      jniAccessors.getClassOf("android/hardware/camera2/CaptureResult");
  CaptureResult.fromRef(jni.JObject ref) : super.fromRef(ref);

  static final _id_BLACK_LEVEL_LOCK = jniAccessors.getStaticFieldIDOf(_classRef,
      "BLACK_LEVEL_LOCK", "Landroid/hardware/camera2/CaptureResult\$Key;");

  /// from: static public final android.hardware.camera2.CaptureResult.Key<java.lang.Boolean> BLACK_LEVEL_LOCK
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// Whether black-level compensation is locked
  /// to its current values, or is free to vary.
  ///
  /// Whether the black level offset was locked for this frame.  Should be
  /// ON if CaptureRequest\#BLACK_LEVEL_LOCK android.blackLevel.lock was ON in the capture request, unless
  /// a change in other capture settings forced the camera device to
  /// perform a black level reset.
  ///
  /// __Optional__ - This value may be {@code null} on some devices.
  ///
  /// __Full capability__ -
  /// Present on all camera devices that report being CameraCharacteristics\#INFO_SUPPORTED_HARDWARE_LEVEL_FULL HARDWARE_LEVEL_FULL devices in the
  /// CameraCharacteristics\#INFO_SUPPORTED_HARDWARE_LEVEL android.info.supportedHardwareLevel key
  ///
  ///@see CaptureRequest\#BLACK_LEVEL_LOCK
  ///@see CameraCharacteristics\#INFO_SUPPORTED_HARDWARE_LEVEL
  static CaptureResult_Key get BLACK_LEVEL_LOCK =>
      CaptureResult_Key.fromRef(jniAccessors
          .getStaticField(
              _classRef, _id_BLACK_LEVEL_LOCK, jni.JniType.objectType)
          .object);

  static final _id_COLOR_CORRECTION_ABERRATION_MODE =
      jniAccessors.getStaticFieldIDOf(
          _classRef,
          "COLOR_CORRECTION_ABERRATION_MODE",
          "Landroid/hardware/camera2/CaptureResult\$Key;");

  /// from: static public final android.hardware.camera2.CaptureResult.Key<java.lang.Integer> COLOR_CORRECTION_ABERRATION_MODE
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// Mode of operation for the chromatic aberration correction algorithm.
  ///
  /// Chromatic (color) aberration is caused by the fact that different wavelengths of light
  /// can not focus on the same point after exiting from the lens. This metadata defines
  /// the high level control of chromatic aberration correction algorithm, which aims to
  /// minimize the chromatic artifacts that may occur along the object boundaries in an
  /// image.
  ///
  /// FAST/HIGH_QUALITY both mean that camera device determined aberration
  /// correction will be applied. HIGH_QUALITY mode indicates that the camera device will
  /// use the highest-quality aberration correction algorithms, even if it slows down
  /// capture rate. FAST means the camera device will not slow down capture rate when
  /// applying aberration correction.
  ///
  /// LEGACY devices will always be in FAST mode.
  ///
  /// __Possible values:__
  /// <ul>
  ///   <li>\#COLOR_CORRECTION_ABERRATION_MODE_OFF OFF</li>
  ///   <li>\#COLOR_CORRECTION_ABERRATION_MODE_FAST FAST</li>
  ///   <li>\#COLOR_CORRECTION_ABERRATION_MODE_HIGH_QUALITY HIGH_QUALITY</li>
  /// </ul>
  ///
  /// __Available values for this device:__<br>
  /// CameraCharacteristics\#COLOR_CORRECTION_AVAILABLE_ABERRATION_MODES android.colorCorrection.availableAberrationModes
  ///
  /// This key is available on all devices.
  ///
  ///@see CameraCharacteristics\#COLOR_CORRECTION_AVAILABLE_ABERRATION_MODES
  ///@see \#COLOR_CORRECTION_ABERRATION_MODE_OFF
  ///@see \#COLOR_CORRECTION_ABERRATION_MODE_FAST
  ///@see \#COLOR_CORRECTION_ABERRATION_MODE_HIGH_QUALITY
  static CaptureResult_Key get COLOR_CORRECTION_ABERRATION_MODE =>
      CaptureResult_Key.fromRef(jniAccessors
          .getStaticField(_classRef, _id_COLOR_CORRECTION_ABERRATION_MODE,
              jni.JniType.objectType)
          .object);

  static final _id_COLOR_CORRECTION_GAINS = jniAccessors.getStaticFieldIDOf(
      _classRef,
      "COLOR_CORRECTION_GAINS",
      "Landroid/hardware/camera2/CaptureResult\$Key;");

  /// from: static public final android.hardware.camera2.CaptureResult.Key<android.hardware.camera2.params.RggbChannelVector> COLOR_CORRECTION_GAINS
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// Gains applying to Bayer raw color channels for
  /// white-balance.
  ///
  /// These per-channel gains are either set by the camera device
  /// when the request CaptureRequest\#COLOR_CORRECTION_MODE android.colorCorrection.mode is not
  /// TRANSFORM_MATRIX, or directly by the application in the
  /// request when the CaptureRequest\#COLOR_CORRECTION_MODE android.colorCorrection.mode is
  /// TRANSFORM_MATRIX.
  ///
  /// The gains in the result metadata are the gains actually
  /// applied by the camera device to the current frame.
  ///
  /// The valid range of gains varies on different devices, but gains
  /// between [1.0, 3.0] are guaranteed not to be clipped. Even if a given
  /// device allows gains below 1.0, this is usually not recommended because
  /// this can create color artifacts.
  ///
  /// __Units__: Unitless gain factors
  ///
  /// __Optional__ - This value may be {@code null} on some devices.
  ///
  /// __Full capability__ -
  /// Present on all camera devices that report being CameraCharacteristics\#INFO_SUPPORTED_HARDWARE_LEVEL_FULL HARDWARE_LEVEL_FULL devices in the
  /// CameraCharacteristics\#INFO_SUPPORTED_HARDWARE_LEVEL android.info.supportedHardwareLevel key
  ///
  ///@see CaptureRequest\#COLOR_CORRECTION_MODE
  ///@see CameraCharacteristics\#INFO_SUPPORTED_HARDWARE_LEVEL
  static CaptureResult_Key get COLOR_CORRECTION_GAINS =>
      CaptureResult_Key.fromRef(jniAccessors
          .getStaticField(
              _classRef, _id_COLOR_CORRECTION_GAINS, jni.JniType.objectType)
          .object);

  static final _id_COLOR_CORRECTION_MODE = jniAccessors.getStaticFieldIDOf(
      _classRef,
      "COLOR_CORRECTION_MODE",
      "Landroid/hardware/camera2/CaptureResult\$Key;");

  /// from: static public final android.hardware.camera2.CaptureResult.Key<java.lang.Integer> COLOR_CORRECTION_MODE
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// The mode control selects how the image data is converted from the
  /// sensor's native color into linear sRGB color.
  ///
  /// When auto-white balance (AWB) is enabled with CaptureRequest\#CONTROL_AWB_MODE android.control.awbMode, this
  /// control is overridden by the AWB routine. When AWB is disabled, the
  /// application controls how the color mapping is performed.
  ///
  /// We define the expected processing pipeline below. For consistency
  /// across devices, this is always the case with TRANSFORM_MATRIX.
  ///
  /// When either FULL or HIGH_QUALITY is used, the camera device may
  /// do additional processing but CaptureRequest\#COLOR_CORRECTION_GAINS android.colorCorrection.gains and
  /// CaptureRequest\#COLOR_CORRECTION_TRANSFORM android.colorCorrection.transform will still be provided by the
  /// camera device (in the results) and be roughly correct.
  ///
  /// Switching to TRANSFORM_MATRIX and using the data provided from
  /// FAST or HIGH_QUALITY will yield a picture with the same white point
  /// as what was produced by the camera device in the earlier frame.
  ///
  /// The expected processing pipeline is as follows:
  ///
  /// <img alt="White balance processing pipeline"src="/reference/images/camera2/metadata/android.colorCorrection.mode/processing_pipeline.png"/>
  ///
  /// The white balance is encoded by two values, a 4-channel white-balance
  /// gain vector (applied in the Bayer domain), and a 3x3 color transform
  /// matrix (applied after demosaic).
  ///
  /// The 4-channel white-balance gains are defined as:
  ///
  /// <pre><code>CaptureRequest\#COLOR_CORRECTION_GAINS android.colorCorrection.gains = [ R G_even G_odd B ]
  /// </code></pre>
  /// where <code>G_even</code> is the gain for green pixels on even rows of the
  /// output, and <code>G_odd</code> is the gain for green pixels on the odd rows.
  /// These may be identical for a given camera device implementation; if
  /// the camera device does not support a separate gain for even/odd green
  /// channels, it will use the <code>G_even</code> value, and write <code>G_odd</code> equal to
  /// <code>G_even</code> in the output result metadata.
  ///
  /// The matrices for color transforms are defined as a 9-entry vector:
  ///
  /// <pre><code>CaptureRequest\#COLOR_CORRECTION_TRANSFORM android.colorCorrection.transform = [ I0 I1 I2 I3 I4 I5 I6 I7 I8 ]
  /// </code></pre>
  /// which define a transform from input sensor colors, <code>P_in = [ r g b ]</code>,
  /// to output linear sRGB, <code>P_out = [ r' g' b' ]</code>,
  ///
  /// with colors as follows:
  ///
  /// <pre><code>r' = I0r + I1g + I2b
  /// g' = I3r + I4g + I5b
  /// b' = I6r + I7g + I8b
  /// </code></pre>
  /// Both the input and output value ranges must match. Overflow/underflow
  /// values are clipped to fit within the range.
  ///
  /// __Possible values:__
  /// <ul>
  ///   <li>\#COLOR_CORRECTION_MODE_TRANSFORM_MATRIX TRANSFORM_MATRIX</li>
  ///   <li>\#COLOR_CORRECTION_MODE_FAST FAST</li>
  ///   <li>\#COLOR_CORRECTION_MODE_HIGH_QUALITY HIGH_QUALITY</li>
  /// </ul>
  ///
  /// __Optional__ - This value may be {@code null} on some devices.
  ///
  /// __Full capability__ -
  /// Present on all camera devices that report being CameraCharacteristics\#INFO_SUPPORTED_HARDWARE_LEVEL_FULL HARDWARE_LEVEL_FULL devices in the
  /// CameraCharacteristics\#INFO_SUPPORTED_HARDWARE_LEVEL android.info.supportedHardwareLevel key
  ///
  ///@see CaptureRequest\#COLOR_CORRECTION_GAINS
  ///@see CaptureRequest\#COLOR_CORRECTION_TRANSFORM
  ///@see CaptureRequest\#CONTROL_AWB_MODE
  ///@see CameraCharacteristics\#INFO_SUPPORTED_HARDWARE_LEVEL
  ///@see \#COLOR_CORRECTION_MODE_TRANSFORM_MATRIX
  ///@see \#COLOR_CORRECTION_MODE_FAST
  ///@see \#COLOR_CORRECTION_MODE_HIGH_QUALITY
  static CaptureResult_Key get COLOR_CORRECTION_MODE =>
      CaptureResult_Key.fromRef(jniAccessors
          .getStaticField(
              _classRef, _id_COLOR_CORRECTION_MODE, jni.JniType.objectType)
          .object);

  static final _id_COLOR_CORRECTION_TRANSFORM = jniAccessors.getStaticFieldIDOf(
      _classRef,
      "COLOR_CORRECTION_TRANSFORM",
      "Landroid/hardware/camera2/CaptureResult\$Key;");

  /// from: static public final android.hardware.camera2.CaptureResult.Key<android.hardware.camera2.params.ColorSpaceTransform> COLOR_CORRECTION_TRANSFORM
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// A color transform matrix to use to transform
  /// from sensor RGB color space to output linear sRGB color space.
  ///
  /// This matrix is either set by the camera device when the request
  /// CaptureRequest\#COLOR_CORRECTION_MODE android.colorCorrection.mode is not TRANSFORM_MATRIX, or
  /// directly by the application in the request when the
  /// CaptureRequest\#COLOR_CORRECTION_MODE android.colorCorrection.mode is TRANSFORM_MATRIX.
  ///
  /// In the latter case, the camera device may round the matrix to account
  /// for precision issues; the final rounded matrix should be reported back
  /// in this matrix result metadata. The transform should keep the magnitude
  /// of the output color values within <code>[0, 1.0]</code> (assuming input color
  /// values is within the normalized range <code>[0, 1.0]</code>), or clipping may occur.
  ///
  /// The valid range of each matrix element varies on different devices, but
  /// values within [-1.5, 3.0] are guaranteed not to be clipped.
  ///
  /// __Units__: Unitless scale factors
  ///
  /// __Optional__ - This value may be {@code null} on some devices.
  ///
  /// __Full capability__ -
  /// Present on all camera devices that report being CameraCharacteristics\#INFO_SUPPORTED_HARDWARE_LEVEL_FULL HARDWARE_LEVEL_FULL devices in the
  /// CameraCharacteristics\#INFO_SUPPORTED_HARDWARE_LEVEL android.info.supportedHardwareLevel key
  ///
  ///@see CaptureRequest\#COLOR_CORRECTION_MODE
  ///@see CameraCharacteristics\#INFO_SUPPORTED_HARDWARE_LEVEL
  static CaptureResult_Key get COLOR_CORRECTION_TRANSFORM =>
      CaptureResult_Key.fromRef(jniAccessors
          .getStaticField(
              _classRef, _id_COLOR_CORRECTION_TRANSFORM, jni.JniType.objectType)
          .object);

  static final _id_CONTROL_AE_ANTIBANDING_MODE =
      jniAccessors.getStaticFieldIDOf(_classRef, "CONTROL_AE_ANTIBANDING_MODE",
          "Landroid/hardware/camera2/CaptureResult\$Key;");

  /// from: static public final android.hardware.camera2.CaptureResult.Key<java.lang.Integer> CONTROL_AE_ANTIBANDING_MODE
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// The desired setting for the camera device's auto-exposure
  /// algorithm's antibanding compensation.
  ///
  /// Some kinds of lighting fixtures, such as some fluorescent
  /// lights, flicker at the rate of the power supply frequency
  /// (60Hz or 50Hz, depending on country). While this is
  /// typically not noticeable to a person, it can be visible to
  /// a camera device. If a camera sets its exposure time to the
  /// wrong value, the flicker may become visible in the
  /// viewfinder as flicker or in a final captured image, as a
  /// set of variable-brightness bands across the image.
  ///
  /// Therefore, the auto-exposure routines of camera devices
  /// include antibanding routines that ensure that the chosen
  /// exposure value will not cause such banding. The choice of
  /// exposure time depends on the rate of flicker, which the
  /// camera device can detect automatically, or the expected
  /// rate can be selected by the application using this
  /// control.
  ///
  /// A given camera device may not support all of the possible
  /// options for the antibanding mode. The
  /// CameraCharacteristics\#CONTROL_AE_AVAILABLE_ANTIBANDING_MODES android.control.aeAvailableAntibandingModes key contains
  /// the available modes for a given camera device.
  ///
  /// AUTO mode is the default if it is available on given
  /// camera device. When AUTO mode is not available, the
  /// default will be either 50HZ or 60HZ, and both 50HZ
  /// and 60HZ will be available.
  ///
  /// If manual exposure control is enabled (by setting
  /// CaptureRequest\#CONTROL_AE_MODE android.control.aeMode or CaptureRequest\#CONTROL_MODE android.control.mode to OFF),
  /// then this setting has no effect, and the application must
  /// ensure it selects exposure times that do not cause banding
  /// issues. The CaptureResult\#STATISTICS_SCENE_FLICKER android.statistics.sceneFlicker key can assist
  /// the application in this.
  ///
  /// __Possible values:__
  /// <ul>
  ///   <li>\#CONTROL_AE_ANTIBANDING_MODE_OFF OFF</li>
  ///   <li>\#CONTROL_AE_ANTIBANDING_MODE_50HZ 50HZ</li>
  ///   <li>\#CONTROL_AE_ANTIBANDING_MODE_60HZ 60HZ</li>
  ///   <li>\#CONTROL_AE_ANTIBANDING_MODE_AUTO AUTO</li>
  /// </ul>
  ///
  /// __Available values for this device:__<br>
  ///
  /// CameraCharacteristics\#CONTROL_AE_AVAILABLE_ANTIBANDING_MODES android.control.aeAvailableAntibandingModes
  ///
  /// This key is available on all devices.
  ///
  ///@see CameraCharacteristics\#CONTROL_AE_AVAILABLE_ANTIBANDING_MODES
  ///@see CaptureRequest\#CONTROL_AE_MODE
  ///@see CaptureRequest\#CONTROL_MODE
  ///@see CaptureResult\#STATISTICS_SCENE_FLICKER
  ///@see \#CONTROL_AE_ANTIBANDING_MODE_OFF
  ///@see \#CONTROL_AE_ANTIBANDING_MODE_50HZ
  ///@see \#CONTROL_AE_ANTIBANDING_MODE_60HZ
  ///@see \#CONTROL_AE_ANTIBANDING_MODE_AUTO
  static CaptureResult_Key get CONTROL_AE_ANTIBANDING_MODE =>
      CaptureResult_Key.fromRef(jniAccessors
          .getStaticField(_classRef, _id_CONTROL_AE_ANTIBANDING_MODE,
              jni.JniType.objectType)
          .object);

  static final _id_CONTROL_AE_EXPOSURE_COMPENSATION =
      jniAccessors.getStaticFieldIDOf(
          _classRef,
          "CONTROL_AE_EXPOSURE_COMPENSATION",
          "Landroid/hardware/camera2/CaptureResult\$Key;");

  /// from: static public final android.hardware.camera2.CaptureResult.Key<java.lang.Integer> CONTROL_AE_EXPOSURE_COMPENSATION
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// Adjustment to auto-exposure (AE) target image
  /// brightness.
  ///
  /// The adjustment is measured as a count of steps, with the
  /// step size defined by CameraCharacteristics\#CONTROL_AE_COMPENSATION_STEP android.control.aeCompensationStep and the
  /// allowed range by CameraCharacteristics\#CONTROL_AE_COMPENSATION_RANGE android.control.aeCompensationRange.
  ///
  /// For example, if the exposure value (EV) step is 0.333, '6'
  /// will mean an exposure compensation of +2 EV; -3 will mean an
  /// exposure compensation of -1 EV. One EV represents a doubling
  /// of image brightness. Note that this control will only be
  /// effective if CaptureRequest\#CONTROL_AE_MODE android.control.aeMode <code>!=</code> OFF. This control
  /// will take effect even when CaptureRequest\#CONTROL_AE_LOCK android.control.aeLock <code>== true</code>.
  ///
  /// In the event of exposure compensation value being changed, camera device
  /// may take several frames to reach the newly requested exposure target.
  /// During that time, CaptureResult\#CONTROL_AE_STATE android.control.aeState field will be in the SEARCHING
  /// state. Once the new exposure target is reached, CaptureResult\#CONTROL_AE_STATE android.control.aeState will
  /// change from SEARCHING to either CONVERGED, LOCKED (if AE lock is enabled), or
  /// FLASH_REQUIRED (if the scene is too dark for still capture).
  ///
  /// __Units__: Compensation steps
  ///
  /// __Range of valid values:__<br>
  /// CameraCharacteristics\#CONTROL_AE_COMPENSATION_RANGE android.control.aeCompensationRange
  ///
  /// This key is available on all devices.
  ///
  ///@see CameraCharacteristics\#CONTROL_AE_COMPENSATION_RANGE
  ///@see CameraCharacteristics\#CONTROL_AE_COMPENSATION_STEP
  ///@see CaptureRequest\#CONTROL_AE_LOCK
  ///@see CaptureRequest\#CONTROL_AE_MODE
  ///@see CaptureResult\#CONTROL_AE_STATE
  static CaptureResult_Key get CONTROL_AE_EXPOSURE_COMPENSATION =>
      CaptureResult_Key.fromRef(jniAccessors
          .getStaticField(_classRef, _id_CONTROL_AE_EXPOSURE_COMPENSATION,
              jni.JniType.objectType)
          .object);

  static final _id_CONTROL_AE_LOCK = jniAccessors.getStaticFieldIDOf(_classRef,
      "CONTROL_AE_LOCK", "Landroid/hardware/camera2/CaptureResult\$Key;");

  /// from: static public final android.hardware.camera2.CaptureResult.Key<java.lang.Boolean> CONTROL_AE_LOCK
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// Whether auto-exposure (AE) is currently locked to its latest
  /// calculated values.
  ///
  /// When set to <code>true</code> (ON), the AE algorithm is locked to its latest parameters,
  /// and will not change exposure settings until the lock is set to <code>false</code> (OFF).
  ///
  /// Note that even when AE is locked, the flash may be fired if
  /// the CaptureRequest\#CONTROL_AE_MODE android.control.aeMode is ON_AUTO_FLASH /
  /// ON_ALWAYS_FLASH / ON_AUTO_FLASH_REDEYE.
  ///
  /// When CaptureRequest\#CONTROL_AE_EXPOSURE_COMPENSATION android.control.aeExposureCompensation is changed, even if the AE lock
  /// is ON, the camera device will still adjust its exposure value.
  ///
  /// If AE precapture is triggered (see CaptureRequest\#CONTROL_AE_PRECAPTURE_TRIGGER android.control.aePrecaptureTrigger)
  /// when AE is already locked, the camera device will not change the exposure time
  /// (CaptureRequest\#SENSOR_EXPOSURE_TIME android.sensor.exposureTime) and sensitivity (CaptureRequest\#SENSOR_SENSITIVITY android.sensor.sensitivity)
  /// parameters. The flash may be fired if the CaptureRequest\#CONTROL_AE_MODE android.control.aeMode
  /// is ON_AUTO_FLASH/ON_AUTO_FLASH_REDEYE and the scene is too dark. If the
  /// CaptureRequest\#CONTROL_AE_MODE android.control.aeMode is ON_ALWAYS_FLASH, the scene may become overexposed.
  /// Similarly, AE precapture trigger CANCEL has no effect when AE is already locked.
  ///
  /// When an AE precapture sequence is triggered, AE unlock will not be able to unlock
  /// the AE if AE is locked by the camera device internally during precapture metering
  /// sequence In other words, submitting requests with AE unlock has no effect for an
  /// ongoing precapture metering sequence. Otherwise, the precapture metering sequence
  /// will never succeed in a sequence of preview requests where AE lock is always set
  /// to <code>false</code>.
  ///
  /// Since the camera device has a pipeline of in-flight requests, the settings that
  /// get locked do not necessarily correspond to the settings that were present in the
  /// latest capture result received from the camera device, since additional captures
  /// and AE updates may have occurred even before the result was sent out. If an
  /// application is switching between automatic and manual control and wishes to eliminate
  /// any flicker during the switch, the following procedure is recommended:
  ///
  /// <ol>
  /// <li>Starting in auto-AE mode:</li>
  /// <li>Lock AE</li>
  /// <li>Wait for the first result to be output that has the AE locked</li>
  /// <li>Copy exposure settings from that result into a request, set the request to manual AE</li>
  /// <li>Submit the capture request, proceed to run manual AE as desired.</li>
  /// </ol>
  /// See CaptureResult\#CONTROL_AE_STATE android.control.aeState for AE lock related state transition details.
  ///
  /// This key is available on all devices.
  ///
  ///@see CaptureRequest\#CONTROL_AE_EXPOSURE_COMPENSATION
  ///@see CaptureRequest\#CONTROL_AE_MODE
  ///@see CaptureRequest\#CONTROL_AE_PRECAPTURE_TRIGGER
  ///@see CaptureResult\#CONTROL_AE_STATE
  ///@see CaptureRequest\#SENSOR_EXPOSURE_TIME
  ///@see CaptureRequest\#SENSOR_SENSITIVITY
  static CaptureResult_Key get CONTROL_AE_LOCK =>
      CaptureResult_Key.fromRef(jniAccessors
          .getStaticField(
              _classRef, _id_CONTROL_AE_LOCK, jni.JniType.objectType)
          .object);

  static final _id_CONTROL_AE_MODE = jniAccessors.getStaticFieldIDOf(_classRef,
      "CONTROL_AE_MODE", "Landroid/hardware/camera2/CaptureResult\$Key;");

  /// from: static public final android.hardware.camera2.CaptureResult.Key<java.lang.Integer> CONTROL_AE_MODE
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// The desired mode for the camera device's
  /// auto-exposure routine.
  ///
  /// This control is only effective if CaptureRequest\#CONTROL_MODE android.control.mode is
  /// AUTO.
  ///
  /// When set to any of the ON modes, the camera device's
  /// auto-exposure routine is enabled, overriding the
  /// application's selected exposure time, sensor sensitivity,
  /// and frame duration (CaptureRequest\#SENSOR_EXPOSURE_TIME android.sensor.exposureTime,
  /// CaptureRequest\#SENSOR_SENSITIVITY android.sensor.sensitivity, and
  /// CaptureRequest\#SENSOR_FRAME_DURATION android.sensor.frameDuration). If one of the FLASH modes
  /// is selected, the camera device's flash unit controls are
  /// also overridden.
  ///
  /// The FLASH modes are only available if the camera device
  /// has a flash unit (CameraCharacteristics\#FLASH_INFO_AVAILABLE android.flash.info.available is <code>true</code>).
  ///
  /// If flash TORCH mode is desired, this field must be set to
  /// ON or OFF, and CaptureRequest\#FLASH_MODE android.flash.mode set to TORCH.
  ///
  /// When set to any of the ON modes, the values chosen by the
  /// camera device auto-exposure routine for the overridden
  /// fields for a given capture will be available in its
  /// CaptureResult.
  ///
  /// __Possible values:__
  /// <ul>
  ///   <li>\#CONTROL_AE_MODE_OFF OFF</li>
  ///   <li>\#CONTROL_AE_MODE_ON ON</li>
  ///   <li>\#CONTROL_AE_MODE_ON_AUTO_FLASH ON_AUTO_FLASH</li>
  ///   <li>\#CONTROL_AE_MODE_ON_ALWAYS_FLASH ON_ALWAYS_FLASH</li>
  ///   <li>\#CONTROL_AE_MODE_ON_AUTO_FLASH_REDEYE ON_AUTO_FLASH_REDEYE</li>
  ///   <li>\#CONTROL_AE_MODE_ON_EXTERNAL_FLASH ON_EXTERNAL_FLASH</li>
  /// </ul>
  ///
  /// __Available values for this device:__<br>
  /// CameraCharacteristics\#CONTROL_AE_AVAILABLE_MODES android.control.aeAvailableModes
  ///
  /// This key is available on all devices.
  ///
  ///@see CameraCharacteristics\#CONTROL_AE_AVAILABLE_MODES
  ///@see CaptureRequest\#CONTROL_MODE
  ///@see CameraCharacteristics\#FLASH_INFO_AVAILABLE
  ///@see CaptureRequest\#FLASH_MODE
  ///@see CaptureRequest\#SENSOR_EXPOSURE_TIME
  ///@see CaptureRequest\#SENSOR_FRAME_DURATION
  ///@see CaptureRequest\#SENSOR_SENSITIVITY
  ///@see \#CONTROL_AE_MODE_OFF
  ///@see \#CONTROL_AE_MODE_ON
  ///@see \#CONTROL_AE_MODE_ON_AUTO_FLASH
  ///@see \#CONTROL_AE_MODE_ON_ALWAYS_FLASH
  ///@see \#CONTROL_AE_MODE_ON_AUTO_FLASH_REDEYE
  ///@see \#CONTROL_AE_MODE_ON_EXTERNAL_FLASH
  static CaptureResult_Key get CONTROL_AE_MODE =>
      CaptureResult_Key.fromRef(jniAccessors
          .getStaticField(
              _classRef, _id_CONTROL_AE_MODE, jni.JniType.objectType)
          .object);

  static final _id_CONTROL_AE_PRECAPTURE_TRIGGER =
      jniAccessors.getStaticFieldIDOf(
          _classRef,
          "CONTROL_AE_PRECAPTURE_TRIGGER",
          "Landroid/hardware/camera2/CaptureResult\$Key;");

  /// from: static public final android.hardware.camera2.CaptureResult.Key<java.lang.Integer> CONTROL_AE_PRECAPTURE_TRIGGER
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// Whether the camera device will trigger a precapture
  /// metering sequence when it processes this request.
  ///
  /// This entry is normally set to IDLE, or is not
  /// included at all in the request settings. When included and
  /// set to START, the camera device will trigger the auto-exposure (AE)
  /// precapture metering sequence.
  ///
  /// When set to CANCEL, the camera device will cancel any active
  /// precapture metering trigger, and return to its initial AE state.
  /// If a precapture metering sequence is already completed, and the camera
  /// device has implicitly locked the AE for subsequent still capture, the
  /// CANCEL trigger will unlock the AE and return to its initial AE state.
  ///
  /// The precapture sequence should be triggered before starting a
  /// high-quality still capture for final metering decisions to
  /// be made, and for firing pre-capture flash pulses to estimate
  /// scene brightness and required final capture flash power, when
  /// the flash is enabled.
  ///
  /// Normally, this entry should be set to START for only a
  /// single request, and the application should wait until the
  /// sequence completes before starting a new one.
  ///
  /// When a precapture metering sequence is finished, the camera device
  /// may lock the auto-exposure routine internally to be able to accurately expose the
  /// subsequent still capture image (<code>CaptureRequest\#CONTROL_CAPTURE_INTENT android.control.captureIntent == STILL_CAPTURE</code>).
  /// For this case, the AE may not resume normal scan if no subsequent still capture is
  /// submitted. To ensure that the AE routine restarts normal scan, the application should
  /// submit a request with <code>CaptureRequest\#CONTROL_AE_LOCK android.control.aeLock == true</code>, followed by a request
  /// with <code>CaptureRequest\#CONTROL_AE_LOCK android.control.aeLock == false</code>, if the application decides not to submit a
  /// still capture request after the precapture sequence completes. Alternatively, for
  /// API level 23 or newer devices, the CANCEL can be used to unlock the camera device
  /// internally locked AE if the application doesn't submit a still capture request after
  /// the AE precapture trigger. Note that, the CANCEL was added in API level 23, and must not
  /// be used in devices that have earlier API levels.
  ///
  /// The exact effect of auto-exposure (AE) precapture trigger
  /// depends on the current AE mode and state; see
  /// CaptureResult\#CONTROL_AE_STATE android.control.aeState for AE precapture state transition
  /// details.
  ///
  /// On LEGACY-level devices, the precapture trigger is not supported;
  /// capturing a high-resolution JPEG image will automatically trigger a
  /// precapture sequence before the high-resolution capture, including
  /// potentially firing a pre-capture flash.
  ///
  /// Using the precapture trigger and the auto-focus trigger CaptureRequest\#CONTROL_AF_TRIGGER android.control.afTrigger
  /// simultaneously is allowed. However, since these triggers often require cooperation between
  /// the auto-focus and auto-exposure routines (for example, the may need to be enabled for a
  /// focus sweep), the camera device may delay acting on a later trigger until the previous
  /// trigger has been fully handled. This may lead to longer intervals between the trigger and
  /// changes to CaptureResult\#CONTROL_AE_STATE android.control.aeState indicating the start of the precapture sequence, for
  /// example.
  ///
  /// If both the precapture and the auto-focus trigger are activated on the same request, then
  /// the camera device will complete them in the optimal order for that device.
  ///
  /// __Possible values:__
  /// <ul>
  ///   <li>\#CONTROL_AE_PRECAPTURE_TRIGGER_IDLE IDLE</li>
  ///   <li>\#CONTROL_AE_PRECAPTURE_TRIGGER_START START</li>
  ///   <li>\#CONTROL_AE_PRECAPTURE_TRIGGER_CANCEL CANCEL</li>
  /// </ul>
  ///
  /// __Optional__ - This value may be {@code null} on some devices.
  ///
  /// __Limited capability__ -
  /// Present on all camera devices that report being at least CameraCharacteristics\#INFO_SUPPORTED_HARDWARE_LEVEL_LIMITED HARDWARE_LEVEL_LIMITED devices in the
  /// CameraCharacteristics\#INFO_SUPPORTED_HARDWARE_LEVEL android.info.supportedHardwareLevel key
  ///
  ///@see CaptureRequest\#CONTROL_AE_LOCK
  ///@see CaptureResult\#CONTROL_AE_STATE
  ///@see CaptureRequest\#CONTROL_AF_TRIGGER
  ///@see CaptureRequest\#CONTROL_CAPTURE_INTENT
  ///@see CameraCharacteristics\#INFO_SUPPORTED_HARDWARE_LEVEL
  ///@see \#CONTROL_AE_PRECAPTURE_TRIGGER_IDLE
  ///@see \#CONTROL_AE_PRECAPTURE_TRIGGER_START
  ///@see \#CONTROL_AE_PRECAPTURE_TRIGGER_CANCEL
  static CaptureResult_Key get CONTROL_AE_PRECAPTURE_TRIGGER =>
      CaptureResult_Key.fromRef(jniAccessors
          .getStaticField(_classRef, _id_CONTROL_AE_PRECAPTURE_TRIGGER,
              jni.JniType.objectType)
          .object);

  static final _id_CONTROL_AE_REGIONS = jniAccessors.getStaticFieldIDOf(
      _classRef,
      "CONTROL_AE_REGIONS",
      "Landroid/hardware/camera2/CaptureResult\$Key;");

  /// from: static public final android.hardware.camera2.CaptureResult.Key<android.hardware.camera2.params.MeteringRectangle[]> CONTROL_AE_REGIONS
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// List of metering areas to use for auto-exposure adjustment.
  ///
  /// Not available if CameraCharacteristics\#CONTROL_MAX_REGIONS_AE android.control.maxRegionsAe is 0.
  /// Otherwise will always be present.
  ///
  /// The maximum number of regions supported by the device is determined by the value
  /// of CameraCharacteristics\#CONTROL_MAX_REGIONS_AE android.control.maxRegionsAe.
  ///
  /// For devices not supporting CaptureRequest\#DISTORTION_CORRECTION_MODE android.distortionCorrection.mode control, the coordinate
  /// system always follows that of CameraCharacteristics\#SENSOR_INFO_ACTIVE_ARRAY_SIZE android.sensor.info.activeArraySize, with (0,0) being
  /// the top-left pixel in the active pixel array, and
  /// (CameraCharacteristics\#SENSOR_INFO_ACTIVE_ARRAY_SIZE android.sensor.info.activeArraySize.width - 1,
  /// CameraCharacteristics\#SENSOR_INFO_ACTIVE_ARRAY_SIZE android.sensor.info.activeArraySize.height - 1) being the bottom-right pixel in the
  /// active pixel array.
  ///
  /// For devices supporting CaptureRequest\#DISTORTION_CORRECTION_MODE android.distortionCorrection.mode control, the coordinate
  /// system depends on the mode being set.
  /// When the distortion correction mode is OFF, the coordinate system follows
  /// CameraCharacteristics\#SENSOR_INFO_PRE_CORRECTION_ACTIVE_ARRAY_SIZE android.sensor.info.preCorrectionActiveArraySize, with
  /// <code>(0, 0)</code> being the top-left pixel of the pre-correction active array, and
  /// (CameraCharacteristics\#SENSOR_INFO_PRE_CORRECTION_ACTIVE_ARRAY_SIZE android.sensor.info.preCorrectionActiveArraySize.width - 1,
  /// CameraCharacteristics\#SENSOR_INFO_PRE_CORRECTION_ACTIVE_ARRAY_SIZE android.sensor.info.preCorrectionActiveArraySize.height - 1) being the bottom-right
  /// pixel in the pre-correction active pixel array.
  /// When the distortion correction mode is not OFF, the coordinate system follows
  /// CameraCharacteristics\#SENSOR_INFO_ACTIVE_ARRAY_SIZE android.sensor.info.activeArraySize, with
  /// <code>(0, 0)</code> being the top-left pixel of the active array, and
  /// (CameraCharacteristics\#SENSOR_INFO_ACTIVE_ARRAY_SIZE android.sensor.info.activeArraySize.width - 1,
  /// CameraCharacteristics\#SENSOR_INFO_ACTIVE_ARRAY_SIZE android.sensor.info.activeArraySize.height - 1) being the bottom-right pixel in the
  /// active pixel array.
  ///
  /// The weight must be within <code>[0, 1000]</code>, and represents a weight
  /// for every pixel in the area. This means that a large metering area
  /// with the same weight as a smaller area will have more effect in
  /// the metering result. Metering areas can partially overlap and the
  /// camera device will add the weights in the overlap region.
  ///
  /// The weights are relative to weights of other exposure metering regions, so if only one
  /// region is used, all non-zero weights will have the same effect. A region with 0
  /// weight is ignored.
  ///
  /// If all regions have 0 weight, then no specific metering area needs to be used by the
  /// camera device.
  ///
  /// If the metering region is outside the used CaptureRequest\#SCALER_CROP_REGION android.scaler.cropRegion returned in
  /// capture result metadata, the camera device will ignore the sections outside the crop
  /// region and output only the intersection rectangle as the metering region in the result
  /// metadata.  If the region is entirely outside the crop region, it will be ignored and
  /// not reported in the result metadata.
  ///
  /// __Units__: Pixel coordinates within CameraCharacteristics\#SENSOR_INFO_ACTIVE_ARRAY_SIZE android.sensor.info.activeArraySize or
  /// CameraCharacteristics\#SENSOR_INFO_PRE_CORRECTION_ACTIVE_ARRAY_SIZE android.sensor.info.preCorrectionActiveArraySize depending on
  /// distortion correction capability and mode
  ///
  /// __Range of valid values:__<br>
  /// Coordinates must be between <code>[(0,0), (width, height))</code> of
  /// CameraCharacteristics\#SENSOR_INFO_ACTIVE_ARRAY_SIZE android.sensor.info.activeArraySize or CameraCharacteristics\#SENSOR_INFO_PRE_CORRECTION_ACTIVE_ARRAY_SIZE android.sensor.info.preCorrectionActiveArraySize
  /// depending on distortion correction capability and mode
  ///
  /// __Optional__ - This value may be {@code null} on some devices.
  ///
  ///@see CameraCharacteristics\#CONTROL_MAX_REGIONS_AE
  ///@see CaptureRequest\#DISTORTION_CORRECTION_MODE
  ///@see CaptureRequest\#SCALER_CROP_REGION
  ///@see CameraCharacteristics\#SENSOR_INFO_ACTIVE_ARRAY_SIZE
  ///@see CameraCharacteristics\#SENSOR_INFO_PRE_CORRECTION_ACTIVE_ARRAY_SIZE
  static CaptureResult_Key get CONTROL_AE_REGIONS =>
      CaptureResult_Key.fromRef(jniAccessors
          .getStaticField(
              _classRef, _id_CONTROL_AE_REGIONS, jni.JniType.objectType)
          .object);

  static final _id_CONTROL_AE_STATE = jniAccessors.getStaticFieldIDOf(_classRef,
      "CONTROL_AE_STATE", "Landroid/hardware/camera2/CaptureResult\$Key;");

  /// from: static public final android.hardware.camera2.CaptureResult.Key<java.lang.Integer> CONTROL_AE_STATE
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// Current state of the auto-exposure (AE) algorithm.
  ///
  /// Switching between or enabling AE modes (CaptureRequest\#CONTROL_AE_MODE android.control.aeMode) always
  /// resets the AE state to INACTIVE. Similarly, switching between CaptureRequest\#CONTROL_MODE android.control.mode,
  /// or CaptureRequest\#CONTROL_SCENE_MODE android.control.sceneMode if <code>CaptureRequest\#CONTROL_MODE android.control.mode == USE_SCENE_MODE</code> resets all
  /// the algorithm states to INACTIVE.
  ///
  /// The camera device can do several state transitions between two results, if it is
  /// allowed by the state transition table. For example: INACTIVE may never actually be
  /// seen in a result.
  ///
  /// The state in the result is the state for this image (in sync with this image): if
  /// AE state becomes CONVERGED, then the image data associated with this result should
  /// be good to use.
  ///
  /// Below are state transition tables for different AE modes.
  ///
  /// <table>
  /// <thead>
  /// <tr>
  /// <th align="center">State</th>
  /// <th align="center">Transition Cause</th>
  /// <th align="center">New State</th>
  /// <th align="center">Notes</th>
  /// </tr>
  /// </thead>
  /// <tbody>
  /// <tr>
  /// <td align="center">INACTIVE</td>
  /// <td align="center"></td>
  /// <td align="center">INACTIVE</td>
  /// <td align="center">Camera device auto exposure algorithm is disabled</td>
  /// </tr>
  /// </tbody>
  /// </table>
  /// When CaptureRequest\#CONTROL_AE_MODE android.control.aeMode is AE_MODE_ON*:
  ///
  /// <table>
  /// <thead>
  /// <tr>
  /// <th align="center">State</th>
  /// <th align="center">Transition Cause</th>
  /// <th align="center">New State</th>
  /// <th align="center">Notes</th>
  /// </tr>
  /// </thead>
  /// <tbody>
  /// <tr>
  /// <td align="center">INACTIVE</td>
  /// <td align="center">Camera device initiates AE scan</td>
  /// <td align="center">SEARCHING</td>
  /// <td align="center">Values changing</td>
  /// </tr>
  /// <tr>
  /// <td align="center">INACTIVE</td>
  /// <td align="center">CaptureRequest\#CONTROL_AE_LOCK android.control.aeLock is ON</td>
  /// <td align="center">LOCKED</td>
  /// <td align="center">Values locked</td>
  /// </tr>
  /// <tr>
  /// <td align="center">SEARCHING</td>
  /// <td align="center">Camera device finishes AE scan</td>
  /// <td align="center">CONVERGED</td>
  /// <td align="center">Good values, not changing</td>
  /// </tr>
  /// <tr>
  /// <td align="center">SEARCHING</td>
  /// <td align="center">Camera device finishes AE scan</td>
  /// <td align="center">FLASH_REQUIRED</td>
  /// <td align="center">Converged but too dark w/o flash</td>
  /// </tr>
  /// <tr>
  /// <td align="center">SEARCHING</td>
  /// <td align="center">CaptureRequest\#CONTROL_AE_LOCK android.control.aeLock is ON</td>
  /// <td align="center">LOCKED</td>
  /// <td align="center">Values locked</td>
  /// </tr>
  /// <tr>
  /// <td align="center">CONVERGED</td>
  /// <td align="center">Camera device initiates AE scan</td>
  /// <td align="center">SEARCHING</td>
  /// <td align="center">Values changing</td>
  /// </tr>
  /// <tr>
  /// <td align="center">CONVERGED</td>
  /// <td align="center">CaptureRequest\#CONTROL_AE_LOCK android.control.aeLock is ON</td>
  /// <td align="center">LOCKED</td>
  /// <td align="center">Values locked</td>
  /// </tr>
  /// <tr>
  /// <td align="center">FLASH_REQUIRED</td>
  /// <td align="center">Camera device initiates AE scan</td>
  /// <td align="center">SEARCHING</td>
  /// <td align="center">Values changing</td>
  /// </tr>
  /// <tr>
  /// <td align="center">FLASH_REQUIRED</td>
  /// <td align="center">CaptureRequest\#CONTROL_AE_LOCK android.control.aeLock is ON</td>
  /// <td align="center">LOCKED</td>
  /// <td align="center">Values locked</td>
  /// </tr>
  /// <tr>
  /// <td align="center">LOCKED</td>
  /// <td align="center">CaptureRequest\#CONTROL_AE_LOCK android.control.aeLock is OFF</td>
  /// <td align="center">SEARCHING</td>
  /// <td align="center">Values not good after unlock</td>
  /// </tr>
  /// <tr>
  /// <td align="center">LOCKED</td>
  /// <td align="center">CaptureRequest\#CONTROL_AE_LOCK android.control.aeLock is OFF</td>
  /// <td align="center">CONVERGED</td>
  /// <td align="center">Values good after unlock</td>
  /// </tr>
  /// <tr>
  /// <td align="center">LOCKED</td>
  /// <td align="center">CaptureRequest\#CONTROL_AE_LOCK android.control.aeLock is OFF</td>
  /// <td align="center">FLASH_REQUIRED</td>
  /// <td align="center">Exposure good, but too dark</td>
  /// </tr>
  /// <tr>
  /// <td align="center">PRECAPTURE</td>
  /// <td align="center">Sequence done. CaptureRequest\#CONTROL_AE_LOCK android.control.aeLock is OFF</td>
  /// <td align="center">CONVERGED</td>
  /// <td align="center">Ready for high-quality capture</td>
  /// </tr>
  /// <tr>
  /// <td align="center">PRECAPTURE</td>
  /// <td align="center">Sequence done. CaptureRequest\#CONTROL_AE_LOCK android.control.aeLock is ON</td>
  /// <td align="center">LOCKED</td>
  /// <td align="center">Ready for high-quality capture</td>
  /// </tr>
  /// <tr>
  /// <td align="center">LOCKED</td>
  /// <td align="center">aeLock is ON and aePrecaptureTrigger is START</td>
  /// <td align="center">LOCKED</td>
  /// <td align="center">Precapture trigger is ignored when AE is already locked</td>
  /// </tr>
  /// <tr>
  /// <td align="center">LOCKED</td>
  /// <td align="center">aeLock is ON and aePrecaptureTrigger is CANCEL</td>
  /// <td align="center">LOCKED</td>
  /// <td align="center">Precapture trigger is ignored when AE is already locked</td>
  /// </tr>
  /// <tr>
  /// <td align="center">Any state (excluding LOCKED)</td>
  /// <td align="center">CaptureRequest\#CONTROL_AE_PRECAPTURE_TRIGGER android.control.aePrecaptureTrigger is START</td>
  /// <td align="center">PRECAPTURE</td>
  /// <td align="center">Start AE precapture metering sequence</td>
  /// </tr>
  /// <tr>
  /// <td align="center">Any state (excluding LOCKED)</td>
  /// <td align="center">CaptureRequest\#CONTROL_AE_PRECAPTURE_TRIGGER android.control.aePrecaptureTrigger is CANCEL</td>
  /// <td align="center">INACTIVE</td>
  /// <td align="center">Currently active precapture metering sequence is canceled</td>
  /// </tr>
  /// </tbody>
  /// </table>
  /// If the camera device supports AE external flash mode (ON_EXTERNAL_FLASH is included in
  /// CameraCharacteristics\#CONTROL_AE_AVAILABLE_MODES android.control.aeAvailableModes), CaptureResult\#CONTROL_AE_STATE android.control.aeState must be FLASH_REQUIRED after
  /// the camera device finishes AE scan and it's too dark without flash.
  ///
  /// For the above table, the camera device may skip reporting any state changes that happen
  /// without application intervention (i.e. mode switch, trigger, locking). Any state that
  /// can be skipped in that manner is called a transient state.
  ///
  /// For example, for above AE modes (AE_MODE_ON*), in addition to the state transitions
  /// listed in above table, it is also legal for the camera device to skip one or more
  /// transient states between two results. See below table for examples:
  ///
  /// <table>
  /// <thead>
  /// <tr>
  /// <th align="center">State</th>
  /// <th align="center">Transition Cause</th>
  /// <th align="center">New State</th>
  /// <th align="center">Notes</th>
  /// </tr>
  /// </thead>
  /// <tbody>
  /// <tr>
  /// <td align="center">INACTIVE</td>
  /// <td align="center">Camera device finished AE scan</td>
  /// <td align="center">CONVERGED</td>
  /// <td align="center">Values are already good, transient states are skipped by camera device.</td>
  /// </tr>
  /// <tr>
  /// <td align="center">Any state (excluding LOCKED)</td>
  /// <td align="center">CaptureRequest\#CONTROL_AE_PRECAPTURE_TRIGGER android.control.aePrecaptureTrigger is START, sequence done</td>
  /// <td align="center">FLASH_REQUIRED</td>
  /// <td align="center">Converged but too dark w/o flash after a precapture sequence, transient states are skipped by camera device.</td>
  /// </tr>
  /// <tr>
  /// <td align="center">Any state (excluding LOCKED)</td>
  /// <td align="center">CaptureRequest\#CONTROL_AE_PRECAPTURE_TRIGGER android.control.aePrecaptureTrigger is START, sequence done</td>
  /// <td align="center">CONVERGED</td>
  /// <td align="center">Converged after a precapture sequence, transient states are skipped by camera device.</td>
  /// </tr>
  /// <tr>
  /// <td align="center">Any state (excluding LOCKED)</td>
  /// <td align="center">CaptureRequest\#CONTROL_AE_PRECAPTURE_TRIGGER android.control.aePrecaptureTrigger is CANCEL, converged</td>
  /// <td align="center">FLASH_REQUIRED</td>
  /// <td align="center">Converged but too dark w/o flash after a precapture sequence is canceled, transient states are skipped by camera device.</td>
  /// </tr>
  /// <tr>
  /// <td align="center">Any state (excluding LOCKED)</td>
  /// <td align="center">CaptureRequest\#CONTROL_AE_PRECAPTURE_TRIGGER android.control.aePrecaptureTrigger is CANCEL, converged</td>
  /// <td align="center">CONVERGED</td>
  /// <td align="center">Converged after a precapture sequenceis canceled, transient states are skipped by camera device.</td>
  /// </tr>
  /// <tr>
  /// <td align="center">CONVERGED</td>
  /// <td align="center">Camera device finished AE scan</td>
  /// <td align="center">FLASH_REQUIRED</td>
  /// <td align="center">Converged but too dark w/o flash after a new scan, transient states are skipped by camera device.</td>
  /// </tr>
  /// <tr>
  /// <td align="center">FLASH_REQUIRED</td>
  /// <td align="center">Camera device finished AE scan</td>
  /// <td align="center">CONVERGED</td>
  /// <td align="center">Converged after a new scan, transient states are skipped by camera device.</td>
  /// </tr>
  /// </tbody>
  /// </table>
  /// __Possible values:__
  /// <ul>
  ///   <li>\#CONTROL_AE_STATE_INACTIVE INACTIVE</li>
  ///   <li>\#CONTROL_AE_STATE_SEARCHING SEARCHING</li>
  ///   <li>\#CONTROL_AE_STATE_CONVERGED CONVERGED</li>
  ///   <li>\#CONTROL_AE_STATE_LOCKED LOCKED</li>
  ///   <li>\#CONTROL_AE_STATE_FLASH_REQUIRED FLASH_REQUIRED</li>
  ///   <li>\#CONTROL_AE_STATE_PRECAPTURE PRECAPTURE</li>
  /// </ul>
  ///
  /// __Optional__ - This value may be {@code null} on some devices.
  ///
  /// __Limited capability__ -
  /// Present on all camera devices that report being at least CameraCharacteristics\#INFO_SUPPORTED_HARDWARE_LEVEL_LIMITED HARDWARE_LEVEL_LIMITED devices in the
  /// CameraCharacteristics\#INFO_SUPPORTED_HARDWARE_LEVEL android.info.supportedHardwareLevel key
  ///
  ///@see CameraCharacteristics\#CONTROL_AE_AVAILABLE_MODES
  ///@see CaptureRequest\#CONTROL_AE_LOCK
  ///@see CaptureRequest\#CONTROL_AE_MODE
  ///@see CaptureRequest\#CONTROL_AE_PRECAPTURE_TRIGGER
  ///@see CaptureResult\#CONTROL_AE_STATE
  ///@see CaptureRequest\#CONTROL_MODE
  ///@see CaptureRequest\#CONTROL_SCENE_MODE
  ///@see CameraCharacteristics\#INFO_SUPPORTED_HARDWARE_LEVEL
  ///@see \#CONTROL_AE_STATE_INACTIVE
  ///@see \#CONTROL_AE_STATE_SEARCHING
  ///@see \#CONTROL_AE_STATE_CONVERGED
  ///@see \#CONTROL_AE_STATE_LOCKED
  ///@see \#CONTROL_AE_STATE_FLASH_REQUIRED
  ///@see \#CONTROL_AE_STATE_PRECAPTURE
  static CaptureResult_Key get CONTROL_AE_STATE =>
      CaptureResult_Key.fromRef(jniAccessors
          .getStaticField(
              _classRef, _id_CONTROL_AE_STATE, jni.JniType.objectType)
          .object);

  static final _id_CONTROL_AE_TARGET_FPS_RANGE =
      jniAccessors.getStaticFieldIDOf(_classRef, "CONTROL_AE_TARGET_FPS_RANGE",
          "Landroid/hardware/camera2/CaptureResult\$Key;");

  /// from: static public final android.hardware.camera2.CaptureResult.Key<android.util.Range<java.lang.Integer>> CONTROL_AE_TARGET_FPS_RANGE
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// Range over which the auto-exposure routine can
  /// adjust the capture frame rate to maintain good
  /// exposure.
  ///
  /// Only constrains auto-exposure (AE) algorithm, not
  /// manual control of CaptureRequest\#SENSOR_EXPOSURE_TIME android.sensor.exposureTime and
  /// CaptureRequest\#SENSOR_FRAME_DURATION android.sensor.frameDuration.
  ///
  /// __Units__: Frames per second (FPS)
  ///
  /// __Range of valid values:__<br>
  /// Any of the entries in CameraCharacteristics\#CONTROL_AE_AVAILABLE_TARGET_FPS_RANGES android.control.aeAvailableTargetFpsRanges
  ///
  /// This key is available on all devices.
  ///
  ///@see CameraCharacteristics\#CONTROL_AE_AVAILABLE_TARGET_FPS_RANGES
  ///@see CaptureRequest\#SENSOR_EXPOSURE_TIME
  ///@see CaptureRequest\#SENSOR_FRAME_DURATION
  static CaptureResult_Key get CONTROL_AE_TARGET_FPS_RANGE =>
      CaptureResult_Key.fromRef(jniAccessors
          .getStaticField(_classRef, _id_CONTROL_AE_TARGET_FPS_RANGE,
              jni.JniType.objectType)
          .object);

  static final _id_CONTROL_AF_MODE = jniAccessors.getStaticFieldIDOf(_classRef,
      "CONTROL_AF_MODE", "Landroid/hardware/camera2/CaptureResult\$Key;");

  /// from: static public final android.hardware.camera2.CaptureResult.Key<java.lang.Integer> CONTROL_AF_MODE
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// Whether auto-focus (AF) is currently enabled, and what
  /// mode it is set to.
  ///
  /// Only effective if CaptureRequest\#CONTROL_MODE android.control.mode = AUTO and the lens is not fixed focus
  /// (i.e. <code>CameraCharacteristics\#LENS_INFO_MINIMUM_FOCUS_DISTANCE android.lens.info.minimumFocusDistance &gt; 0</code>). Also note that
  /// when CaptureRequest\#CONTROL_AE_MODE android.control.aeMode is OFF, the behavior of AF is device
  /// dependent. It is recommended to lock AF by using CaptureRequest\#CONTROL_AF_TRIGGER android.control.afTrigger before
  /// setting CaptureRequest\#CONTROL_AE_MODE android.control.aeMode to OFF, or set AF mode to OFF when AE is OFF.
  ///
  /// If the lens is controlled by the camera device auto-focus algorithm,
  /// the camera device will report the current AF status in CaptureResult\#CONTROL_AF_STATE android.control.afState
  /// in result metadata.
  ///
  /// __Possible values:__
  /// <ul>
  ///   <li>\#CONTROL_AF_MODE_OFF OFF</li>
  ///   <li>\#CONTROL_AF_MODE_AUTO AUTO</li>
  ///   <li>\#CONTROL_AF_MODE_MACRO MACRO</li>
  ///   <li>\#CONTROL_AF_MODE_CONTINUOUS_VIDEO CONTINUOUS_VIDEO</li>
  ///   <li>\#CONTROL_AF_MODE_CONTINUOUS_PICTURE CONTINUOUS_PICTURE</li>
  ///   <li>\#CONTROL_AF_MODE_EDOF EDOF</li>
  /// </ul>
  ///
  /// __Available values for this device:__<br>
  /// CameraCharacteristics\#CONTROL_AF_AVAILABLE_MODES android.control.afAvailableModes
  ///
  /// This key is available on all devices.
  ///
  ///@see CaptureRequest\#CONTROL_AE_MODE
  ///@see CameraCharacteristics\#CONTROL_AF_AVAILABLE_MODES
  ///@see CaptureResult\#CONTROL_AF_STATE
  ///@see CaptureRequest\#CONTROL_AF_TRIGGER
  ///@see CaptureRequest\#CONTROL_MODE
  ///@see CameraCharacteristics\#LENS_INFO_MINIMUM_FOCUS_DISTANCE
  ///@see \#CONTROL_AF_MODE_OFF
  ///@see \#CONTROL_AF_MODE_AUTO
  ///@see \#CONTROL_AF_MODE_MACRO
  ///@see \#CONTROL_AF_MODE_CONTINUOUS_VIDEO
  ///@see \#CONTROL_AF_MODE_CONTINUOUS_PICTURE
  ///@see \#CONTROL_AF_MODE_EDOF
  static CaptureResult_Key get CONTROL_AF_MODE =>
      CaptureResult_Key.fromRef(jniAccessors
          .getStaticField(
              _classRef, _id_CONTROL_AF_MODE, jni.JniType.objectType)
          .object);

  static final _id_CONTROL_AF_REGIONS = jniAccessors.getStaticFieldIDOf(
      _classRef,
      "CONTROL_AF_REGIONS",
      "Landroid/hardware/camera2/CaptureResult\$Key;");

  /// from: static public final android.hardware.camera2.CaptureResult.Key<android.hardware.camera2.params.MeteringRectangle[]> CONTROL_AF_REGIONS
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// List of metering areas to use for auto-focus.
  ///
  /// Not available if CameraCharacteristics\#CONTROL_MAX_REGIONS_AF android.control.maxRegionsAf is 0.
  /// Otherwise will always be present.
  ///
  /// The maximum number of focus areas supported by the device is determined by the value
  /// of CameraCharacteristics\#CONTROL_MAX_REGIONS_AF android.control.maxRegionsAf.
  ///
  /// For devices not supporting CaptureRequest\#DISTORTION_CORRECTION_MODE android.distortionCorrection.mode control, the coordinate
  /// system always follows that of CameraCharacteristics\#SENSOR_INFO_ACTIVE_ARRAY_SIZE android.sensor.info.activeArraySize, with (0,0) being
  /// the top-left pixel in the active pixel array, and
  /// (CameraCharacteristics\#SENSOR_INFO_ACTIVE_ARRAY_SIZE android.sensor.info.activeArraySize.width - 1,
  /// CameraCharacteristics\#SENSOR_INFO_ACTIVE_ARRAY_SIZE android.sensor.info.activeArraySize.height - 1) being the bottom-right pixel in the
  /// active pixel array.
  ///
  /// For devices supporting CaptureRequest\#DISTORTION_CORRECTION_MODE android.distortionCorrection.mode control, the coordinate
  /// system depends on the mode being set.
  /// When the distortion correction mode is OFF, the coordinate system follows
  /// CameraCharacteristics\#SENSOR_INFO_PRE_CORRECTION_ACTIVE_ARRAY_SIZE android.sensor.info.preCorrectionActiveArraySize, with
  /// <code>(0, 0)</code> being the top-left pixel of the pre-correction active array, and
  /// (CameraCharacteristics\#SENSOR_INFO_PRE_CORRECTION_ACTIVE_ARRAY_SIZE android.sensor.info.preCorrectionActiveArraySize.width - 1,
  /// CameraCharacteristics\#SENSOR_INFO_PRE_CORRECTION_ACTIVE_ARRAY_SIZE android.sensor.info.preCorrectionActiveArraySize.height - 1) being the bottom-right
  /// pixel in the pre-correction active pixel array.
  /// When the distortion correction mode is not OFF, the coordinate system follows
  /// CameraCharacteristics\#SENSOR_INFO_ACTIVE_ARRAY_SIZE android.sensor.info.activeArraySize, with
  /// <code>(0, 0)</code> being the top-left pixel of the active array, and
  /// (CameraCharacteristics\#SENSOR_INFO_ACTIVE_ARRAY_SIZE android.sensor.info.activeArraySize.width - 1,
  /// CameraCharacteristics\#SENSOR_INFO_ACTIVE_ARRAY_SIZE android.sensor.info.activeArraySize.height - 1) being the bottom-right pixel in the
  /// active pixel array.
  ///
  /// The weight must be within <code>[0, 1000]</code>, and represents a weight
  /// for every pixel in the area. This means that a large metering area
  /// with the same weight as a smaller area will have more effect in
  /// the metering result. Metering areas can partially overlap and the
  /// camera device will add the weights in the overlap region.
  ///
  /// The weights are relative to weights of other metering regions, so if only one region
  /// is used, all non-zero weights will have the same effect. A region with 0 weight is
  /// ignored.
  ///
  /// If all regions have 0 weight, then no specific metering area needs to be used by the
  /// camera device. The capture result will either be a zero weight region as well, or
  /// the region selected by the camera device as the focus area of interest.
  ///
  /// If the metering region is outside the used CaptureRequest\#SCALER_CROP_REGION android.scaler.cropRegion returned in
  /// capture result metadata, the camera device will ignore the sections outside the crop
  /// region and output only the intersection rectangle as the metering region in the result
  /// metadata. If the region is entirely outside the crop region, it will be ignored and
  /// not reported in the result metadata.
  ///
  /// __Units__: Pixel coordinates within CameraCharacteristics\#SENSOR_INFO_ACTIVE_ARRAY_SIZE android.sensor.info.activeArraySize or
  /// CameraCharacteristics\#SENSOR_INFO_PRE_CORRECTION_ACTIVE_ARRAY_SIZE android.sensor.info.preCorrectionActiveArraySize depending on
  /// distortion correction capability and mode
  ///
  /// __Range of valid values:__<br>
  /// Coordinates must be between <code>[(0,0), (width, height))</code> of
  /// CameraCharacteristics\#SENSOR_INFO_ACTIVE_ARRAY_SIZE android.sensor.info.activeArraySize or CameraCharacteristics\#SENSOR_INFO_PRE_CORRECTION_ACTIVE_ARRAY_SIZE android.sensor.info.preCorrectionActiveArraySize
  /// depending on distortion correction capability and mode
  ///
  /// __Optional__ - This value may be {@code null} on some devices.
  ///
  ///@see CameraCharacteristics\#CONTROL_MAX_REGIONS_AF
  ///@see CaptureRequest\#DISTORTION_CORRECTION_MODE
  ///@see CaptureRequest\#SCALER_CROP_REGION
  ///@see CameraCharacteristics\#SENSOR_INFO_ACTIVE_ARRAY_SIZE
  ///@see CameraCharacteristics\#SENSOR_INFO_PRE_CORRECTION_ACTIVE_ARRAY_SIZE
  static CaptureResult_Key get CONTROL_AF_REGIONS =>
      CaptureResult_Key.fromRef(jniAccessors
          .getStaticField(
              _classRef, _id_CONTROL_AF_REGIONS, jni.JniType.objectType)
          .object);

  static final _id_CONTROL_AF_SCENE_CHANGE = jniAccessors.getStaticFieldIDOf(
      _classRef,
      "CONTROL_AF_SCENE_CHANGE",
      "Landroid/hardware/camera2/CaptureResult\$Key;");

  /// from: static public final android.hardware.camera2.CaptureResult.Key<java.lang.Integer> CONTROL_AF_SCENE_CHANGE
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// Whether a significant scene change is detected within the currently-set AF
  /// region(s).
  ///
  /// When the camera focus routine detects a change in the scene it is looking at,
  /// such as a large shift in camera viewpoint, significant motion in the scene, or a
  /// significant illumination change, this value will be set to DETECTED for a single capture
  /// result. Otherwise the value will be NOT_DETECTED. The threshold for detection is similar
  /// to what would trigger a new passive focus scan to begin in CONTINUOUS autofocus modes.
  ///
  /// This key will be available if the camera device advertises this key via android.hardware.camera2.CameraCharacteristics\#getAvailableCaptureResultKeys.
  ///
  /// __Possible values:__
  /// <ul>
  ///   <li>\#CONTROL_AF_SCENE_CHANGE_NOT_DETECTED NOT_DETECTED</li>
  ///   <li>\#CONTROL_AF_SCENE_CHANGE_DETECTED DETECTED</li>
  /// </ul>
  ///
  /// __Optional__ - This value may be {@code null} on some devices.
  ///
  ///@see \#CONTROL_AF_SCENE_CHANGE_NOT_DETECTED
  ///@see \#CONTROL_AF_SCENE_CHANGE_DETECTED
  static CaptureResult_Key get CONTROL_AF_SCENE_CHANGE =>
      CaptureResult_Key.fromRef(jniAccessors
          .getStaticField(
              _classRef, _id_CONTROL_AF_SCENE_CHANGE, jni.JniType.objectType)
          .object);

  static final _id_CONTROL_AF_STATE = jniAccessors.getStaticFieldIDOf(_classRef,
      "CONTROL_AF_STATE", "Landroid/hardware/camera2/CaptureResult\$Key;");

  /// from: static public final android.hardware.camera2.CaptureResult.Key<java.lang.Integer> CONTROL_AF_STATE
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// Current state of auto-focus (AF) algorithm.
  ///
  /// Switching between or enabling AF modes (CaptureRequest\#CONTROL_AF_MODE android.control.afMode) always
  /// resets the AF state to INACTIVE. Similarly, switching between CaptureRequest\#CONTROL_MODE android.control.mode,
  /// or CaptureRequest\#CONTROL_SCENE_MODE android.control.sceneMode if <code>CaptureRequest\#CONTROL_MODE android.control.mode == USE_SCENE_MODE</code> resets all
  /// the algorithm states to INACTIVE.
  ///
  /// The camera device can do several state transitions between two results, if it is
  /// allowed by the state transition table. For example: INACTIVE may never actually be
  /// seen in a result.
  ///
  /// The state in the result is the state for this image (in sync with this image): if
  /// AF state becomes FOCUSED, then the image data associated with this result should
  /// be sharp.
  ///
  /// Below are state transition tables for different AF modes.
  ///
  /// When CaptureRequest\#CONTROL_AF_MODE android.control.afMode is AF_MODE_OFF or AF_MODE_EDOF:
  ///
  /// <table>
  /// <thead>
  /// <tr>
  /// <th align="center">State</th>
  /// <th align="center">Transition Cause</th>
  /// <th align="center">New State</th>
  /// <th align="center">Notes</th>
  /// </tr>
  /// </thead>
  /// <tbody>
  /// <tr>
  /// <td align="center">INACTIVE</td>
  /// <td align="center"></td>
  /// <td align="center">INACTIVE</td>
  /// <td align="center">Never changes</td>
  /// </tr>
  /// </tbody>
  /// </table>
  /// When CaptureRequest\#CONTROL_AF_MODE android.control.afMode is AF_MODE_AUTO or AF_MODE_MACRO:
  ///
  /// <table>
  /// <thead>
  /// <tr>
  /// <th align="center">State</th>
  /// <th align="center">Transition Cause</th>
  /// <th align="center">New State</th>
  /// <th align="center">Notes</th>
  /// </tr>
  /// </thead>
  /// <tbody>
  /// <tr>
  /// <td align="center">INACTIVE</td>
  /// <td align="center">AF_TRIGGER</td>
  /// <td align="center">ACTIVE_SCAN</td>
  /// <td align="center">Start AF sweep, Lens now moving</td>
  /// </tr>
  /// <tr>
  /// <td align="center">ACTIVE_SCAN</td>
  /// <td align="center">AF sweep done</td>
  /// <td align="center">FOCUSED_LOCKED</td>
  /// <td align="center">Focused, Lens now locked</td>
  /// </tr>
  /// <tr>
  /// <td align="center">ACTIVE_SCAN</td>
  /// <td align="center">AF sweep done</td>
  /// <td align="center">NOT_FOCUSED_LOCKED</td>
  /// <td align="center">Not focused, Lens now locked</td>
  /// </tr>
  /// <tr>
  /// <td align="center">ACTIVE_SCAN</td>
  /// <td align="center">AF_CANCEL</td>
  /// <td align="center">INACTIVE</td>
  /// <td align="center">Cancel/reset AF, Lens now locked</td>
  /// </tr>
  /// <tr>
  /// <td align="center">FOCUSED_LOCKED</td>
  /// <td align="center">AF_CANCEL</td>
  /// <td align="center">INACTIVE</td>
  /// <td align="center">Cancel/reset AF</td>
  /// </tr>
  /// <tr>
  /// <td align="center">FOCUSED_LOCKED</td>
  /// <td align="center">AF_TRIGGER</td>
  /// <td align="center">ACTIVE_SCAN</td>
  /// <td align="center">Start new sweep, Lens now moving</td>
  /// </tr>
  /// <tr>
  /// <td align="center">NOT_FOCUSED_LOCKED</td>
  /// <td align="center">AF_CANCEL</td>
  /// <td align="center">INACTIVE</td>
  /// <td align="center">Cancel/reset AF</td>
  /// </tr>
  /// <tr>
  /// <td align="center">NOT_FOCUSED_LOCKED</td>
  /// <td align="center">AF_TRIGGER</td>
  /// <td align="center">ACTIVE_SCAN</td>
  /// <td align="center">Start new sweep, Lens now moving</td>
  /// </tr>
  /// <tr>
  /// <td align="center">Any state</td>
  /// <td align="center">Mode change</td>
  /// <td align="center">INACTIVE</td>
  /// <td align="center"></td>
  /// </tr>
  /// </tbody>
  /// </table>
  /// For the above table, the camera device may skip reporting any state changes that happen
  /// without application intervention (i.e. mode switch, trigger, locking). Any state that
  /// can be skipped in that manner is called a transient state.
  ///
  /// For example, for these AF modes (AF_MODE_AUTO and AF_MODE_MACRO), in addition to the
  /// state transitions listed in above table, it is also legal for the camera device to skip
  /// one or more transient states between two results. See below table for examples:
  ///
  /// <table>
  /// <thead>
  /// <tr>
  /// <th align="center">State</th>
  /// <th align="center">Transition Cause</th>
  /// <th align="center">New State</th>
  /// <th align="center">Notes</th>
  /// </tr>
  /// </thead>
  /// <tbody>
  /// <tr>
  /// <td align="center">INACTIVE</td>
  /// <td align="center">AF_TRIGGER</td>
  /// <td align="center">FOCUSED_LOCKED</td>
  /// <td align="center">Focus is already good or good after a scan, lens is now locked.</td>
  /// </tr>
  /// <tr>
  /// <td align="center">INACTIVE</td>
  /// <td align="center">AF_TRIGGER</td>
  /// <td align="center">NOT_FOCUSED_LOCKED</td>
  /// <td align="center">Focus failed after a scan, lens is now locked.</td>
  /// </tr>
  /// <tr>
  /// <td align="center">FOCUSED_LOCKED</td>
  /// <td align="center">AF_TRIGGER</td>
  /// <td align="center">FOCUSED_LOCKED</td>
  /// <td align="center">Focus is already good or good after a scan, lens is now locked.</td>
  /// </tr>
  /// <tr>
  /// <td align="center">NOT_FOCUSED_LOCKED</td>
  /// <td align="center">AF_TRIGGER</td>
  /// <td align="center">FOCUSED_LOCKED</td>
  /// <td align="center">Focus is good after a scan, lens is not locked.</td>
  /// </tr>
  /// </tbody>
  /// </table>
  /// When CaptureRequest\#CONTROL_AF_MODE android.control.afMode is AF_MODE_CONTINUOUS_VIDEO:
  ///
  /// <table>
  /// <thead>
  /// <tr>
  /// <th align="center">State</th>
  /// <th align="center">Transition Cause</th>
  /// <th align="center">New State</th>
  /// <th align="center">Notes</th>
  /// </tr>
  /// </thead>
  /// <tbody>
  /// <tr>
  /// <td align="center">INACTIVE</td>
  /// <td align="center">Camera device initiates new scan</td>
  /// <td align="center">PASSIVE_SCAN</td>
  /// <td align="center">Start AF scan, Lens now moving</td>
  /// </tr>
  /// <tr>
  /// <td align="center">INACTIVE</td>
  /// <td align="center">AF_TRIGGER</td>
  /// <td align="center">NOT_FOCUSED_LOCKED</td>
  /// <td align="center">AF state query, Lens now locked</td>
  /// </tr>
  /// <tr>
  /// <td align="center">PASSIVE_SCAN</td>
  /// <td align="center">Camera device completes current scan</td>
  /// <td align="center">PASSIVE_FOCUSED</td>
  /// <td align="center">End AF scan, Lens now locked</td>
  /// </tr>
  /// <tr>
  /// <td align="center">PASSIVE_SCAN</td>
  /// <td align="center">Camera device fails current scan</td>
  /// <td align="center">PASSIVE_UNFOCUSED</td>
  /// <td align="center">End AF scan, Lens now locked</td>
  /// </tr>
  /// <tr>
  /// <td align="center">PASSIVE_SCAN</td>
  /// <td align="center">AF_TRIGGER</td>
  /// <td align="center">FOCUSED_LOCKED</td>
  /// <td align="center">Immediate transition, if focus is good. Lens now locked</td>
  /// </tr>
  /// <tr>
  /// <td align="center">PASSIVE_SCAN</td>
  /// <td align="center">AF_TRIGGER</td>
  /// <td align="center">NOT_FOCUSED_LOCKED</td>
  /// <td align="center">Immediate transition, if focus is bad. Lens now locked</td>
  /// </tr>
  /// <tr>
  /// <td align="center">PASSIVE_SCAN</td>
  /// <td align="center">AF_CANCEL</td>
  /// <td align="center">INACTIVE</td>
  /// <td align="center">Reset lens position, Lens now locked</td>
  /// </tr>
  /// <tr>
  /// <td align="center">PASSIVE_FOCUSED</td>
  /// <td align="center">Camera device initiates new scan</td>
  /// <td align="center">PASSIVE_SCAN</td>
  /// <td align="center">Start AF scan, Lens now moving</td>
  /// </tr>
  /// <tr>
  /// <td align="center">PASSIVE_UNFOCUSED</td>
  /// <td align="center">Camera device initiates new scan</td>
  /// <td align="center">PASSIVE_SCAN</td>
  /// <td align="center">Start AF scan, Lens now moving</td>
  /// </tr>
  /// <tr>
  /// <td align="center">PASSIVE_FOCUSED</td>
  /// <td align="center">AF_TRIGGER</td>
  /// <td align="center">FOCUSED_LOCKED</td>
  /// <td align="center">Immediate transition, lens now locked</td>
  /// </tr>
  /// <tr>
  /// <td align="center">PASSIVE_UNFOCUSED</td>
  /// <td align="center">AF_TRIGGER</td>
  /// <td align="center">NOT_FOCUSED_LOCKED</td>
  /// <td align="center">Immediate transition, lens now locked</td>
  /// </tr>
  /// <tr>
  /// <td align="center">FOCUSED_LOCKED</td>
  /// <td align="center">AF_TRIGGER</td>
  /// <td align="center">FOCUSED_LOCKED</td>
  /// <td align="center">No effect</td>
  /// </tr>
  /// <tr>
  /// <td align="center">FOCUSED_LOCKED</td>
  /// <td align="center">AF_CANCEL</td>
  /// <td align="center">INACTIVE</td>
  /// <td align="center">Restart AF scan</td>
  /// </tr>
  /// <tr>
  /// <td align="center">NOT_FOCUSED_LOCKED</td>
  /// <td align="center">AF_TRIGGER</td>
  /// <td align="center">NOT_FOCUSED_LOCKED</td>
  /// <td align="center">No effect</td>
  /// </tr>
  /// <tr>
  /// <td align="center">NOT_FOCUSED_LOCKED</td>
  /// <td align="center">AF_CANCEL</td>
  /// <td align="center">INACTIVE</td>
  /// <td align="center">Restart AF scan</td>
  /// </tr>
  /// </tbody>
  /// </table>
  /// When CaptureRequest\#CONTROL_AF_MODE android.control.afMode is AF_MODE_CONTINUOUS_PICTURE:
  ///
  /// <table>
  /// <thead>
  /// <tr>
  /// <th align="center">State</th>
  /// <th align="center">Transition Cause</th>
  /// <th align="center">New State</th>
  /// <th align="center">Notes</th>
  /// </tr>
  /// </thead>
  /// <tbody>
  /// <tr>
  /// <td align="center">INACTIVE</td>
  /// <td align="center">Camera device initiates new scan</td>
  /// <td align="center">PASSIVE_SCAN</td>
  /// <td align="center">Start AF scan, Lens now moving</td>
  /// </tr>
  /// <tr>
  /// <td align="center">INACTIVE</td>
  /// <td align="center">AF_TRIGGER</td>
  /// <td align="center">NOT_FOCUSED_LOCKED</td>
  /// <td align="center">AF state query, Lens now locked</td>
  /// </tr>
  /// <tr>
  /// <td align="center">PASSIVE_SCAN</td>
  /// <td align="center">Camera device completes current scan</td>
  /// <td align="center">PASSIVE_FOCUSED</td>
  /// <td align="center">End AF scan, Lens now locked</td>
  /// </tr>
  /// <tr>
  /// <td align="center">PASSIVE_SCAN</td>
  /// <td align="center">Camera device fails current scan</td>
  /// <td align="center">PASSIVE_UNFOCUSED</td>
  /// <td align="center">End AF scan, Lens now locked</td>
  /// </tr>
  /// <tr>
  /// <td align="center">PASSIVE_SCAN</td>
  /// <td align="center">AF_TRIGGER</td>
  /// <td align="center">FOCUSED_LOCKED</td>
  /// <td align="center">Eventual transition once the focus is good. Lens now locked</td>
  /// </tr>
  /// <tr>
  /// <td align="center">PASSIVE_SCAN</td>
  /// <td align="center">AF_TRIGGER</td>
  /// <td align="center">NOT_FOCUSED_LOCKED</td>
  /// <td align="center">Eventual transition if cannot find focus. Lens now locked</td>
  /// </tr>
  /// <tr>
  /// <td align="center">PASSIVE_SCAN</td>
  /// <td align="center">AF_CANCEL</td>
  /// <td align="center">INACTIVE</td>
  /// <td align="center">Reset lens position, Lens now locked</td>
  /// </tr>
  /// <tr>
  /// <td align="center">PASSIVE_FOCUSED</td>
  /// <td align="center">Camera device initiates new scan</td>
  /// <td align="center">PASSIVE_SCAN</td>
  /// <td align="center">Start AF scan, Lens now moving</td>
  /// </tr>
  /// <tr>
  /// <td align="center">PASSIVE_UNFOCUSED</td>
  /// <td align="center">Camera device initiates new scan</td>
  /// <td align="center">PASSIVE_SCAN</td>
  /// <td align="center">Start AF scan, Lens now moving</td>
  /// </tr>
  /// <tr>
  /// <td align="center">PASSIVE_FOCUSED</td>
  /// <td align="center">AF_TRIGGER</td>
  /// <td align="center">FOCUSED_LOCKED</td>
  /// <td align="center">Immediate trans. Lens now locked</td>
  /// </tr>
  /// <tr>
  /// <td align="center">PASSIVE_UNFOCUSED</td>
  /// <td align="center">AF_TRIGGER</td>
  /// <td align="center">NOT_FOCUSED_LOCKED</td>
  /// <td align="center">Immediate trans. Lens now locked</td>
  /// </tr>
  /// <tr>
  /// <td align="center">FOCUSED_LOCKED</td>
  /// <td align="center">AF_TRIGGER</td>
  /// <td align="center">FOCUSED_LOCKED</td>
  /// <td align="center">No effect</td>
  /// </tr>
  /// <tr>
  /// <td align="center">FOCUSED_LOCKED</td>
  /// <td align="center">AF_CANCEL</td>
  /// <td align="center">INACTIVE</td>
  /// <td align="center">Restart AF scan</td>
  /// </tr>
  /// <tr>
  /// <td align="center">NOT_FOCUSED_LOCKED</td>
  /// <td align="center">AF_TRIGGER</td>
  /// <td align="center">NOT_FOCUSED_LOCKED</td>
  /// <td align="center">No effect</td>
  /// </tr>
  /// <tr>
  /// <td align="center">NOT_FOCUSED_LOCKED</td>
  /// <td align="center">AF_CANCEL</td>
  /// <td align="center">INACTIVE</td>
  /// <td align="center">Restart AF scan</td>
  /// </tr>
  /// </tbody>
  /// </table>
  /// When switch between AF_MODE_CONTINUOUS_* (CAF modes) and AF_MODE_AUTO/AF_MODE_MACRO
  /// (AUTO modes), the initial INACTIVE or PASSIVE_SCAN states may be skipped by the
  /// camera device. When a trigger is included in a mode switch request, the trigger
  /// will be evaluated in the context of the new mode in the request.
  /// See below table for examples:
  ///
  /// <table>
  /// <thead>
  /// <tr>
  /// <th align="center">State</th>
  /// <th align="center">Transition Cause</th>
  /// <th align="center">New State</th>
  /// <th align="center">Notes</th>
  /// </tr>
  /// </thead>
  /// <tbody>
  /// <tr>
  /// <td align="center">any state</td>
  /// <td align="center">CAF--&gt;AUTO mode switch</td>
  /// <td align="center">INACTIVE</td>
  /// <td align="center">Mode switch without trigger, initial state must be INACTIVE</td>
  /// </tr>
  /// <tr>
  /// <td align="center">any state</td>
  /// <td align="center">CAF--&gt;AUTO mode switch with AF_TRIGGER</td>
  /// <td align="center">trigger-reachable states from INACTIVE</td>
  /// <td align="center">Mode switch with trigger, INACTIVE is skipped</td>
  /// </tr>
  /// <tr>
  /// <td align="center">any state</td>
  /// <td align="center">AUTO--&gt;CAF mode switch</td>
  /// <td align="center">passively reachable states from INACTIVE</td>
  /// <td align="center">Mode switch without trigger, passive transient state is skipped</td>
  /// </tr>
  /// </tbody>
  /// </table>
  /// __Possible values:__
  /// <ul>
  ///   <li>\#CONTROL_AF_STATE_INACTIVE INACTIVE</li>
  ///   <li>\#CONTROL_AF_STATE_PASSIVE_SCAN PASSIVE_SCAN</li>
  ///   <li>\#CONTROL_AF_STATE_PASSIVE_FOCUSED PASSIVE_FOCUSED</li>
  ///   <li>\#CONTROL_AF_STATE_ACTIVE_SCAN ACTIVE_SCAN</li>
  ///   <li>\#CONTROL_AF_STATE_FOCUSED_LOCKED FOCUSED_LOCKED</li>
  ///   <li>\#CONTROL_AF_STATE_NOT_FOCUSED_LOCKED NOT_FOCUSED_LOCKED</li>
  ///   <li>\#CONTROL_AF_STATE_PASSIVE_UNFOCUSED PASSIVE_UNFOCUSED</li>
  /// </ul>
  ///
  /// This key is available on all devices.
  ///
  ///@see CaptureRequest\#CONTROL_AF_MODE
  ///@see CaptureRequest\#CONTROL_MODE
  ///@see CaptureRequest\#CONTROL_SCENE_MODE
  ///@see \#CONTROL_AF_STATE_INACTIVE
  ///@see \#CONTROL_AF_STATE_PASSIVE_SCAN
  ///@see \#CONTROL_AF_STATE_PASSIVE_FOCUSED
  ///@see \#CONTROL_AF_STATE_ACTIVE_SCAN
  ///@see \#CONTROL_AF_STATE_FOCUSED_LOCKED
  ///@see \#CONTROL_AF_STATE_NOT_FOCUSED_LOCKED
  ///@see \#CONTROL_AF_STATE_PASSIVE_UNFOCUSED
  static CaptureResult_Key get CONTROL_AF_STATE =>
      CaptureResult_Key.fromRef(jniAccessors
          .getStaticField(
              _classRef, _id_CONTROL_AF_STATE, jni.JniType.objectType)
          .object);

  static final _id_CONTROL_AF_TRIGGER = jniAccessors.getStaticFieldIDOf(
      _classRef,
      "CONTROL_AF_TRIGGER",
      "Landroid/hardware/camera2/CaptureResult\$Key;");

  /// from: static public final android.hardware.camera2.CaptureResult.Key<java.lang.Integer> CONTROL_AF_TRIGGER
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// Whether the camera device will trigger autofocus for this request.
  ///
  /// This entry is normally set to IDLE, or is not
  /// included at all in the request settings.
  ///
  /// When included and set to START, the camera device will trigger the
  /// autofocus algorithm. If autofocus is disabled, this trigger has no effect.
  ///
  /// When set to CANCEL, the camera device will cancel any active trigger,
  /// and return to its initial AF state.
  ///
  /// Generally, applications should set this entry to START or CANCEL for only a
  /// single capture, and then return it to IDLE (or not set at all). Specifying
  /// START for multiple captures in a row means restarting the AF operation over
  /// and over again.
  ///
  /// See CaptureResult\#CONTROL_AF_STATE android.control.afState for what the trigger means for each AF mode.
  ///
  /// Using the autofocus trigger and the precapture trigger CaptureRequest\#CONTROL_AE_PRECAPTURE_TRIGGER android.control.aePrecaptureTrigger
  /// simultaneously is allowed. However, since these triggers often require cooperation between
  /// the auto-focus and auto-exposure routines (for example, the may need to be enabled for a
  /// focus sweep), the camera device may delay acting on a later trigger until the previous
  /// trigger has been fully handled. This may lead to longer intervals between the trigger and
  /// changes to CaptureResult\#CONTROL_AF_STATE android.control.afState, for example.
  ///
  /// __Possible values:__
  /// <ul>
  ///   <li>\#CONTROL_AF_TRIGGER_IDLE IDLE</li>
  ///   <li>\#CONTROL_AF_TRIGGER_START START</li>
  ///   <li>\#CONTROL_AF_TRIGGER_CANCEL CANCEL</li>
  /// </ul>
  ///
  /// This key is available on all devices.
  ///
  ///@see CaptureRequest\#CONTROL_AE_PRECAPTURE_TRIGGER
  ///@see CaptureResult\#CONTROL_AF_STATE
  ///@see \#CONTROL_AF_TRIGGER_IDLE
  ///@see \#CONTROL_AF_TRIGGER_START
  ///@see \#CONTROL_AF_TRIGGER_CANCEL
  static CaptureResult_Key get CONTROL_AF_TRIGGER =>
      CaptureResult_Key.fromRef(jniAccessors
          .getStaticField(
              _classRef, _id_CONTROL_AF_TRIGGER, jni.JniType.objectType)
          .object);

  static final _id_CONTROL_AWB_LOCK = jniAccessors.getStaticFieldIDOf(_classRef,
      "CONTROL_AWB_LOCK", "Landroid/hardware/camera2/CaptureResult\$Key;");

  /// from: static public final android.hardware.camera2.CaptureResult.Key<java.lang.Boolean> CONTROL_AWB_LOCK
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// Whether auto-white balance (AWB) is currently locked to its
  /// latest calculated values.
  ///
  /// When set to <code>true</code> (ON), the AWB algorithm is locked to its latest parameters,
  /// and will not change color balance settings until the lock is set to <code>false</code> (OFF).
  ///
  /// Since the camera device has a pipeline of in-flight requests, the settings that
  /// get locked do not necessarily correspond to the settings that were present in the
  /// latest capture result received from the camera device, since additional captures
  /// and AWB updates may have occurred even before the result was sent out. If an
  /// application is switching between automatic and manual control and wishes to eliminate
  /// any flicker during the switch, the following procedure is recommended:
  ///
  /// <ol>
  /// <li>Starting in auto-AWB mode:</li>
  /// <li>Lock AWB</li>
  /// <li>Wait for the first result to be output that has the AWB locked</li>
  /// <li>Copy AWB settings from that result into a request, set the request to manual AWB</li>
  /// <li>Submit the capture request, proceed to run manual AWB as desired.</li>
  /// </ol>
  /// Note that AWB lock is only meaningful when
  /// CaptureRequest\#CONTROL_AWB_MODE android.control.awbMode is in the AUTO mode; in other modes,
  /// AWB is already fixed to a specific setting.
  ///
  /// Some LEGACY devices may not support ON; the value is then overridden to OFF.
  ///
  /// This key is available on all devices.
  ///
  ///@see CaptureRequest\#CONTROL_AWB_MODE
  static CaptureResult_Key get CONTROL_AWB_LOCK =>
      CaptureResult_Key.fromRef(jniAccessors
          .getStaticField(
              _classRef, _id_CONTROL_AWB_LOCK, jni.JniType.objectType)
          .object);

  static final _id_CONTROL_AWB_MODE = jniAccessors.getStaticFieldIDOf(_classRef,
      "CONTROL_AWB_MODE", "Landroid/hardware/camera2/CaptureResult\$Key;");

  /// from: static public final android.hardware.camera2.CaptureResult.Key<java.lang.Integer> CONTROL_AWB_MODE
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// Whether auto-white balance (AWB) is currently setting the color
  /// transform fields, and what its illumination target
  /// is.
  ///
  /// This control is only effective if CaptureRequest\#CONTROL_MODE android.control.mode is AUTO.
  ///
  /// When set to the ON mode, the camera device's auto-white balance
  /// routine is enabled, overriding the application's selected
  /// CaptureRequest\#COLOR_CORRECTION_TRANSFORM android.colorCorrection.transform, CaptureRequest\#COLOR_CORRECTION_GAINS android.colorCorrection.gains and
  /// CaptureRequest\#COLOR_CORRECTION_MODE android.colorCorrection.mode. Note that when CaptureRequest\#CONTROL_AE_MODE android.control.aeMode
  /// is OFF, the behavior of AWB is device dependent. It is recommened to
  /// also set AWB mode to OFF or lock AWB by using CaptureRequest\#CONTROL_AWB_LOCK android.control.awbLock before
  /// setting AE mode to OFF.
  ///
  /// When set to the OFF mode, the camera device's auto-white balance
  /// routine is disabled. The application manually controls the white
  /// balance by CaptureRequest\#COLOR_CORRECTION_TRANSFORM android.colorCorrection.transform, CaptureRequest\#COLOR_CORRECTION_GAINS android.colorCorrection.gains
  /// and CaptureRequest\#COLOR_CORRECTION_MODE android.colorCorrection.mode.
  ///
  /// When set to any other modes, the camera device's auto-white
  /// balance routine is disabled. The camera device uses each
  /// particular illumination target for white balance
  /// adjustment. The application's values for
  /// CaptureRequest\#COLOR_CORRECTION_TRANSFORM android.colorCorrection.transform,
  /// CaptureRequest\#COLOR_CORRECTION_GAINS android.colorCorrection.gains and
  /// CaptureRequest\#COLOR_CORRECTION_MODE android.colorCorrection.mode are ignored.
  ///
  /// __Possible values:__
  /// <ul>
  ///   <li>\#CONTROL_AWB_MODE_OFF OFF</li>
  ///   <li>\#CONTROL_AWB_MODE_AUTO AUTO</li>
  ///   <li>\#CONTROL_AWB_MODE_INCANDESCENT INCANDESCENT</li>
  ///   <li>\#CONTROL_AWB_MODE_FLUORESCENT FLUORESCENT</li>
  ///   <li>\#CONTROL_AWB_MODE_WARM_FLUORESCENT WARM_FLUORESCENT</li>
  ///   <li>\#CONTROL_AWB_MODE_DAYLIGHT DAYLIGHT</li>
  ///   <li>\#CONTROL_AWB_MODE_CLOUDY_DAYLIGHT CLOUDY_DAYLIGHT</li>
  ///   <li>\#CONTROL_AWB_MODE_TWILIGHT TWILIGHT</li>
  ///   <li>\#CONTROL_AWB_MODE_SHADE SHADE</li>
  /// </ul>
  ///
  /// __Available values for this device:__<br>
  /// CameraCharacteristics\#CONTROL_AWB_AVAILABLE_MODES android.control.awbAvailableModes
  ///
  /// This key is available on all devices.
  ///
  ///@see CaptureRequest\#COLOR_CORRECTION_GAINS
  ///@see CaptureRequest\#COLOR_CORRECTION_MODE
  ///@see CaptureRequest\#COLOR_CORRECTION_TRANSFORM
  ///@see CaptureRequest\#CONTROL_AE_MODE
  ///@see CameraCharacteristics\#CONTROL_AWB_AVAILABLE_MODES
  ///@see CaptureRequest\#CONTROL_AWB_LOCK
  ///@see CaptureRequest\#CONTROL_MODE
  ///@see \#CONTROL_AWB_MODE_OFF
  ///@see \#CONTROL_AWB_MODE_AUTO
  ///@see \#CONTROL_AWB_MODE_INCANDESCENT
  ///@see \#CONTROL_AWB_MODE_FLUORESCENT
  ///@see \#CONTROL_AWB_MODE_WARM_FLUORESCENT
  ///@see \#CONTROL_AWB_MODE_DAYLIGHT
  ///@see \#CONTROL_AWB_MODE_CLOUDY_DAYLIGHT
  ///@see \#CONTROL_AWB_MODE_TWILIGHT
  ///@see \#CONTROL_AWB_MODE_SHADE
  static CaptureResult_Key get CONTROL_AWB_MODE =>
      CaptureResult_Key.fromRef(jniAccessors
          .getStaticField(
              _classRef, _id_CONTROL_AWB_MODE, jni.JniType.objectType)
          .object);

  static final _id_CONTROL_AWB_REGIONS = jniAccessors.getStaticFieldIDOf(
      _classRef,
      "CONTROL_AWB_REGIONS",
      "Landroid/hardware/camera2/CaptureResult\$Key;");

  /// from: static public final android.hardware.camera2.CaptureResult.Key<android.hardware.camera2.params.MeteringRectangle[]> CONTROL_AWB_REGIONS
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// List of metering areas to use for auto-white-balance illuminant
  /// estimation.
  ///
  /// Not available if CameraCharacteristics\#CONTROL_MAX_REGIONS_AWB android.control.maxRegionsAwb is 0.
  /// Otherwise will always be present.
  ///
  /// The maximum number of regions supported by the device is determined by the value
  /// of CameraCharacteristics\#CONTROL_MAX_REGIONS_AWB android.control.maxRegionsAwb.
  ///
  /// For devices not supporting CaptureRequest\#DISTORTION_CORRECTION_MODE android.distortionCorrection.mode control, the coordinate
  /// system always follows that of CameraCharacteristics\#SENSOR_INFO_ACTIVE_ARRAY_SIZE android.sensor.info.activeArraySize, with (0,0) being
  /// the top-left pixel in the active pixel array, and
  /// (CameraCharacteristics\#SENSOR_INFO_ACTIVE_ARRAY_SIZE android.sensor.info.activeArraySize.width - 1,
  /// CameraCharacteristics\#SENSOR_INFO_ACTIVE_ARRAY_SIZE android.sensor.info.activeArraySize.height - 1) being the bottom-right pixel in the
  /// active pixel array.
  ///
  /// For devices supporting CaptureRequest\#DISTORTION_CORRECTION_MODE android.distortionCorrection.mode control, the coordinate
  /// system depends on the mode being set.
  /// When the distortion correction mode is OFF, the coordinate system follows
  /// CameraCharacteristics\#SENSOR_INFO_PRE_CORRECTION_ACTIVE_ARRAY_SIZE android.sensor.info.preCorrectionActiveArraySize, with
  /// <code>(0, 0)</code> being the top-left pixel of the pre-correction active array, and
  /// (CameraCharacteristics\#SENSOR_INFO_PRE_CORRECTION_ACTIVE_ARRAY_SIZE android.sensor.info.preCorrectionActiveArraySize.width - 1,
  /// CameraCharacteristics\#SENSOR_INFO_PRE_CORRECTION_ACTIVE_ARRAY_SIZE android.sensor.info.preCorrectionActiveArraySize.height - 1) being the bottom-right
  /// pixel in the pre-correction active pixel array.
  /// When the distortion correction mode is not OFF, the coordinate system follows
  /// CameraCharacteristics\#SENSOR_INFO_ACTIVE_ARRAY_SIZE android.sensor.info.activeArraySize, with
  /// <code>(0, 0)</code> being the top-left pixel of the active array, and
  /// (CameraCharacteristics\#SENSOR_INFO_ACTIVE_ARRAY_SIZE android.sensor.info.activeArraySize.width - 1,
  /// CameraCharacteristics\#SENSOR_INFO_ACTIVE_ARRAY_SIZE android.sensor.info.activeArraySize.height - 1) being the bottom-right pixel in the
  /// active pixel array.
  ///
  /// The weight must range from 0 to 1000, and represents a weight
  /// for every pixel in the area. This means that a large metering area
  /// with the same weight as a smaller area will have more effect in
  /// the metering result. Metering areas can partially overlap and the
  /// camera device will add the weights in the overlap region.
  ///
  /// The weights are relative to weights of other white balance metering regions, so if
  /// only one region is used, all non-zero weights will have the same effect. A region with
  /// 0 weight is ignored.
  ///
  /// If all regions have 0 weight, then no specific metering area needs to be used by the
  /// camera device.
  ///
  /// If the metering region is outside the used CaptureRequest\#SCALER_CROP_REGION android.scaler.cropRegion returned in
  /// capture result metadata, the camera device will ignore the sections outside the crop
  /// region and output only the intersection rectangle as the metering region in the result
  /// metadata.  If the region is entirely outside the crop region, it will be ignored and
  /// not reported in the result metadata.
  ///
  /// __Units__: Pixel coordinates within CameraCharacteristics\#SENSOR_INFO_ACTIVE_ARRAY_SIZE android.sensor.info.activeArraySize or
  /// CameraCharacteristics\#SENSOR_INFO_PRE_CORRECTION_ACTIVE_ARRAY_SIZE android.sensor.info.preCorrectionActiveArraySize depending on
  /// distortion correction capability and mode
  ///
  /// __Range of valid values:__<br>
  /// Coordinates must be between <code>[(0,0), (width, height))</code> of
  /// CameraCharacteristics\#SENSOR_INFO_ACTIVE_ARRAY_SIZE android.sensor.info.activeArraySize or CameraCharacteristics\#SENSOR_INFO_PRE_CORRECTION_ACTIVE_ARRAY_SIZE android.sensor.info.preCorrectionActiveArraySize
  /// depending on distortion correction capability and mode
  ///
  /// __Optional__ - This value may be {@code null} on some devices.
  ///
  ///@see CameraCharacteristics\#CONTROL_MAX_REGIONS_AWB
  ///@see CaptureRequest\#DISTORTION_CORRECTION_MODE
  ///@see CaptureRequest\#SCALER_CROP_REGION
  ///@see CameraCharacteristics\#SENSOR_INFO_ACTIVE_ARRAY_SIZE
  ///@see CameraCharacteristics\#SENSOR_INFO_PRE_CORRECTION_ACTIVE_ARRAY_SIZE
  static CaptureResult_Key get CONTROL_AWB_REGIONS =>
      CaptureResult_Key.fromRef(jniAccessors
          .getStaticField(
              _classRef, _id_CONTROL_AWB_REGIONS, jni.JniType.objectType)
          .object);

  static final _id_CONTROL_AWB_STATE = jniAccessors.getStaticFieldIDOf(
      _classRef,
      "CONTROL_AWB_STATE",
      "Landroid/hardware/camera2/CaptureResult\$Key;");

  /// from: static public final android.hardware.camera2.CaptureResult.Key<java.lang.Integer> CONTROL_AWB_STATE
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// Current state of auto-white balance (AWB) algorithm.
  ///
  /// Switching between or enabling AWB modes (CaptureRequest\#CONTROL_AWB_MODE android.control.awbMode) always
  /// resets the AWB state to INACTIVE. Similarly, switching between CaptureRequest\#CONTROL_MODE android.control.mode,
  /// or CaptureRequest\#CONTROL_SCENE_MODE android.control.sceneMode if <code>CaptureRequest\#CONTROL_MODE android.control.mode == USE_SCENE_MODE</code> resets all
  /// the algorithm states to INACTIVE.
  ///
  /// The camera device can do several state transitions between two results, if it is
  /// allowed by the state transition table. So INACTIVE may never actually be seen in
  /// a result.
  ///
  /// The state in the result is the state for this image (in sync with this image): if
  /// AWB state becomes CONVERGED, then the image data associated with this result should
  /// be good to use.
  ///
  /// Below are state transition tables for different AWB modes.
  ///
  /// When <code>CaptureRequest\#CONTROL_AWB_MODE android.control.awbMode != AWB_MODE_AUTO</code>:
  ///
  /// <table>
  /// <thead>
  /// <tr>
  /// <th align="center">State</th>
  /// <th align="center">Transition Cause</th>
  /// <th align="center">New State</th>
  /// <th align="center">Notes</th>
  /// </tr>
  /// </thead>
  /// <tbody>
  /// <tr>
  /// <td align="center">INACTIVE</td>
  /// <td align="center"></td>
  /// <td align="center">INACTIVE</td>
  /// <td align="center">Camera device auto white balance algorithm is disabled</td>
  /// </tr>
  /// </tbody>
  /// </table>
  /// When CaptureRequest\#CONTROL_AWB_MODE android.control.awbMode is AWB_MODE_AUTO:
  ///
  /// <table>
  /// <thead>
  /// <tr>
  /// <th align="center">State</th>
  /// <th align="center">Transition Cause</th>
  /// <th align="center">New State</th>
  /// <th align="center">Notes</th>
  /// </tr>
  /// </thead>
  /// <tbody>
  /// <tr>
  /// <td align="center">INACTIVE</td>
  /// <td align="center">Camera device initiates AWB scan</td>
  /// <td align="center">SEARCHING</td>
  /// <td align="center">Values changing</td>
  /// </tr>
  /// <tr>
  /// <td align="center">INACTIVE</td>
  /// <td align="center">CaptureRequest\#CONTROL_AWB_LOCK android.control.awbLock is ON</td>
  /// <td align="center">LOCKED</td>
  /// <td align="center">Values locked</td>
  /// </tr>
  /// <tr>
  /// <td align="center">SEARCHING</td>
  /// <td align="center">Camera device finishes AWB scan</td>
  /// <td align="center">CONVERGED</td>
  /// <td align="center">Good values, not changing</td>
  /// </tr>
  /// <tr>
  /// <td align="center">SEARCHING</td>
  /// <td align="center">CaptureRequest\#CONTROL_AWB_LOCK android.control.awbLock is ON</td>
  /// <td align="center">LOCKED</td>
  /// <td align="center">Values locked</td>
  /// </tr>
  /// <tr>
  /// <td align="center">CONVERGED</td>
  /// <td align="center">Camera device initiates AWB scan</td>
  /// <td align="center">SEARCHING</td>
  /// <td align="center">Values changing</td>
  /// </tr>
  /// <tr>
  /// <td align="center">CONVERGED</td>
  /// <td align="center">CaptureRequest\#CONTROL_AWB_LOCK android.control.awbLock is ON</td>
  /// <td align="center">LOCKED</td>
  /// <td align="center">Values locked</td>
  /// </tr>
  /// <tr>
  /// <td align="center">LOCKED</td>
  /// <td align="center">CaptureRequest\#CONTROL_AWB_LOCK android.control.awbLock is OFF</td>
  /// <td align="center">SEARCHING</td>
  /// <td align="center">Values not good after unlock</td>
  /// </tr>
  /// </tbody>
  /// </table>
  /// For the above table, the camera device may skip reporting any state changes that happen
  /// without application intervention (i.e. mode switch, trigger, locking). Any state that
  /// can be skipped in that manner is called a transient state.
  ///
  /// For example, for this AWB mode (AWB_MODE_AUTO), in addition to the state transitions
  /// listed in above table, it is also legal for the camera device to skip one or more
  /// transient states between two results. See below table for examples:
  ///
  /// <table>
  /// <thead>
  /// <tr>
  /// <th align="center">State</th>
  /// <th align="center">Transition Cause</th>
  /// <th align="center">New State</th>
  /// <th align="center">Notes</th>
  /// </tr>
  /// </thead>
  /// <tbody>
  /// <tr>
  /// <td align="center">INACTIVE</td>
  /// <td align="center">Camera device finished AWB scan</td>
  /// <td align="center">CONVERGED</td>
  /// <td align="center">Values are already good, transient states are skipped by camera device.</td>
  /// </tr>
  /// <tr>
  /// <td align="center">LOCKED</td>
  /// <td align="center">CaptureRequest\#CONTROL_AWB_LOCK android.control.awbLock is OFF</td>
  /// <td align="center">CONVERGED</td>
  /// <td align="center">Values good after unlock, transient states are skipped by camera device.</td>
  /// </tr>
  /// </tbody>
  /// </table>
  /// __Possible values:__
  /// <ul>
  ///   <li>\#CONTROL_AWB_STATE_INACTIVE INACTIVE</li>
  ///   <li>\#CONTROL_AWB_STATE_SEARCHING SEARCHING</li>
  ///   <li>\#CONTROL_AWB_STATE_CONVERGED CONVERGED</li>
  ///   <li>\#CONTROL_AWB_STATE_LOCKED LOCKED</li>
  /// </ul>
  ///
  /// __Optional__ - This value may be {@code null} on some devices.
  ///
  /// __Limited capability__ -
  /// Present on all camera devices that report being at least CameraCharacteristics\#INFO_SUPPORTED_HARDWARE_LEVEL_LIMITED HARDWARE_LEVEL_LIMITED devices in the
  /// CameraCharacteristics\#INFO_SUPPORTED_HARDWARE_LEVEL android.info.supportedHardwareLevel key
  ///
  ///@see CaptureRequest\#CONTROL_AWB_LOCK
  ///@see CaptureRequest\#CONTROL_AWB_MODE
  ///@see CaptureRequest\#CONTROL_MODE
  ///@see CaptureRequest\#CONTROL_SCENE_MODE
  ///@see CameraCharacteristics\#INFO_SUPPORTED_HARDWARE_LEVEL
  ///@see \#CONTROL_AWB_STATE_INACTIVE
  ///@see \#CONTROL_AWB_STATE_SEARCHING
  ///@see \#CONTROL_AWB_STATE_CONVERGED
  ///@see \#CONTROL_AWB_STATE_LOCKED
  static CaptureResult_Key get CONTROL_AWB_STATE =>
      CaptureResult_Key.fromRef(jniAccessors
          .getStaticField(
              _classRef, _id_CONTROL_AWB_STATE, jni.JniType.objectType)
          .object);

  static final _id_CONTROL_CAPTURE_INTENT = jniAccessors.getStaticFieldIDOf(
      _classRef,
      "CONTROL_CAPTURE_INTENT",
      "Landroid/hardware/camera2/CaptureResult\$Key;");

  /// from: static public final android.hardware.camera2.CaptureResult.Key<java.lang.Integer> CONTROL_CAPTURE_INTENT
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// Information to the camera device 3A (auto-exposure,
  /// auto-focus, auto-white balance) routines about the purpose
  /// of this capture, to help the camera device to decide optimal 3A
  /// strategy.
  ///
  /// This control (except for MANUAL) is only effective if
  /// <code>CaptureRequest\#CONTROL_MODE android.control.mode != OFF</code> and any 3A routine is active.
  ///
  /// All intents are supported by all devices, except that:
  ///   * ZERO_SHUTTER_LAG will be supported if CameraCharacteristics\#REQUEST_AVAILABLE_CAPABILITIES android.request.availableCapabilities contains
  /// PRIVATE_REPROCESSING or YUV_REPROCESSING.
  ///   * MANUAL will be supported if CameraCharacteristics\#REQUEST_AVAILABLE_CAPABILITIES android.request.availableCapabilities contains
  /// MANUAL_SENSOR.
  ///   * MOTION_TRACKING will be supported if CameraCharacteristics\#REQUEST_AVAILABLE_CAPABILITIES android.request.availableCapabilities contains
  /// MOTION_TRACKING.
  ///
  /// __Possible values:__
  /// <ul>
  ///   <li>\#CONTROL_CAPTURE_INTENT_CUSTOM CUSTOM</li>
  ///   <li>\#CONTROL_CAPTURE_INTENT_PREVIEW PREVIEW</li>
  ///   <li>\#CONTROL_CAPTURE_INTENT_STILL_CAPTURE STILL_CAPTURE</li>
  ///   <li>\#CONTROL_CAPTURE_INTENT_VIDEO_RECORD VIDEO_RECORD</li>
  ///   <li>\#CONTROL_CAPTURE_INTENT_VIDEO_SNAPSHOT VIDEO_SNAPSHOT</li>
  ///   <li>\#CONTROL_CAPTURE_INTENT_ZERO_SHUTTER_LAG ZERO_SHUTTER_LAG</li>
  ///   <li>\#CONTROL_CAPTURE_INTENT_MANUAL MANUAL</li>
  ///   <li>\#CONTROL_CAPTURE_INTENT_MOTION_TRACKING MOTION_TRACKING</li>
  /// </ul>
  ///
  /// This key is available on all devices.
  ///
  ///@see CaptureRequest\#CONTROL_MODE
  ///@see CameraCharacteristics\#REQUEST_AVAILABLE_CAPABILITIES
  ///@see \#CONTROL_CAPTURE_INTENT_CUSTOM
  ///@see \#CONTROL_CAPTURE_INTENT_PREVIEW
  ///@see \#CONTROL_CAPTURE_INTENT_STILL_CAPTURE
  ///@see \#CONTROL_CAPTURE_INTENT_VIDEO_RECORD
  ///@see \#CONTROL_CAPTURE_INTENT_VIDEO_SNAPSHOT
  ///@see \#CONTROL_CAPTURE_INTENT_ZERO_SHUTTER_LAG
  ///@see \#CONTROL_CAPTURE_INTENT_MANUAL
  ///@see \#CONTROL_CAPTURE_INTENT_MOTION_TRACKING
  static CaptureResult_Key get CONTROL_CAPTURE_INTENT =>
      CaptureResult_Key.fromRef(jniAccessors
          .getStaticField(
              _classRef, _id_CONTROL_CAPTURE_INTENT, jni.JniType.objectType)
          .object);

  static final _id_CONTROL_EFFECT_MODE = jniAccessors.getStaticFieldIDOf(
      _classRef,
      "CONTROL_EFFECT_MODE",
      "Landroid/hardware/camera2/CaptureResult\$Key;");

  /// from: static public final android.hardware.camera2.CaptureResult.Key<java.lang.Integer> CONTROL_EFFECT_MODE
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// A special color effect to apply.
  ///
  /// When this mode is set, a color effect will be applied
  /// to images produced by the camera device. The interpretation
  /// and implementation of these color effects is left to the
  /// implementor of the camera device, and should not be
  /// depended on to be consistent (or present) across all
  /// devices.
  ///
  /// __Possible values:__
  /// <ul>
  ///   <li>\#CONTROL_EFFECT_MODE_OFF OFF</li>
  ///   <li>\#CONTROL_EFFECT_MODE_MONO MONO</li>
  ///   <li>\#CONTROL_EFFECT_MODE_NEGATIVE NEGATIVE</li>
  ///   <li>\#CONTROL_EFFECT_MODE_SOLARIZE SOLARIZE</li>
  ///   <li>\#CONTROL_EFFECT_MODE_SEPIA SEPIA</li>
  ///   <li>\#CONTROL_EFFECT_MODE_POSTERIZE POSTERIZE</li>
  ///   <li>\#CONTROL_EFFECT_MODE_WHITEBOARD WHITEBOARD</li>
  ///   <li>\#CONTROL_EFFECT_MODE_BLACKBOARD BLACKBOARD</li>
  ///   <li>\#CONTROL_EFFECT_MODE_AQUA AQUA</li>
  /// </ul>
  ///
  /// __Available values for this device:__<br>
  /// CameraCharacteristics\#CONTROL_AVAILABLE_EFFECTS android.control.availableEffects
  ///
  /// This key is available on all devices.
  ///
  ///@see CameraCharacteristics\#CONTROL_AVAILABLE_EFFECTS
  ///@see \#CONTROL_EFFECT_MODE_OFF
  ///@see \#CONTROL_EFFECT_MODE_MONO
  ///@see \#CONTROL_EFFECT_MODE_NEGATIVE
  ///@see \#CONTROL_EFFECT_MODE_SOLARIZE
  ///@see \#CONTROL_EFFECT_MODE_SEPIA
  ///@see \#CONTROL_EFFECT_MODE_POSTERIZE
  ///@see \#CONTROL_EFFECT_MODE_WHITEBOARD
  ///@see \#CONTROL_EFFECT_MODE_BLACKBOARD
  ///@see \#CONTROL_EFFECT_MODE_AQUA
  static CaptureResult_Key get CONTROL_EFFECT_MODE =>
      CaptureResult_Key.fromRef(jniAccessors
          .getStaticField(
              _classRef, _id_CONTROL_EFFECT_MODE, jni.JniType.objectType)
          .object);

  static final _id_CONTROL_ENABLE_ZSL = jniAccessors.getStaticFieldIDOf(
      _classRef,
      "CONTROL_ENABLE_ZSL",
      "Landroid/hardware/camera2/CaptureResult\$Key;");

  /// from: static public final android.hardware.camera2.CaptureResult.Key<java.lang.Boolean> CONTROL_ENABLE_ZSL
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// Allow camera device to enable zero-shutter-lag mode for requests with
  /// CaptureRequest\#CONTROL_CAPTURE_INTENT android.control.captureIntent == STILL_CAPTURE.
  ///
  /// If enableZsl is <code>true</code>, the camera device may enable zero-shutter-lag mode for requests with
  /// STILL_CAPTURE capture intent. The camera device may use images captured in the past to
  /// produce output images for a zero-shutter-lag request. The result metadata including the
  /// CaptureResult\#SENSOR_TIMESTAMP android.sensor.timestamp reflects the source frames used to produce output images.
  /// Therefore, the contents of the output images and the result metadata may be out of order
  /// compared to previous regular requests. enableZsl does not affect requests with other
  /// capture intents.
  ///
  /// For example, when requests are submitted in the following order:
  ///   Request A: enableZsl is ON, CaptureRequest\#CONTROL_CAPTURE_INTENT android.control.captureIntent is PREVIEW
  ///   Request B: enableZsl is ON, CaptureRequest\#CONTROL_CAPTURE_INTENT android.control.captureIntent is STILL_CAPTURE
  ///
  /// The output images for request B may have contents captured before the output images for
  /// request A, and the result metadata for request B may be older than the result metadata for
  /// request A.
  ///
  /// Note that when enableZsl is <code>true</code>, it is not guaranteed to get output images captured in
  /// the past for requests with STILL_CAPTURE capture intent.
  ///
  /// For applications targeting SDK versions O and newer, the value of enableZsl in
  /// TEMPLATE_STILL_CAPTURE template may be <code>true</code>. The value in other templates is always
  /// <code>false</code> if present.
  ///
  /// For applications targeting SDK versions older than O, the value of enableZsl in all
  /// capture templates is always <code>false</code> if present.
  ///
  /// For application-operated ZSL, use CAMERA3_TEMPLATE_ZERO_SHUTTER_LAG template.
  ///
  /// __Optional__ - This value may be {@code null} on some devices.
  ///
  ///@see CaptureRequest\#CONTROL_CAPTURE_INTENT
  ///@see CaptureResult\#SENSOR_TIMESTAMP
  static CaptureResult_Key get CONTROL_ENABLE_ZSL =>
      CaptureResult_Key.fromRef(jniAccessors
          .getStaticField(
              _classRef, _id_CONTROL_ENABLE_ZSL, jni.JniType.objectType)
          .object);

  static final _id_CONTROL_MODE = jniAccessors.getStaticFieldIDOf(_classRef,
      "CONTROL_MODE", "Landroid/hardware/camera2/CaptureResult\$Key;");

  /// from: static public final android.hardware.camera2.CaptureResult.Key<java.lang.Integer> CONTROL_MODE
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// Overall mode of 3A (auto-exposure, auto-white-balance, auto-focus) control
  /// routines.
  ///
  /// This is a top-level 3A control switch. When set to OFF, all 3A control
  /// by the camera device is disabled. The application must set the fields for
  /// capture parameters itself.
  ///
  /// When set to AUTO, the individual algorithm controls in
  /// android.control.* are in effect, such as CaptureRequest\#CONTROL_AF_MODE android.control.afMode.
  ///
  /// When set to USE_SCENE_MODE, the individual controls in
  /// android.control.* are mostly disabled, and the camera device
  /// implements one of the scene mode settings (such as ACTION,
  /// SUNSET, or PARTY) as it wishes. The camera device scene mode
  /// 3A settings are provided by android.hardware.camera2.CaptureResult capture results.
  ///
  /// When set to OFF_KEEP_STATE, it is similar to OFF mode, the only difference
  /// is that this frame will not be used by camera device background 3A statistics
  /// update, as if this frame is never captured. This mode can be used in the scenario
  /// where the application doesn't want a 3A manual control capture to affect
  /// the subsequent auto 3A capture results.
  ///
  /// __Possible values:__
  /// <ul>
  ///   <li>\#CONTROL_MODE_OFF OFF</li>
  ///   <li>\#CONTROL_MODE_AUTO AUTO</li>
  ///   <li>\#CONTROL_MODE_USE_SCENE_MODE USE_SCENE_MODE</li>
  ///   <li>\#CONTROL_MODE_OFF_KEEP_STATE OFF_KEEP_STATE</li>
  /// </ul>
  ///
  /// __Available values for this device:__<br>
  /// CameraCharacteristics\#CONTROL_AVAILABLE_MODES android.control.availableModes
  ///
  /// This key is available on all devices.
  ///
  ///@see CaptureRequest\#CONTROL_AF_MODE
  ///@see CameraCharacteristics\#CONTROL_AVAILABLE_MODES
  ///@see \#CONTROL_MODE_OFF
  ///@see \#CONTROL_MODE_AUTO
  ///@see \#CONTROL_MODE_USE_SCENE_MODE
  ///@see \#CONTROL_MODE_OFF_KEEP_STATE
  static CaptureResult_Key get CONTROL_MODE =>
      CaptureResult_Key.fromRef(jniAccessors
          .getStaticField(_classRef, _id_CONTROL_MODE, jni.JniType.objectType)
          .object);

  static final _id_CONTROL_POST_RAW_SENSITIVITY_BOOST =
      jniAccessors.getStaticFieldIDOf(
          _classRef,
          "CONTROL_POST_RAW_SENSITIVITY_BOOST",
          "Landroid/hardware/camera2/CaptureResult\$Key;");

  /// from: static public final android.hardware.camera2.CaptureResult.Key<java.lang.Integer> CONTROL_POST_RAW_SENSITIVITY_BOOST
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// The amount of additional sensitivity boost applied to output images
  /// after RAW sensor data is captured.
  ///
  /// Some camera devices support additional digital sensitivity boosting in the
  /// camera processing pipeline after sensor RAW image is captured.
  /// Such a boost will be applied to YUV/JPEG format output images but will not
  /// have effect on RAW output formats like RAW_SENSOR, RAW10, RAW12 or RAW_OPAQUE.
  ///
  /// This key will be <code>null</code> for devices that do not support any RAW format
  /// outputs. For devices that do support RAW format outputs, this key will always
  /// present, and if a device does not support post RAW sensitivity boost, it will
  /// list <code>100</code> in this key.
  ///
  /// If the camera device cannot apply the exact boost requested, it will reduce the
  /// boost to the nearest supported value.
  /// The final boost value used will be available in the output capture result.
  ///
  /// For devices that support post RAW sensitivity boost, the YUV/JPEG output images
  /// of such device will have the total sensitivity of
  /// <code>CaptureRequest\#SENSOR_SENSITIVITY android.sensor.sensitivity * CaptureRequest\#CONTROL_POST_RAW_SENSITIVITY_BOOST android.control.postRawSensitivityBoost / 100</code>
  /// The sensitivity of RAW format images will always be <code>CaptureRequest\#SENSOR_SENSITIVITY android.sensor.sensitivity</code>
  ///
  /// This control is only effective if CaptureRequest\#CONTROL_AE_MODE android.control.aeMode or CaptureRequest\#CONTROL_MODE android.control.mode is set to
  /// OFF; otherwise the auto-exposure algorithm will override this value.
  ///
  /// __Units__: ISO arithmetic units, the same as CaptureRequest\#SENSOR_SENSITIVITY android.sensor.sensitivity
  ///
  /// __Range of valid values:__<br>
  /// CameraCharacteristics\#CONTROL_POST_RAW_SENSITIVITY_BOOST_RANGE android.control.postRawSensitivityBoostRange
  ///
  /// __Optional__ - This value may be {@code null} on some devices.
  ///
  ///@see CaptureRequest\#CONTROL_AE_MODE
  ///@see CaptureRequest\#CONTROL_MODE
  ///@see CaptureRequest\#CONTROL_POST_RAW_SENSITIVITY_BOOST
  ///@see CameraCharacteristics\#CONTROL_POST_RAW_SENSITIVITY_BOOST_RANGE
  ///@see CaptureRequest\#SENSOR_SENSITIVITY
  static CaptureResult_Key get CONTROL_POST_RAW_SENSITIVITY_BOOST =>
      CaptureResult_Key.fromRef(jniAccessors
          .getStaticField(_classRef, _id_CONTROL_POST_RAW_SENSITIVITY_BOOST,
              jni.JniType.objectType)
          .object);

  static final _id_CONTROL_SCENE_MODE = jniAccessors.getStaticFieldIDOf(
      _classRef,
      "CONTROL_SCENE_MODE",
      "Landroid/hardware/camera2/CaptureResult\$Key;");

  /// from: static public final android.hardware.camera2.CaptureResult.Key<java.lang.Integer> CONTROL_SCENE_MODE
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// Control for which scene mode is currently active.
  ///
  /// Scene modes are custom camera modes optimized for a certain set of conditions and
  /// capture settings.
  ///
  /// This is the mode that that is active when
  /// <code>CaptureRequest\#CONTROL_MODE android.control.mode == USE_SCENE_MODE</code>. Aside from FACE_PRIORITY, these modes will
  /// disable CaptureRequest\#CONTROL_AE_MODE android.control.aeMode, CaptureRequest\#CONTROL_AWB_MODE android.control.awbMode, and CaptureRequest\#CONTROL_AF_MODE android.control.afMode
  /// while in use.
  ///
  /// The interpretation and implementation of these scene modes is left
  /// to the implementor of the camera device. Their behavior will not be
  /// consistent across all devices, and any given device may only implement
  /// a subset of these modes.
  ///
  /// __Possible values:__
  /// <ul>
  ///   <li>\#CONTROL_SCENE_MODE_DISABLED DISABLED</li>
  ///   <li>\#CONTROL_SCENE_MODE_FACE_PRIORITY FACE_PRIORITY</li>
  ///   <li>\#CONTROL_SCENE_MODE_ACTION ACTION</li>
  ///   <li>\#CONTROL_SCENE_MODE_PORTRAIT PORTRAIT</li>
  ///   <li>\#CONTROL_SCENE_MODE_LANDSCAPE LANDSCAPE</li>
  ///   <li>\#CONTROL_SCENE_MODE_NIGHT NIGHT</li>
  ///   <li>\#CONTROL_SCENE_MODE_NIGHT_PORTRAIT NIGHT_PORTRAIT</li>
  ///   <li>\#CONTROL_SCENE_MODE_THEATRE THEATRE</li>
  ///   <li>\#CONTROL_SCENE_MODE_BEACH BEACH</li>
  ///   <li>\#CONTROL_SCENE_MODE_SNOW SNOW</li>
  ///   <li>\#CONTROL_SCENE_MODE_SUNSET SUNSET</li>
  ///   <li>\#CONTROL_SCENE_MODE_STEADYPHOTO STEADYPHOTO</li>
  ///   <li>\#CONTROL_SCENE_MODE_FIREWORKS FIREWORKS</li>
  ///   <li>\#CONTROL_SCENE_MODE_SPORTS SPORTS</li>
  ///   <li>\#CONTROL_SCENE_MODE_PARTY PARTY</li>
  ///   <li>\#CONTROL_SCENE_MODE_CANDLELIGHT CANDLELIGHT</li>
  ///   <li>\#CONTROL_SCENE_MODE_BARCODE BARCODE</li>
  ///   <li>\#CONTROL_SCENE_MODE_HIGH_SPEED_VIDEO HIGH_SPEED_VIDEO</li>
  ///   <li>\#CONTROL_SCENE_MODE_HDR HDR</li>
  /// </ul>
  ///
  /// __Available values for this device:__<br>
  /// CameraCharacteristics\#CONTROL_AVAILABLE_SCENE_MODES android.control.availableSceneModes
  ///
  /// This key is available on all devices.
  ///
  ///@see CaptureRequest\#CONTROL_AE_MODE
  ///@see CaptureRequest\#CONTROL_AF_MODE
  ///@see CameraCharacteristics\#CONTROL_AVAILABLE_SCENE_MODES
  ///@see CaptureRequest\#CONTROL_AWB_MODE
  ///@see CaptureRequest\#CONTROL_MODE
  ///@see \#CONTROL_SCENE_MODE_DISABLED
  ///@see \#CONTROL_SCENE_MODE_FACE_PRIORITY
  ///@see \#CONTROL_SCENE_MODE_ACTION
  ///@see \#CONTROL_SCENE_MODE_PORTRAIT
  ///@see \#CONTROL_SCENE_MODE_LANDSCAPE
  ///@see \#CONTROL_SCENE_MODE_NIGHT
  ///@see \#CONTROL_SCENE_MODE_NIGHT_PORTRAIT
  ///@see \#CONTROL_SCENE_MODE_THEATRE
  ///@see \#CONTROL_SCENE_MODE_BEACH
  ///@see \#CONTROL_SCENE_MODE_SNOW
  ///@see \#CONTROL_SCENE_MODE_SUNSET
  ///@see \#CONTROL_SCENE_MODE_STEADYPHOTO
  ///@see \#CONTROL_SCENE_MODE_FIREWORKS
  ///@see \#CONTROL_SCENE_MODE_SPORTS
  ///@see \#CONTROL_SCENE_MODE_PARTY
  ///@see \#CONTROL_SCENE_MODE_CANDLELIGHT
  ///@see \#CONTROL_SCENE_MODE_BARCODE
  ///@see \#CONTROL_SCENE_MODE_HIGH_SPEED_VIDEO
  ///@see \#CONTROL_SCENE_MODE_HDR
  static CaptureResult_Key get CONTROL_SCENE_MODE =>
      CaptureResult_Key.fromRef(jniAccessors
          .getStaticField(
              _classRef, _id_CONTROL_SCENE_MODE, jni.JniType.objectType)
          .object);

  static final _id_CONTROL_VIDEO_STABILIZATION_MODE =
      jniAccessors.getStaticFieldIDOf(
          _classRef,
          "CONTROL_VIDEO_STABILIZATION_MODE",
          "Landroid/hardware/camera2/CaptureResult\$Key;");

  /// from: static public final android.hardware.camera2.CaptureResult.Key<java.lang.Integer> CONTROL_VIDEO_STABILIZATION_MODE
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// Whether video stabilization is
  /// active.
  ///
  /// Video stabilization automatically warps images from
  /// the camera in order to stabilize motion between consecutive frames.
  ///
  /// If enabled, video stabilization can modify the
  /// CaptureRequest\#SCALER_CROP_REGION android.scaler.cropRegion to keep the video stream stabilized.
  ///
  /// Switching between different video stabilization modes may take several
  /// frames to initialize, the camera device will report the current mode
  /// in capture result metadata. For example, When "ON" mode is requested,
  /// the video stabilization modes in the first several capture results may
  /// still be "OFF", and it will become "ON" when the initialization is
  /// done.
  ///
  /// In addition, not all recording sizes or frame rates may be supported for
  /// stabilization by a device that reports stabilization support. It is guaranteed
  /// that an output targeting a MediaRecorder or MediaCodec will be stabilized if
  /// the recording resolution is less than or equal to 1920 x 1080 (width less than
  /// or equal to 1920, height less than or equal to 1080), and the recording
  /// frame rate is less than or equal to 30fps.  At other sizes, the CaptureResult
  /// CaptureRequest\#CONTROL_VIDEO_STABILIZATION_MODE android.control.videoStabilizationMode field will return
  /// OFF if the recording output is not stabilized, or if there are no output
  /// Surface types that can be stabilized.
  ///
  /// If a camera device supports both this mode and OIS
  /// (CaptureRequest\#LENS_OPTICAL_STABILIZATION_MODE android.lens.opticalStabilizationMode), turning both modes on may
  /// produce undesirable interaction, so it is recommended not to enable
  /// both at the same time.
  ///
  /// __Possible values:__
  /// <ul>
  ///   <li>\#CONTROL_VIDEO_STABILIZATION_MODE_OFF OFF</li>
  ///   <li>\#CONTROL_VIDEO_STABILIZATION_MODE_ON ON</li>
  /// </ul>
  ///
  /// This key is available on all devices.
  ///
  ///@see CaptureRequest\#CONTROL_VIDEO_STABILIZATION_MODE
  ///@see CaptureRequest\#LENS_OPTICAL_STABILIZATION_MODE
  ///@see CaptureRequest\#SCALER_CROP_REGION
  ///@see \#CONTROL_VIDEO_STABILIZATION_MODE_OFF
  ///@see \#CONTROL_VIDEO_STABILIZATION_MODE_ON
  static CaptureResult_Key get CONTROL_VIDEO_STABILIZATION_MODE =>
      CaptureResult_Key.fromRef(jniAccessors
          .getStaticField(_classRef, _id_CONTROL_VIDEO_STABILIZATION_MODE,
              jni.JniType.objectType)
          .object);

  static final _id_DISTORTION_CORRECTION_MODE = jniAccessors.getStaticFieldIDOf(
      _classRef,
      "DISTORTION_CORRECTION_MODE",
      "Landroid/hardware/camera2/CaptureResult\$Key;");

  /// from: static public final android.hardware.camera2.CaptureResult.Key<java.lang.Integer> DISTORTION_CORRECTION_MODE
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// Mode of operation for the lens distortion correction block.
  ///
  /// The lens distortion correction block attempts to improve image quality by fixing
  /// radial, tangential, or other geometric aberrations in the camera device's optics.  If
  /// available, the CameraCharacteristics\#LENS_DISTORTION android.lens.distortion field documents the lens's distortion parameters.
  ///
  /// OFF means no distortion correction is done.
  ///
  /// FAST/HIGH_QUALITY both mean camera device determined distortion correction will be
  /// applied. HIGH_QUALITY mode indicates that the camera device will use the highest-quality
  /// correction algorithms, even if it slows down capture rate. FAST means the camera device
  /// will not slow down capture rate when applying correction. FAST may be the same as OFF if
  /// any correction at all would slow down capture rate.  Every output stream will have a
  /// similar amount of enhancement applied.
  ///
  /// The correction only applies to processed outputs such as YUV, JPEG, or DEPTH16; it is not
  /// applied to any RAW output. Metadata coordinates such as face rectangles or metering
  /// regions are also not affected by correction.
  ///
  /// This control will be on by default on devices that support this control. Applications
  /// disabling distortion correction need to pay extra attention with the coordinate system of
  /// metering regions, crop region, and face rectangles. When distortion correction is OFF,
  /// metadata coordinates follow the coordinate system of
  /// CameraCharacteristics\#SENSOR_INFO_PRE_CORRECTION_ACTIVE_ARRAY_SIZE android.sensor.info.preCorrectionActiveArraySize. When distortion is not OFF, metadata
  /// coordinates follow the coordinate system of CameraCharacteristics\#SENSOR_INFO_ACTIVE_ARRAY_SIZE android.sensor.info.activeArraySize.
  ///
  /// __Possible values:__
  /// <ul>
  ///   <li>\#DISTORTION_CORRECTION_MODE_OFF OFF</li>
  ///   <li>\#DISTORTION_CORRECTION_MODE_FAST FAST</li>
  ///   <li>\#DISTORTION_CORRECTION_MODE_HIGH_QUALITY HIGH_QUALITY</li>
  /// </ul>
  ///
  /// __Available values for this device:__<br>
  /// CameraCharacteristics\#DISTORTION_CORRECTION_AVAILABLE_MODES android.distortionCorrection.availableModes
  ///
  /// __Optional__ - This value may be {@code null} on some devices.
  ///
  ///@see CameraCharacteristics\#DISTORTION_CORRECTION_AVAILABLE_MODES
  ///@see CameraCharacteristics\#LENS_DISTORTION
  ///@see CameraCharacteristics\#SENSOR_INFO_ACTIVE_ARRAY_SIZE
  ///@see CameraCharacteristics\#SENSOR_INFO_PRE_CORRECTION_ACTIVE_ARRAY_SIZE
  ///@see \#DISTORTION_CORRECTION_MODE_OFF
  ///@see \#DISTORTION_CORRECTION_MODE_FAST
  ///@see \#DISTORTION_CORRECTION_MODE_HIGH_QUALITY
  static CaptureResult_Key get DISTORTION_CORRECTION_MODE =>
      CaptureResult_Key.fromRef(jniAccessors
          .getStaticField(
              _classRef, _id_DISTORTION_CORRECTION_MODE, jni.JniType.objectType)
          .object);

  static final _id_EDGE_MODE = jniAccessors.getStaticFieldIDOf(
      _classRef, "EDGE_MODE", "Landroid/hardware/camera2/CaptureResult\$Key;");

  /// from: static public final android.hardware.camera2.CaptureResult.Key<java.lang.Integer> EDGE_MODE
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// Operation mode for edge
  /// enhancement.
  ///
  /// Edge enhancement improves sharpness and details in the captured image. OFF means
  /// no enhancement will be applied by the camera device.
  ///
  /// FAST/HIGH_QUALITY both mean camera device determined enhancement
  /// will be applied. HIGH_QUALITY mode indicates that the
  /// camera device will use the highest-quality enhancement algorithms,
  /// even if it slows down capture rate. FAST means the camera device will
  /// not slow down capture rate when applying edge enhancement. FAST may be the same as OFF if
  /// edge enhancement will slow down capture rate. Every output stream will have a similar
  /// amount of enhancement applied.
  ///
  /// ZERO_SHUTTER_LAG is meant to be used by applications that maintain a continuous circular
  /// buffer of high-resolution images during preview and reprocess image(s) from that buffer
  /// into a final capture when triggered by the user. In this mode, the camera device applies
  /// edge enhancement to low-resolution streams (below maximum recording resolution) to
  /// maximize preview quality, but does not apply edge enhancement to high-resolution streams,
  /// since those will be reprocessed later if necessary.
  ///
  /// For YUV_REPROCESSING, these FAST/HIGH_QUALITY modes both mean that the camera
  /// device will apply FAST/HIGH_QUALITY YUV-domain edge enhancement, respectively.
  /// The camera device may adjust its internal edge enhancement parameters for best
  /// image quality based on the CaptureRequest\#REPROCESS_EFFECTIVE_EXPOSURE_FACTOR android.reprocess.effectiveExposureFactor, if it is set.
  ///
  /// __Possible values:__
  /// <ul>
  ///   <li>\#EDGE_MODE_OFF OFF</li>
  ///   <li>\#EDGE_MODE_FAST FAST</li>
  ///   <li>\#EDGE_MODE_HIGH_QUALITY HIGH_QUALITY</li>
  ///   <li>\#EDGE_MODE_ZERO_SHUTTER_LAG ZERO_SHUTTER_LAG</li>
  /// </ul>
  ///
  /// __Available values for this device:__<br>
  /// CameraCharacteristics\#EDGE_AVAILABLE_EDGE_MODES android.edge.availableEdgeModes
  ///
  /// __Optional__ - This value may be {@code null} on some devices.
  ///
  /// __Full capability__ -
  /// Present on all camera devices that report being CameraCharacteristics\#INFO_SUPPORTED_HARDWARE_LEVEL_FULL HARDWARE_LEVEL_FULL devices in the
  /// CameraCharacteristics\#INFO_SUPPORTED_HARDWARE_LEVEL android.info.supportedHardwareLevel key
  ///
  ///@see CameraCharacteristics\#EDGE_AVAILABLE_EDGE_MODES
  ///@see CameraCharacteristics\#INFO_SUPPORTED_HARDWARE_LEVEL
  ///@see CaptureRequest\#REPROCESS_EFFECTIVE_EXPOSURE_FACTOR
  ///@see \#EDGE_MODE_OFF
  ///@see \#EDGE_MODE_FAST
  ///@see \#EDGE_MODE_HIGH_QUALITY
  ///@see \#EDGE_MODE_ZERO_SHUTTER_LAG
  static CaptureResult_Key get EDGE_MODE =>
      CaptureResult_Key.fromRef(jniAccessors
          .getStaticField(_classRef, _id_EDGE_MODE, jni.JniType.objectType)
          .object);

  static final _id_FLASH_MODE = jniAccessors.getStaticFieldIDOf(
      _classRef, "FLASH_MODE", "Landroid/hardware/camera2/CaptureResult\$Key;");

  /// from: static public final android.hardware.camera2.CaptureResult.Key<java.lang.Integer> FLASH_MODE
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// The desired mode for for the camera device's flash control.
  ///
  /// This control is only effective when flash unit is available
  /// (<code>CameraCharacteristics\#FLASH_INFO_AVAILABLE android.flash.info.available == true</code>).
  ///
  /// When this control is used, the CaptureRequest\#CONTROL_AE_MODE android.control.aeMode must be set to ON or OFF.
  /// Otherwise, the camera device auto-exposure related flash control (ON_AUTO_FLASH,
  /// ON_ALWAYS_FLASH, or ON_AUTO_FLASH_REDEYE) will override this control.
  ///
  /// When set to OFF, the camera device will not fire flash for this capture.
  ///
  /// When set to SINGLE, the camera device will fire flash regardless of the camera
  /// device's auto-exposure routine's result. When used in still capture case, this
  /// control should be used along with auto-exposure (AE) precapture metering sequence
  /// (CaptureRequest\#CONTROL_AE_PRECAPTURE_TRIGGER android.control.aePrecaptureTrigger), otherwise, the image may be incorrectly exposed.
  ///
  /// When set to TORCH, the flash will be on continuously. This mode can be used
  /// for use cases such as preview, auto-focus assist, still capture, or video recording.
  ///
  /// The flash status will be reported by CaptureResult\#FLASH_STATE android.flash.state in the capture result metadata.
  ///
  /// __Possible values:__
  /// <ul>
  ///   <li>\#FLASH_MODE_OFF OFF</li>
  ///   <li>\#FLASH_MODE_SINGLE SINGLE</li>
  ///   <li>\#FLASH_MODE_TORCH TORCH</li>
  /// </ul>
  ///
  /// This key is available on all devices.
  ///
  ///@see CaptureRequest\#CONTROL_AE_MODE
  ///@see CaptureRequest\#CONTROL_AE_PRECAPTURE_TRIGGER
  ///@see CameraCharacteristics\#FLASH_INFO_AVAILABLE
  ///@see CaptureResult\#FLASH_STATE
  ///@see \#FLASH_MODE_OFF
  ///@see \#FLASH_MODE_SINGLE
  ///@see \#FLASH_MODE_TORCH
  static CaptureResult_Key get FLASH_MODE =>
      CaptureResult_Key.fromRef(jniAccessors
          .getStaticField(_classRef, _id_FLASH_MODE, jni.JniType.objectType)
          .object);

  static final _id_FLASH_STATE = jniAccessors.getStaticFieldIDOf(_classRef,
      "FLASH_STATE", "Landroid/hardware/camera2/CaptureResult\$Key;");

  /// from: static public final android.hardware.camera2.CaptureResult.Key<java.lang.Integer> FLASH_STATE
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// Current state of the flash
  /// unit.
  ///
  /// When the camera device doesn't have flash unit
  /// (i.e. <code>CameraCharacteristics\#FLASH_INFO_AVAILABLE android.flash.info.available == false</code>), this state will always be UNAVAILABLE.
  /// Other states indicate the current flash status.
  ///
  /// In certain conditions, this will be available on LEGACY devices:
  ///
  /// <ul>
  /// <li>Flash-less cameras always return UNAVAILABLE.</li>
  /// <li>Using CaptureRequest\#CONTROL_AE_MODE android.control.aeMode <code>==</code> ON_ALWAYS_FLASH
  ///    will always return FIRED.</li>
  /// <li>Using CaptureRequest\#FLASH_MODE android.flash.mode <code>==</code> TORCH
  ///    will always return FIRED.</li>
  /// </ul>
  /// In all other conditions the state will not be available on
  /// LEGACY devices (i.e. it will be <code>null</code>).
  ///
  /// __Possible values:__
  /// <ul>
  ///   <li>\#FLASH_STATE_UNAVAILABLE UNAVAILABLE</li>
  ///   <li>\#FLASH_STATE_CHARGING CHARGING</li>
  ///   <li>\#FLASH_STATE_READY READY</li>
  ///   <li>\#FLASH_STATE_FIRED FIRED</li>
  ///   <li>\#FLASH_STATE_PARTIAL PARTIAL</li>
  /// </ul>
  ///
  /// __Optional__ - This value may be {@code null} on some devices.
  ///
  /// __Limited capability__ -
  /// Present on all camera devices that report being at least CameraCharacteristics\#INFO_SUPPORTED_HARDWARE_LEVEL_LIMITED HARDWARE_LEVEL_LIMITED devices in the
  /// CameraCharacteristics\#INFO_SUPPORTED_HARDWARE_LEVEL android.info.supportedHardwareLevel key
  ///
  ///@see CaptureRequest\#CONTROL_AE_MODE
  ///@see CameraCharacteristics\#FLASH_INFO_AVAILABLE
  ///@see CaptureRequest\#FLASH_MODE
  ///@see CameraCharacteristics\#INFO_SUPPORTED_HARDWARE_LEVEL
  ///@see \#FLASH_STATE_UNAVAILABLE
  ///@see \#FLASH_STATE_CHARGING
  ///@see \#FLASH_STATE_READY
  ///@see \#FLASH_STATE_FIRED
  ///@see \#FLASH_STATE_PARTIAL
  static CaptureResult_Key get FLASH_STATE =>
      CaptureResult_Key.fromRef(jniAccessors
          .getStaticField(_classRef, _id_FLASH_STATE, jni.JniType.objectType)
          .object);

  static final _id_HOT_PIXEL_MODE = jniAccessors.getStaticFieldIDOf(_classRef,
      "HOT_PIXEL_MODE", "Landroid/hardware/camera2/CaptureResult\$Key;");

  /// from: static public final android.hardware.camera2.CaptureResult.Key<java.lang.Integer> HOT_PIXEL_MODE
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// Operational mode for hot pixel correction.
  ///
  /// Hotpixel correction interpolates out, or otherwise removes, pixels
  /// that do not accurately measure the incoming light (i.e. pixels that
  /// are stuck at an arbitrary value or are oversensitive).
  ///
  /// __Possible values:__
  /// <ul>
  ///   <li>\#HOT_PIXEL_MODE_OFF OFF</li>
  ///   <li>\#HOT_PIXEL_MODE_FAST FAST</li>
  ///   <li>\#HOT_PIXEL_MODE_HIGH_QUALITY HIGH_QUALITY</li>
  /// </ul>
  ///
  /// __Available values for this device:__<br>
  /// CameraCharacteristics\#HOT_PIXEL_AVAILABLE_HOT_PIXEL_MODES android.hotPixel.availableHotPixelModes
  ///
  /// __Optional__ - This value may be {@code null} on some devices.
  ///
  ///@see CameraCharacteristics\#HOT_PIXEL_AVAILABLE_HOT_PIXEL_MODES
  ///@see \#HOT_PIXEL_MODE_OFF
  ///@see \#HOT_PIXEL_MODE_FAST
  ///@see \#HOT_PIXEL_MODE_HIGH_QUALITY
  static CaptureResult_Key get HOT_PIXEL_MODE =>
      CaptureResult_Key.fromRef(jniAccessors
          .getStaticField(_classRef, _id_HOT_PIXEL_MODE, jni.JniType.objectType)
          .object);

  static final _id_JPEG_GPS_LOCATION = jniAccessors.getStaticFieldIDOf(
      _classRef,
      "JPEG_GPS_LOCATION",
      "Landroid/hardware/camera2/CaptureResult\$Key;");

  /// from: static public final android.hardware.camera2.CaptureResult.Key<android.location.Location> JPEG_GPS_LOCATION
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// A location object to use when generating image GPS metadata.
  ///
  /// Setting a location object in a request will include the GPS coordinates of the location
  /// into any JPEG images captured based on the request. These coordinates can then be
  /// viewed by anyone who receives the JPEG image.
  ///
  /// This key is available on all devices.
  ///
  static CaptureResult_Key get JPEG_GPS_LOCATION =>
      CaptureResult_Key.fromRef(jniAccessors
          .getStaticField(
              _classRef, _id_JPEG_GPS_LOCATION, jni.JniType.objectType)
          .object);

  static final _id_JPEG_ORIENTATION = jniAccessors.getStaticFieldIDOf(_classRef,
      "JPEG_ORIENTATION", "Landroid/hardware/camera2/CaptureResult\$Key;");

  /// from: static public final android.hardware.camera2.CaptureResult.Key<java.lang.Integer> JPEG_ORIENTATION
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// The orientation for a JPEG image.
  ///
  /// The clockwise rotation angle in degrees, relative to the orientation
  /// to the camera, that the JPEG picture needs to be rotated by, to be viewed
  /// upright.
  ///
  /// Camera devices may either encode this value into the JPEG EXIF header, or
  /// rotate the image data to match this orientation. When the image data is rotated,
  /// the thumbnail data will also be rotated.
  ///
  /// Note that this orientation is relative to the orientation of the camera sensor, given
  /// by CameraCharacteristics\#SENSOR_ORIENTATION android.sensor.orientation.
  ///
  /// To translate from the device orientation given by the Android sensor APIs for camera
  /// sensors which are not EXTERNAL, the following sample code may be used:
  ///
  /// <pre><code>private int getJpegOrientation(CameraCharacteristics c, int deviceOrientation) {
  ///     if (deviceOrientation == android.view.OrientationEventListener.ORIENTATION_UNKNOWN) return 0;
  ///     int sensorOrientation = c.get(CameraCharacteristics.SENSOR_ORIENTATION);
  ///
  ///     // Round device orientation to a multiple of 90
  ///     deviceOrientation = (deviceOrientation + 45) / 90 * 90;
  ///
  ///     // Reverse device orientation for front-facing cameras
  ///     boolean facingFront = c.get(CameraCharacteristics.LENS_FACING) == CameraCharacteristics.LENS_FACING_FRONT;
  ///     if (facingFront) deviceOrientation = -deviceOrientation;
  ///
  ///     // Calculate desired JPEG orientation relative to camera orientation to make
  ///     // the image upright relative to the device orientation
  ///     int jpegOrientation = (sensorOrientation + deviceOrientation + 360) % 360;
  ///
  ///     return jpegOrientation;
  /// }
  /// </code></pre>
  /// For EXTERNAL cameras the sensor orientation will always be set to 0 and the facing will
  /// also be set to EXTERNAL. The above code is not relevant in such case.
  ///
  /// __Units__: Degrees in multiples of 90
  ///
  /// __Range of valid values:__<br>
  /// 0, 90, 180, 270
  ///
  /// This key is available on all devices.
  ///
  ///@see CameraCharacteristics\#SENSOR_ORIENTATION
  static CaptureResult_Key get JPEG_ORIENTATION =>
      CaptureResult_Key.fromRef(jniAccessors
          .getStaticField(
              _classRef, _id_JPEG_ORIENTATION, jni.JniType.objectType)
          .object);

  static final _id_JPEG_QUALITY = jniAccessors.getStaticFieldIDOf(_classRef,
      "JPEG_QUALITY", "Landroid/hardware/camera2/CaptureResult\$Key;");

  /// from: static public final android.hardware.camera2.CaptureResult.Key<java.lang.Byte> JPEG_QUALITY
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// Compression quality of the final JPEG
  /// image.
  ///
  /// 85-95 is typical usage range.
  ///
  /// __Range of valid values:__<br>
  /// 1-100; larger is higher quality
  ///
  /// This key is available on all devices.
  ///
  static CaptureResult_Key get JPEG_QUALITY =>
      CaptureResult_Key.fromRef(jniAccessors
          .getStaticField(_classRef, _id_JPEG_QUALITY, jni.JniType.objectType)
          .object);

  static final _id_JPEG_THUMBNAIL_QUALITY = jniAccessors.getStaticFieldIDOf(
      _classRef,
      "JPEG_THUMBNAIL_QUALITY",
      "Landroid/hardware/camera2/CaptureResult\$Key;");

  /// from: static public final android.hardware.camera2.CaptureResult.Key<java.lang.Byte> JPEG_THUMBNAIL_QUALITY
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// Compression quality of JPEG
  /// thumbnail.
  ///
  /// __Range of valid values:__<br>
  /// 1-100; larger is higher quality
  ///
  /// This key is available on all devices.
  ///
  static CaptureResult_Key get JPEG_THUMBNAIL_QUALITY =>
      CaptureResult_Key.fromRef(jniAccessors
          .getStaticField(
              _classRef, _id_JPEG_THUMBNAIL_QUALITY, jni.JniType.objectType)
          .object);

  static final _id_JPEG_THUMBNAIL_SIZE = jniAccessors.getStaticFieldIDOf(
      _classRef,
      "JPEG_THUMBNAIL_SIZE",
      "Landroid/hardware/camera2/CaptureResult\$Key;");

  /// from: static public final android.hardware.camera2.CaptureResult.Key<android.util.Size> JPEG_THUMBNAIL_SIZE
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// Resolution of embedded JPEG thumbnail.
  ///
  /// When set to (0, 0) value, the JPEG EXIF will not contain thumbnail,
  /// but the captured JPEG will still be a valid image.
  ///
  /// For best results, when issuing a request for a JPEG image, the thumbnail size selected
  /// should have the same aspect ratio as the main JPEG output.
  ///
  /// If the thumbnail image aspect ratio differs from the JPEG primary image aspect
  /// ratio, the camera device creates the thumbnail by cropping it from the primary image.
  /// For example, if the primary image has 4:3 aspect ratio, the thumbnail image has
  /// 16:9 aspect ratio, the primary image will be cropped vertically (letterbox) to
  /// generate the thumbnail image. The thumbnail image will always have a smaller Field
  /// Of View (FOV) than the primary image when aspect ratios differ.
  ///
  /// When an CaptureRequest\#JPEG_ORIENTATION android.jpeg.orientation of non-zero degree is requested,
  /// the camera device will handle thumbnail rotation in one of the following ways:
  ///
  /// <ul>
  /// <li>Set the android.media.ExifInterface\#TAG_ORIENTATION EXIF orientation flag
  ///   and keep jpeg and thumbnail image data unrotated.</li>
  /// <li>Rotate the jpeg and thumbnail image data and not set
  ///   android.media.ExifInterface\#TAG_ORIENTATION EXIF orientation flag. In this
  ///   case, LIMITED or FULL hardware level devices will report rotated thumnail size in
  ///   capture result, so the width and height will be interchanged if 90 or 270 degree
  ///   orientation is requested. LEGACY device will always report unrotated thumbnail
  ///   size.</li>
  /// </ul>
  /// __Range of valid values:__<br>
  /// CameraCharacteristics\#JPEG_AVAILABLE_THUMBNAIL_SIZES android.jpeg.availableThumbnailSizes
  ///
  /// This key is available on all devices.
  ///
  ///@see CameraCharacteristics\#JPEG_AVAILABLE_THUMBNAIL_SIZES
  ///@see CaptureRequest\#JPEG_ORIENTATION
  static CaptureResult_Key get JPEG_THUMBNAIL_SIZE =>
      CaptureResult_Key.fromRef(jniAccessors
          .getStaticField(
              _classRef, _id_JPEG_THUMBNAIL_SIZE, jni.JniType.objectType)
          .object);

  static final _id_LENS_APERTURE = jniAccessors.getStaticFieldIDOf(_classRef,
      "LENS_APERTURE", "Landroid/hardware/camera2/CaptureResult\$Key;");

  /// from: static public final android.hardware.camera2.CaptureResult.Key<java.lang.Float> LENS_APERTURE
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// The desired lens aperture size, as a ratio of lens focal length to the
  /// effective aperture diameter.
  ///
  /// Setting this value is only supported on the camera devices that have a variable
  /// aperture lens.
  ///
  /// When this is supported and CaptureRequest\#CONTROL_AE_MODE android.control.aeMode is OFF,
  /// this can be set along with CaptureRequest\#SENSOR_EXPOSURE_TIME android.sensor.exposureTime,
  /// CaptureRequest\#SENSOR_SENSITIVITY android.sensor.sensitivity, and CaptureRequest\#SENSOR_FRAME_DURATION android.sensor.frameDuration
  /// to achieve manual exposure control.
  ///
  /// The requested aperture value may take several frames to reach the
  /// requested value; the camera device will report the current (intermediate)
  /// aperture size in capture result metadata while the aperture is changing.
  /// While the aperture is still changing, CaptureResult\#LENS_STATE android.lens.state will be set to MOVING.
  ///
  /// When this is supported and CaptureRequest\#CONTROL_AE_MODE android.control.aeMode is one of
  /// the ON modes, this will be overridden by the camera device
  /// auto-exposure algorithm, the overridden values are then provided
  /// back to the user in the corresponding result.
  ///
  /// __Units__: The f-number (f/N)
  ///
  /// __Range of valid values:__<br>
  /// CameraCharacteristics\#LENS_INFO_AVAILABLE_APERTURES android.lens.info.availableApertures
  ///
  /// __Optional__ - This value may be {@code null} on some devices.
  ///
  /// __Full capability__ -
  /// Present on all camera devices that report being CameraCharacteristics\#INFO_SUPPORTED_HARDWARE_LEVEL_FULL HARDWARE_LEVEL_FULL devices in the
  /// CameraCharacteristics\#INFO_SUPPORTED_HARDWARE_LEVEL android.info.supportedHardwareLevel key
  ///
  ///@see CaptureRequest\#CONTROL_AE_MODE
  ///@see CameraCharacteristics\#INFO_SUPPORTED_HARDWARE_LEVEL
  ///@see CameraCharacteristics\#LENS_INFO_AVAILABLE_APERTURES
  ///@see CaptureResult\#LENS_STATE
  ///@see CaptureRequest\#SENSOR_EXPOSURE_TIME
  ///@see CaptureRequest\#SENSOR_FRAME_DURATION
  ///@see CaptureRequest\#SENSOR_SENSITIVITY
  static CaptureResult_Key get LENS_APERTURE =>
      CaptureResult_Key.fromRef(jniAccessors
          .getStaticField(_classRef, _id_LENS_APERTURE, jni.JniType.objectType)
          .object);

  static final _id_LENS_DISTORTION = jniAccessors.getStaticFieldIDOf(_classRef,
      "LENS_DISTORTION", "Landroid/hardware/camera2/CaptureResult\$Key;");

  /// from: static public final android.hardware.camera2.CaptureResult.Key<float[]> LENS_DISTORTION
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// The correction coefficients to correct for this camera device's
  /// radial and tangential lens distortion.
  ///
  /// Replaces the deprecated CameraCharacteristics\#LENS_RADIAL_DISTORTION android.lens.radialDistortion field, which was
  /// inconsistently defined.
  ///
  /// Three radial distortion coefficients <code>[kappa_1, kappa_2,
  /// kappa_3]</code> and two tangential distortion coefficients
  /// <code>[kappa_4, kappa_5]</code> that can be used to correct the
  /// lens's geometric distortion with the mapping equations:
  ///
  /// <pre><code> x_c = x_i * ( 1 + kappa_1 * r^2 + kappa_2 * r^4 + kappa_3 * r^6 ) +
  ///        kappa_4 * (2 * x_i * y_i) + kappa_5 * ( r^2 + 2 * x_i^2 )
  ///  y_c = y_i * ( 1 + kappa_1 * r^2 + kappa_2 * r^4 + kappa_3 * r^6 ) +
  ///        kappa_5 * (2 * x_i * y_i) + kappa_4 * ( r^2 + 2 * y_i^2 )
  /// </code></pre>
  /// Here, <code>[x_c, y_c]</code> are the coordinates to sample in the
  /// input image that correspond to the pixel values in the
  /// corrected image at the coordinate <code>[x_i, y_i]</code>:
  ///
  /// <pre><code> correctedImage(x_i, y_i) = sample_at(x_c, y_c, inputImage)
  /// </code></pre>
  /// The pixel coordinates are defined in a coordinate system
  /// related to the CameraCharacteristics\#LENS_INTRINSIC_CALIBRATION android.lens.intrinsicCalibration
  /// calibration fields; see that entry for details of the mapping stages.
  /// Both <code>[x_i, y_i]</code> and <code>[x_c, y_c]</code>
  /// have <code>(0,0)</code> at the lens optical center <code>[c_x, c_y]</code>, and
  /// the range of the coordinates depends on the focal length
  /// terms of the intrinsic calibration.
  ///
  /// Finally, <code>r</code> represents the radial distance from the
  /// optical center, <code>r^2 = x_i^2 + y_i^2</code>.
  ///
  /// The distortion model used is the Brown-Conrady model.
  ///
  /// __Units__:
  /// Unitless coefficients.
  ///
  /// __Optional__ - This value may be {@code null} on some devices.
  ///
  ///@see CameraCharacteristics\#LENS_INTRINSIC_CALIBRATION
  ///@see CameraCharacteristics\#LENS_RADIAL_DISTORTION
  static CaptureResult_Key get LENS_DISTORTION =>
      CaptureResult_Key.fromRef(jniAccessors
          .getStaticField(
              _classRef, _id_LENS_DISTORTION, jni.JniType.objectType)
          .object);

  static final _id_LENS_FILTER_DENSITY = jniAccessors.getStaticFieldIDOf(
      _classRef,
      "LENS_FILTER_DENSITY",
      "Landroid/hardware/camera2/CaptureResult\$Key;");

  /// from: static public final android.hardware.camera2.CaptureResult.Key<java.lang.Float> LENS_FILTER_DENSITY
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// The desired setting for the lens neutral density filter(s).
  ///
  /// This control will not be supported on most camera devices.
  ///
  /// Lens filters are typically used to lower the amount of light the
  /// sensor is exposed to (measured in steps of EV). As used here, an EV
  /// step is the standard logarithmic representation, which are
  /// non-negative, and inversely proportional to the amount of light
  /// hitting the sensor.  For example, setting this to 0 would result
  /// in no reduction of the incoming light, and setting this to 2 would
  /// mean that the filter is set to reduce incoming light by two stops
  /// (allowing 1/4 of the prior amount of light to the sensor).
  ///
  /// It may take several frames before the lens filter density changes
  /// to the requested value. While the filter density is still changing,
  /// CaptureResult\#LENS_STATE android.lens.state will be set to MOVING.
  ///
  /// __Units__: Exposure Value (EV)
  ///
  /// __Range of valid values:__<br>
  /// CameraCharacteristics\#LENS_INFO_AVAILABLE_FILTER_DENSITIES android.lens.info.availableFilterDensities
  ///
  /// __Optional__ - This value may be {@code null} on some devices.
  ///
  /// __Full capability__ -
  /// Present on all camera devices that report being CameraCharacteristics\#INFO_SUPPORTED_HARDWARE_LEVEL_FULL HARDWARE_LEVEL_FULL devices in the
  /// CameraCharacteristics\#INFO_SUPPORTED_HARDWARE_LEVEL android.info.supportedHardwareLevel key
  ///
  ///@see CameraCharacteristics\#INFO_SUPPORTED_HARDWARE_LEVEL
  ///@see CameraCharacteristics\#LENS_INFO_AVAILABLE_FILTER_DENSITIES
  ///@see CaptureResult\#LENS_STATE
  static CaptureResult_Key get LENS_FILTER_DENSITY =>
      CaptureResult_Key.fromRef(jniAccessors
          .getStaticField(
              _classRef, _id_LENS_FILTER_DENSITY, jni.JniType.objectType)
          .object);

  static final _id_LENS_FOCAL_LENGTH = jniAccessors.getStaticFieldIDOf(
      _classRef,
      "LENS_FOCAL_LENGTH",
      "Landroid/hardware/camera2/CaptureResult\$Key;");

  /// from: static public final android.hardware.camera2.CaptureResult.Key<java.lang.Float> LENS_FOCAL_LENGTH
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// The desired lens focal length; used for optical zoom.
  ///
  /// This setting controls the physical focal length of the camera
  /// device's lens. Changing the focal length changes the field of
  /// view of the camera device, and is usually used for optical zoom.
  ///
  /// Like CaptureRequest\#LENS_FOCUS_DISTANCE android.lens.focusDistance and CaptureRequest\#LENS_APERTURE android.lens.aperture, this
  /// setting won't be applied instantaneously, and it may take several
  /// frames before the lens can change to the requested focal length.
  /// While the focal length is still changing, CaptureResult\#LENS_STATE android.lens.state will
  /// be set to MOVING.
  ///
  /// Optical zoom will not be supported on most devices.
  ///
  /// __Units__: Millimeters
  ///
  /// __Range of valid values:__<br>
  /// CameraCharacteristics\#LENS_INFO_AVAILABLE_FOCAL_LENGTHS android.lens.info.availableFocalLengths
  ///
  /// This key is available on all devices.
  ///
  ///@see CaptureRequest\#LENS_APERTURE
  ///@see CaptureRequest\#LENS_FOCUS_DISTANCE
  ///@see CameraCharacteristics\#LENS_INFO_AVAILABLE_FOCAL_LENGTHS
  ///@see CaptureResult\#LENS_STATE
  static CaptureResult_Key get LENS_FOCAL_LENGTH =>
      CaptureResult_Key.fromRef(jniAccessors
          .getStaticField(
              _classRef, _id_LENS_FOCAL_LENGTH, jni.JniType.objectType)
          .object);

  static final _id_LENS_FOCUS_DISTANCE = jniAccessors.getStaticFieldIDOf(
      _classRef,
      "LENS_FOCUS_DISTANCE",
      "Landroid/hardware/camera2/CaptureResult\$Key;");

  /// from: static public final android.hardware.camera2.CaptureResult.Key<java.lang.Float> LENS_FOCUS_DISTANCE
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// Desired distance to plane of sharpest focus,
  /// measured from frontmost surface of the lens.
  ///
  /// Should be zero for fixed-focus cameras
  ///
  /// __Units__: See CameraCharacteristics\#LENS_INFO_FOCUS_DISTANCE_CALIBRATION android.lens.info.focusDistanceCalibration for details
  ///
  /// __Range of valid values:__<br>
  /// &gt;= 0
  ///
  /// __Optional__ - This value may be {@code null} on some devices.
  ///
  /// __Full capability__ -
  /// Present on all camera devices that report being CameraCharacteristics\#INFO_SUPPORTED_HARDWARE_LEVEL_FULL HARDWARE_LEVEL_FULL devices in the
  /// CameraCharacteristics\#INFO_SUPPORTED_HARDWARE_LEVEL android.info.supportedHardwareLevel key
  ///
  ///@see CameraCharacteristics\#INFO_SUPPORTED_HARDWARE_LEVEL
  ///@see CameraCharacteristics\#LENS_INFO_FOCUS_DISTANCE_CALIBRATION
  static CaptureResult_Key get LENS_FOCUS_DISTANCE =>
      CaptureResult_Key.fromRef(jniAccessors
          .getStaticField(
              _classRef, _id_LENS_FOCUS_DISTANCE, jni.JniType.objectType)
          .object);

  static final _id_LENS_FOCUS_RANGE = jniAccessors.getStaticFieldIDOf(_classRef,
      "LENS_FOCUS_RANGE", "Landroid/hardware/camera2/CaptureResult\$Key;");

  /// from: static public final android.hardware.camera2.CaptureResult.Key<android.util.Pair<java.lang.Float,java.lang.Float>> LENS_FOCUS_RANGE
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// The range of scene distances that are in
  /// sharp focus (depth of field).
  ///
  /// If variable focus not supported, can still report
  /// fixed depth of field range
  ///
  /// __Units__: A pair of focus distances in diopters: (near,
  /// far); see CameraCharacteristics\#LENS_INFO_FOCUS_DISTANCE_CALIBRATION android.lens.info.focusDistanceCalibration for details.
  ///
  /// __Range of valid values:__<br>
  /// &gt;=0
  ///
  /// __Optional__ - This value may be {@code null} on some devices.
  ///
  /// __Limited capability__ -
  /// Present on all camera devices that report being at least CameraCharacteristics\#INFO_SUPPORTED_HARDWARE_LEVEL_LIMITED HARDWARE_LEVEL_LIMITED devices in the
  /// CameraCharacteristics\#INFO_SUPPORTED_HARDWARE_LEVEL android.info.supportedHardwareLevel key
  ///
  ///@see CameraCharacteristics\#INFO_SUPPORTED_HARDWARE_LEVEL
  ///@see CameraCharacteristics\#LENS_INFO_FOCUS_DISTANCE_CALIBRATION
  static CaptureResult_Key get LENS_FOCUS_RANGE =>
      CaptureResult_Key.fromRef(jniAccessors
          .getStaticField(
              _classRef, _id_LENS_FOCUS_RANGE, jni.JniType.objectType)
          .object);

  static final _id_LENS_INTRINSIC_CALIBRATION = jniAccessors.getStaticFieldIDOf(
      _classRef,
      "LENS_INTRINSIC_CALIBRATION",
      "Landroid/hardware/camera2/CaptureResult\$Key;");

  /// from: static public final android.hardware.camera2.CaptureResult.Key<float[]> LENS_INTRINSIC_CALIBRATION
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// The parameters for this camera device's intrinsic
  /// calibration.
  ///
  /// The five calibration parameters that describe the
  /// transform from camera-centric 3D coordinates to sensor
  /// pixel coordinates:
  ///
  /// <pre><code>[f_x, f_y, c_x, c_y, s]
  /// </code></pre>
  /// Where <code>f_x</code> and <code>f_y</code> are the horizontal and vertical
  /// focal lengths, <code>[c_x, c_y]</code> is the position of the optical
  /// axis, and <code>s</code> is a skew parameter for the sensor plane not
  /// being aligned with the lens plane.
  ///
  /// These are typically used within a transformation matrix K:
  ///
  /// <pre><code>K = [ f_x,   s, c_x,
  ///        0, f_y, c_y,
  ///        0    0,   1 ]
  /// </code></pre>
  /// which can then be combined with the camera pose rotation
  /// <code>R</code> and translation <code>t</code> (CameraCharacteristics\#LENS_POSE_ROTATION android.lens.poseRotation and
  /// CameraCharacteristics\#LENS_POSE_TRANSLATION android.lens.poseTranslation, respective) to calculate the
  /// complete transform from world coordinates to pixel
  /// coordinates:
  ///
  /// <pre><code>P = [ K 0   * [ R t
  ///      0 1 ]     0 1 ]
  /// </code></pre>
  /// and with <code>p_w</code> being a point in the world coordinate system
  /// and <code>p_s</code> being a point in the camera active pixel array
  /// coordinate system, and with the mapping including the
  /// homogeneous division by z:
  ///
  /// <pre><code> p_h = (x_h, y_h, z_h) = P p_w
  /// p_s = p_h / z_h
  /// </code></pre>
  /// so <code>[x_s, y_s]</code> is the pixel coordinates of the world
  /// point, <code>z_s = 1</code>, and <code>w_s</code> is a measurement of disparity
  /// (depth) in pixel coordinates.
  ///
  /// Note that the coordinate system for this transform is the
  /// CameraCharacteristics\#SENSOR_INFO_PRE_CORRECTION_ACTIVE_ARRAY_SIZE android.sensor.info.preCorrectionActiveArraySize system,
  /// where <code>(0,0)</code> is the top-left of the
  /// preCorrectionActiveArraySize rectangle. Once the pose and
  /// intrinsic calibration transforms have been applied to a
  /// world point, then the CameraCharacteristics\#LENS_DISTORTION android.lens.distortion
  /// transform needs to be applied, and the result adjusted to
  /// be in the CameraCharacteristics\#SENSOR_INFO_ACTIVE_ARRAY_SIZE android.sensor.info.activeArraySize coordinate
  /// system (where <code>(0, 0)</code> is the top-left of the
  /// activeArraySize rectangle), to determine the final pixel
  /// coordinate of the world point for processed (non-RAW)
  /// output buffers.
  ///
  /// __Units__:
  /// Pixels in the
  /// CameraCharacteristics\#SENSOR_INFO_PRE_CORRECTION_ACTIVE_ARRAY_SIZE android.sensor.info.preCorrectionActiveArraySize
  /// coordinate system.
  ///
  /// __Optional__ - This value may be {@code null} on some devices.
  ///
  ///@see CameraCharacteristics\#LENS_DISTORTION
  ///@see CameraCharacteristics\#LENS_POSE_ROTATION
  ///@see CameraCharacteristics\#LENS_POSE_TRANSLATION
  ///@see CameraCharacteristics\#SENSOR_INFO_ACTIVE_ARRAY_SIZE
  ///@see CameraCharacteristics\#SENSOR_INFO_PRE_CORRECTION_ACTIVE_ARRAY_SIZE
  static CaptureResult_Key get LENS_INTRINSIC_CALIBRATION =>
      CaptureResult_Key.fromRef(jniAccessors
          .getStaticField(
              _classRef, _id_LENS_INTRINSIC_CALIBRATION, jni.JniType.objectType)
          .object);

  static final _id_LENS_OPTICAL_STABILIZATION_MODE =
      jniAccessors.getStaticFieldIDOf(
          _classRef,
          "LENS_OPTICAL_STABILIZATION_MODE",
          "Landroid/hardware/camera2/CaptureResult\$Key;");

  /// from: static public final android.hardware.camera2.CaptureResult.Key<java.lang.Integer> LENS_OPTICAL_STABILIZATION_MODE
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// Sets whether the camera device uses optical image stabilization (OIS)
  /// when capturing images.
  ///
  /// OIS is used to compensate for motion blur due to small
  /// movements of the camera during capture. Unlike digital image
  /// stabilization (CaptureRequest\#CONTROL_VIDEO_STABILIZATION_MODE android.control.videoStabilizationMode), OIS
  /// makes use of mechanical elements to stabilize the camera
  /// sensor, and thus allows for longer exposure times before
  /// camera shake becomes apparent.
  ///
  /// Switching between different optical stabilization modes may take several
  /// frames to initialize, the camera device will report the current mode in
  /// capture result metadata. For example, When "ON" mode is requested, the
  /// optical stabilization modes in the first several capture results may still
  /// be "OFF", and it will become "ON" when the initialization is done.
  ///
  /// If a camera device supports both OIS and digital image stabilization
  /// (CaptureRequest\#CONTROL_VIDEO_STABILIZATION_MODE android.control.videoStabilizationMode), turning both modes on may produce undesirable
  /// interaction, so it is recommended not to enable both at the same time.
  ///
  /// Not all devices will support OIS; see
  /// CameraCharacteristics\#LENS_INFO_AVAILABLE_OPTICAL_STABILIZATION android.lens.info.availableOpticalStabilization for
  /// available controls.
  ///
  /// __Possible values:__
  /// <ul>
  ///   <li>\#LENS_OPTICAL_STABILIZATION_MODE_OFF OFF</li>
  ///   <li>\#LENS_OPTICAL_STABILIZATION_MODE_ON ON</li>
  /// </ul>
  ///
  /// __Available values for this device:__<br>
  /// CameraCharacteristics\#LENS_INFO_AVAILABLE_OPTICAL_STABILIZATION android.lens.info.availableOpticalStabilization
  ///
  /// __Optional__ - This value may be {@code null} on some devices.
  ///
  /// __Limited capability__ -
  /// Present on all camera devices that report being at least CameraCharacteristics\#INFO_SUPPORTED_HARDWARE_LEVEL_LIMITED HARDWARE_LEVEL_LIMITED devices in the
  /// CameraCharacteristics\#INFO_SUPPORTED_HARDWARE_LEVEL android.info.supportedHardwareLevel key
  ///
  ///@see CaptureRequest\#CONTROL_VIDEO_STABILIZATION_MODE
  ///@see CameraCharacteristics\#INFO_SUPPORTED_HARDWARE_LEVEL
  ///@see CameraCharacteristics\#LENS_INFO_AVAILABLE_OPTICAL_STABILIZATION
  ///@see \#LENS_OPTICAL_STABILIZATION_MODE_OFF
  ///@see \#LENS_OPTICAL_STABILIZATION_MODE_ON
  static CaptureResult_Key get LENS_OPTICAL_STABILIZATION_MODE =>
      CaptureResult_Key.fromRef(jniAccessors
          .getStaticField(_classRef, _id_LENS_OPTICAL_STABILIZATION_MODE,
              jni.JniType.objectType)
          .object);

  static final _id_LENS_POSE_ROTATION = jniAccessors.getStaticFieldIDOf(
      _classRef,
      "LENS_POSE_ROTATION",
      "Landroid/hardware/camera2/CaptureResult\$Key;");

  /// from: static public final android.hardware.camera2.CaptureResult.Key<float[]> LENS_POSE_ROTATION
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// The orientation of the camera relative to the sensor
  /// coordinate system.
  ///
  /// The four coefficients that describe the quaternion
  /// rotation from the Android sensor coordinate system to a
  /// camera-aligned coordinate system where the X-axis is
  /// aligned with the long side of the image sensor, the Y-axis
  /// is aligned with the short side of the image sensor, and
  /// the Z-axis is aligned with the optical axis of the sensor.
  ///
  /// To convert from the quaternion coefficients <code>(x,y,z,w)</code>
  /// to the axis of rotation <code>(a_x, a_y, a_z)</code> and rotation
  /// amount <code>theta</code>, the following formulas can be used:
  ///
  /// <pre><code> theta = 2 * acos(w)
  /// a_x = x / sin(theta/2)
  /// a_y = y / sin(theta/2)
  /// a_z = z / sin(theta/2)
  /// </code></pre>
  /// To create a 3x3 rotation matrix that applies the rotation
  /// defined by this quaternion, the following matrix can be
  /// used:
  ///
  /// <pre><code>R = [ 1 - 2y^2 - 2z^2,       2xy - 2zw,       2xz + 2yw,
  ///            2xy + 2zw, 1 - 2x^2 - 2z^2,       2yz - 2xw,
  ///            2xz - 2yw,       2yz + 2xw, 1 - 2x^2 - 2y^2 ]
  /// </code></pre>
  /// This matrix can then be used to apply the rotation to a
  ///  column vector point with
  ///
  /// <code>p' = Rp</code>
  ///
  /// where <code>p</code> is in the device sensor coordinate system, and
  ///  <code>p'</code> is in the camera-oriented coordinate system.
  ///
  /// __Units__:
  /// Quaternion coefficients
  ///
  /// __Optional__ - This value may be {@code null} on some devices.
  ///
  static CaptureResult_Key get LENS_POSE_ROTATION =>
      CaptureResult_Key.fromRef(jniAccessors
          .getStaticField(
              _classRef, _id_LENS_POSE_ROTATION, jni.JniType.objectType)
          .object);

  static final _id_LENS_POSE_TRANSLATION = jniAccessors.getStaticFieldIDOf(
      _classRef,
      "LENS_POSE_TRANSLATION",
      "Landroid/hardware/camera2/CaptureResult\$Key;");

  /// from: static public final android.hardware.camera2.CaptureResult.Key<float[]> LENS_POSE_TRANSLATION
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// Position of the camera optical center.
  ///
  /// The position of the camera device's lens optical center,
  /// as a three-dimensional vector <code>(x,y,z)</code>.
  ///
  /// Prior to Android P, or when CameraCharacteristics\#LENS_POSE_REFERENCE android.lens.poseReference is PRIMARY_CAMERA, this position
  /// is relative to the optical center of the largest camera device facing in the same
  /// direction as this camera, in the android.hardware.SensorEvent Android sensor
  /// coordinate axes. Note that only the axis definitions are shared with the sensor
  /// coordinate system, but not the origin.
  ///
  /// If this device is the largest or only camera device with a given facing, then this
  /// position will be <code>(0, 0, 0)</code>; a camera device with a lens optical center located 3 cm
  /// from the main sensor along the +X axis (to the right from the user's perspective) will
  /// report <code>(0.03, 0, 0)</code>.
  ///
  /// To transform a pixel coordinates between two cameras facing the same direction, first
  /// the source camera CameraCharacteristics\#LENS_DISTORTION android.lens.distortion must be corrected for.  Then the source
  /// camera CameraCharacteristics\#LENS_INTRINSIC_CALIBRATION android.lens.intrinsicCalibration needs to be applied, followed by the
  /// CameraCharacteristics\#LENS_POSE_ROTATION android.lens.poseRotation of the source camera, the translation of the source camera
  /// relative to the destination camera, the CameraCharacteristics\#LENS_POSE_ROTATION android.lens.poseRotation of the destination
  /// camera, and finally the inverse of CameraCharacteristics\#LENS_INTRINSIC_CALIBRATION android.lens.intrinsicCalibration of the destination
  /// camera. This obtains a radial-distortion-free coordinate in the destination camera pixel
  /// coordinates.
  ///
  /// To compare this against a real image from the destination camera, the destination camera
  /// image then needs to be corrected for radial distortion before comparison or sampling.
  ///
  /// When CameraCharacteristics\#LENS_POSE_REFERENCE android.lens.poseReference is GYROSCOPE, then this position is relative to
  /// the center of the primary gyroscope on the device.
  ///
  /// __Units__: Meters
  ///
  /// __Optional__ - This value may be {@code null} on some devices.
  ///
  ///@see CameraCharacteristics\#LENS_DISTORTION
  ///@see CameraCharacteristics\#LENS_INTRINSIC_CALIBRATION
  ///@see CameraCharacteristics\#LENS_POSE_REFERENCE
  ///@see CameraCharacteristics\#LENS_POSE_ROTATION
  static CaptureResult_Key get LENS_POSE_TRANSLATION =>
      CaptureResult_Key.fromRef(jniAccessors
          .getStaticField(
              _classRef, _id_LENS_POSE_TRANSLATION, jni.JniType.objectType)
          .object);

  static final _id_LENS_RADIAL_DISTORTION = jniAccessors.getStaticFieldIDOf(
      _classRef,
      "LENS_RADIAL_DISTORTION",
      "Landroid/hardware/camera2/CaptureResult\$Key;");

  /// from: static public final android.hardware.camera2.CaptureResult.Key<float[]> LENS_RADIAL_DISTORTION
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// The correction coefficients to correct for this camera device's
  /// radial and tangential lens distortion.
  ///
  /// Four radial distortion coefficients <code>[kappa_0, kappa_1, kappa_2,
  /// kappa_3]</code> and two tangential distortion coefficients
  /// <code>[kappa_4, kappa_5]</code> that can be used to correct the
  /// lens's geometric distortion with the mapping equations:
  ///
  /// <pre><code> x_c = x_i * ( kappa_0 + kappa_1 * r^2 + kappa_2 * r^4 + kappa_3 * r^6 ) +
  ///        kappa_4 * (2 * x_i * y_i) + kappa_5 * ( r^2 + 2 * x_i^2 )
  ///  y_c = y_i * ( kappa_0 + kappa_1 * r^2 + kappa_2 * r^4 + kappa_3 * r^6 ) +
  ///        kappa_5 * (2 * x_i * y_i) + kappa_4 * ( r^2 + 2 * y_i^2 )
  /// </code></pre>
  /// Here, <code>[x_c, y_c]</code> are the coordinates to sample in the
  /// input image that correspond to the pixel values in the
  /// corrected image at the coordinate <code>[x_i, y_i]</code>:
  ///
  /// <pre><code> correctedImage(x_i, y_i) = sample_at(x_c, y_c, inputImage)
  /// </code></pre>
  /// The pixel coordinates are defined in a normalized
  /// coordinate system related to the
  /// CameraCharacteristics\#LENS_INTRINSIC_CALIBRATION android.lens.intrinsicCalibration calibration fields.
  /// Both <code>[x_i, y_i]</code> and <code>[x_c, y_c]</code> have <code>(0,0)</code> at the
  /// lens optical center <code>[c_x, c_y]</code>. The maximum magnitudes
  /// of both x and y coordinates are normalized to be 1 at the
  /// edge further from the optical center, so the range
  /// for both dimensions is <code>-1 &lt;= x &lt;= 1</code>.
  ///
  /// Finally, <code>r</code> represents the radial distance from the
  /// optical center, <code>r^2 = x_i^2 + y_i^2</code>, and its magnitude
  /// is therefore no larger than <code>|r| &lt;= sqrt(2)</code>.
  ///
  /// The distortion model used is the Brown-Conrady model.
  ///
  /// __Units__:
  /// Unitless coefficients.
  ///
  /// __Optional__ - This value may be {@code null} on some devices.
  ///
  ///@see CameraCharacteristics\#LENS_INTRINSIC_CALIBRATION
  ///@deprecated This field was inconsistently defined in terms of its
  /// normalization. Use CameraCharacteristics\#LENS_DISTORTION android.lens.distortion instead.
  ///
  ///@see CameraCharacteristics\#LENS_DISTORTION
  static CaptureResult_Key get LENS_RADIAL_DISTORTION =>
      CaptureResult_Key.fromRef(jniAccessors
          .getStaticField(
              _classRef, _id_LENS_RADIAL_DISTORTION, jni.JniType.objectType)
          .object);

  static final _id_LENS_STATE = jniAccessors.getStaticFieldIDOf(
      _classRef, "LENS_STATE", "Landroid/hardware/camera2/CaptureResult\$Key;");

  /// from: static public final android.hardware.camera2.CaptureResult.Key<java.lang.Integer> LENS_STATE
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// Current lens status.
  ///
  /// For lens parameters CaptureRequest\#LENS_FOCAL_LENGTH android.lens.focalLength, CaptureRequest\#LENS_FOCUS_DISTANCE android.lens.focusDistance,
  /// CaptureRequest\#LENS_FILTER_DENSITY android.lens.filterDensity and CaptureRequest\#LENS_APERTURE android.lens.aperture, when changes are requested,
  /// they may take several frames to reach the requested values. This state indicates
  /// the current status of the lens parameters.
  ///
  /// When the state is STATIONARY, the lens parameters are not changing. This could be
  /// either because the parameters are all fixed, or because the lens has had enough
  /// time to reach the most recently-requested values.
  /// If all these lens parameters are not changable for a camera device, as listed below:
  ///
  /// <ul>
  /// <li>Fixed focus (<code>CameraCharacteristics\#LENS_INFO_MINIMUM_FOCUS_DISTANCE android.lens.info.minimumFocusDistance == 0</code>), which means
  /// CaptureRequest\#LENS_FOCUS_DISTANCE android.lens.focusDistance parameter will always be 0.</li>
  /// <li>Fixed focal length (CameraCharacteristics\#LENS_INFO_AVAILABLE_FOCAL_LENGTHS android.lens.info.availableFocalLengths contains single value),
  /// which means the optical zoom is not supported.</li>
  /// <li>No ND filter (CameraCharacteristics\#LENS_INFO_AVAILABLE_FILTER_DENSITIES android.lens.info.availableFilterDensities contains only 0).</li>
  /// <li>Fixed aperture (CameraCharacteristics\#LENS_INFO_AVAILABLE_APERTURES android.lens.info.availableApertures contains single value).</li>
  /// </ul>
  /// Then this state will always be STATIONARY.
  ///
  /// When the state is MOVING, it indicates that at least one of the lens parameters
  /// is changing.
  ///
  /// __Possible values:__
  /// <ul>
  ///   <li>\#LENS_STATE_STATIONARY STATIONARY</li>
  ///   <li>\#LENS_STATE_MOVING MOVING</li>
  /// </ul>
  ///
  /// __Optional__ - This value may be {@code null} on some devices.
  ///
  /// __Limited capability__ -
  /// Present on all camera devices that report being at least CameraCharacteristics\#INFO_SUPPORTED_HARDWARE_LEVEL_LIMITED HARDWARE_LEVEL_LIMITED devices in the
  /// CameraCharacteristics\#INFO_SUPPORTED_HARDWARE_LEVEL android.info.supportedHardwareLevel key
  ///
  ///@see CameraCharacteristics\#INFO_SUPPORTED_HARDWARE_LEVEL
  ///@see CaptureRequest\#LENS_APERTURE
  ///@see CaptureRequest\#LENS_FILTER_DENSITY
  ///@see CaptureRequest\#LENS_FOCAL_LENGTH
  ///@see CaptureRequest\#LENS_FOCUS_DISTANCE
  ///@see CameraCharacteristics\#LENS_INFO_AVAILABLE_APERTURES
  ///@see CameraCharacteristics\#LENS_INFO_AVAILABLE_FILTER_DENSITIES
  ///@see CameraCharacteristics\#LENS_INFO_AVAILABLE_FOCAL_LENGTHS
  ///@see CameraCharacteristics\#LENS_INFO_MINIMUM_FOCUS_DISTANCE
  ///@see \#LENS_STATE_STATIONARY
  ///@see \#LENS_STATE_MOVING
  static CaptureResult_Key get LENS_STATE =>
      CaptureResult_Key.fromRef(jniAccessors
          .getStaticField(_classRef, _id_LENS_STATE, jni.JniType.objectType)
          .object);

  static final _id_NOISE_REDUCTION_MODE = jniAccessors.getStaticFieldIDOf(
      _classRef,
      "NOISE_REDUCTION_MODE",
      "Landroid/hardware/camera2/CaptureResult\$Key;");

  /// from: static public final android.hardware.camera2.CaptureResult.Key<java.lang.Integer> NOISE_REDUCTION_MODE
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// Mode of operation for the noise reduction algorithm.
  ///
  /// The noise reduction algorithm attempts to improve image quality by removing
  /// excessive noise added by the capture process, especially in dark conditions.
  ///
  /// OFF means no noise reduction will be applied by the camera device, for both raw and
  /// YUV domain.
  ///
  /// MINIMAL means that only sensor raw domain basic noise reduction is enabled ,to remove
  /// demosaicing or other processing artifacts. For YUV_REPROCESSING, MINIMAL is same as OFF.
  /// This mode is optional, may not be support by all devices. The application should check
  /// CameraCharacteristics\#NOISE_REDUCTION_AVAILABLE_NOISE_REDUCTION_MODES android.noiseReduction.availableNoiseReductionModes before using it.
  ///
  /// FAST/HIGH_QUALITY both mean camera device determined noise filtering
  /// will be applied. HIGH_QUALITY mode indicates that the camera device
  /// will use the highest-quality noise filtering algorithms,
  /// even if it slows down capture rate. FAST means the camera device will not
  /// slow down capture rate when applying noise filtering. FAST may be the same as MINIMAL if
  /// MINIMAL is listed, or the same as OFF if any noise filtering will slow down capture rate.
  /// Every output stream will have a similar amount of enhancement applied.
  ///
  /// ZERO_SHUTTER_LAG is meant to be used by applications that maintain a continuous circular
  /// buffer of high-resolution images during preview and reprocess image(s) from that buffer
  /// into a final capture when triggered by the user. In this mode, the camera device applies
  /// noise reduction to low-resolution streams (below maximum recording resolution) to maximize
  /// preview quality, but does not apply noise reduction to high-resolution streams, since
  /// those will be reprocessed later if necessary.
  ///
  /// For YUV_REPROCESSING, these FAST/HIGH_QUALITY modes both mean that the camera device
  /// will apply FAST/HIGH_QUALITY YUV domain noise reduction, respectively. The camera device
  /// may adjust the noise reduction parameters for best image quality based on the
  /// CaptureRequest\#REPROCESS_EFFECTIVE_EXPOSURE_FACTOR android.reprocess.effectiveExposureFactor if it is set.
  ///
  /// __Possible values:__
  /// <ul>
  ///   <li>\#NOISE_REDUCTION_MODE_OFF OFF</li>
  ///   <li>\#NOISE_REDUCTION_MODE_FAST FAST</li>
  ///   <li>\#NOISE_REDUCTION_MODE_HIGH_QUALITY HIGH_QUALITY</li>
  ///   <li>\#NOISE_REDUCTION_MODE_MINIMAL MINIMAL</li>
  ///   <li>\#NOISE_REDUCTION_MODE_ZERO_SHUTTER_LAG ZERO_SHUTTER_LAG</li>
  /// </ul>
  ///
  /// __Available values for this device:__<br>
  /// CameraCharacteristics\#NOISE_REDUCTION_AVAILABLE_NOISE_REDUCTION_MODES android.noiseReduction.availableNoiseReductionModes
  ///
  /// __Optional__ - This value may be {@code null} on some devices.
  ///
  /// __Full capability__ -
  /// Present on all camera devices that report being CameraCharacteristics\#INFO_SUPPORTED_HARDWARE_LEVEL_FULL HARDWARE_LEVEL_FULL devices in the
  /// CameraCharacteristics\#INFO_SUPPORTED_HARDWARE_LEVEL android.info.supportedHardwareLevel key
  ///
  ///@see CameraCharacteristics\#INFO_SUPPORTED_HARDWARE_LEVEL
  ///@see CameraCharacteristics\#NOISE_REDUCTION_AVAILABLE_NOISE_REDUCTION_MODES
  ///@see CaptureRequest\#REPROCESS_EFFECTIVE_EXPOSURE_FACTOR
  ///@see \#NOISE_REDUCTION_MODE_OFF
  ///@see \#NOISE_REDUCTION_MODE_FAST
  ///@see \#NOISE_REDUCTION_MODE_HIGH_QUALITY
  ///@see \#NOISE_REDUCTION_MODE_MINIMAL
  ///@see \#NOISE_REDUCTION_MODE_ZERO_SHUTTER_LAG
  static CaptureResult_Key get NOISE_REDUCTION_MODE =>
      CaptureResult_Key.fromRef(jniAccessors
          .getStaticField(
              _classRef, _id_NOISE_REDUCTION_MODE, jni.JniType.objectType)
          .object);

  static final _id_REPROCESS_EFFECTIVE_EXPOSURE_FACTOR =
      jniAccessors.getStaticFieldIDOf(
          _classRef,
          "REPROCESS_EFFECTIVE_EXPOSURE_FACTOR",
          "Landroid/hardware/camera2/CaptureResult\$Key;");

  /// from: static public final android.hardware.camera2.CaptureResult.Key<java.lang.Float> REPROCESS_EFFECTIVE_EXPOSURE_FACTOR
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// The amount of exposure time increase factor applied to the original output
  /// frame by the application processing before sending for reprocessing.
  ///
  /// This is optional, and will be supported if the camera device supports YUV_REPROCESSING
  /// capability (CameraCharacteristics\#REQUEST_AVAILABLE_CAPABILITIES android.request.availableCapabilities contains YUV_REPROCESSING).
  ///
  /// For some YUV reprocessing use cases, the application may choose to filter the original
  /// output frames to effectively reduce the noise to the same level as a frame that was
  /// captured with longer exposure time. To be more specific, assuming the original captured
  /// images were captured with a sensitivity of S and an exposure time of T, the model in
  /// the camera device is that the amount of noise in the image would be approximately what
  /// would be expected if the original capture parameters had been a sensitivity of
  /// S/effectiveExposureFactor and an exposure time of T*effectiveExposureFactor, rather
  /// than S and T respectively. If the captured images were processed by the application
  /// before being sent for reprocessing, then the application may have used image processing
  /// algorithms and/or multi-frame image fusion to reduce the noise in the
  /// application-processed images (input images). By using the effectiveExposureFactor
  /// control, the application can communicate to the camera device the actual noise level
  /// improvement in the application-processed image. With this information, the camera
  /// device can select appropriate noise reduction and edge enhancement parameters to avoid
  /// excessive noise reduction (CaptureRequest\#NOISE_REDUCTION_MODE android.noiseReduction.mode) and insufficient edge
  /// enhancement (CaptureRequest\#EDGE_MODE android.edge.mode) being applied to the reprocessed frames.
  ///
  /// For example, for multi-frame image fusion use case, the application may fuse
  /// multiple output frames together to a final frame for reprocessing. When N image are
  /// fused into 1 image for reprocessing, the exposure time increase factor could be up to
  /// square root of N (based on a simple photon shot noise model). The camera device will
  /// adjust the reprocessing noise reduction and edge enhancement parameters accordingly to
  /// produce the best quality images.
  ///
  /// This is relative factor, 1.0 indicates the application hasn't processed the input
  /// buffer in a way that affects its effective exposure time.
  ///
  /// This control is only effective for YUV reprocessing capture request. For noise
  /// reduction reprocessing, it is only effective when <code>CaptureRequest\#NOISE_REDUCTION_MODE android.noiseReduction.mode != OFF</code>.
  /// Similarly, for edge enhancement reprocessing, it is only effective when
  /// <code>CaptureRequest\#EDGE_MODE android.edge.mode != OFF</code>.
  ///
  /// __Units__: Relative exposure time increase factor.
  ///
  /// __Range of valid values:__<br>
  /// &gt;= 1.0
  ///
  /// __Optional__ - This value may be {@code null} on some devices.
  ///
  /// __Limited capability__ -
  /// Present on all camera devices that report being at least CameraCharacteristics\#INFO_SUPPORTED_HARDWARE_LEVEL_LIMITED HARDWARE_LEVEL_LIMITED devices in the
  /// CameraCharacteristics\#INFO_SUPPORTED_HARDWARE_LEVEL android.info.supportedHardwareLevel key
  ///
  ///@see CaptureRequest\#EDGE_MODE
  ///@see CameraCharacteristics\#INFO_SUPPORTED_HARDWARE_LEVEL
  ///@see CaptureRequest\#NOISE_REDUCTION_MODE
  ///@see CameraCharacteristics\#REQUEST_AVAILABLE_CAPABILITIES
  static CaptureResult_Key get REPROCESS_EFFECTIVE_EXPOSURE_FACTOR =>
      CaptureResult_Key.fromRef(jniAccessors
          .getStaticField(_classRef, _id_REPROCESS_EFFECTIVE_EXPOSURE_FACTOR,
              jni.JniType.objectType)
          .object);

  static final _id_REQUEST_PIPELINE_DEPTH = jniAccessors.getStaticFieldIDOf(
      _classRef,
      "REQUEST_PIPELINE_DEPTH",
      "Landroid/hardware/camera2/CaptureResult\$Key;");

  /// from: static public final android.hardware.camera2.CaptureResult.Key<java.lang.Byte> REQUEST_PIPELINE_DEPTH
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// Specifies the number of pipeline stages the frame went
  /// through from when it was exposed to when the final completed result
  /// was available to the framework.
  ///
  /// Depending on what settings are used in the request, and
  /// what streams are configured, the data may undergo less processing,
  /// and some pipeline stages skipped.
  ///
  /// See CameraCharacteristics\#REQUEST_PIPELINE_MAX_DEPTH android.request.pipelineMaxDepth for more details.
  ///
  /// __Range of valid values:__<br>
  /// &lt;= CameraCharacteristics\#REQUEST_PIPELINE_MAX_DEPTH android.request.pipelineMaxDepth
  ///
  /// This key is available on all devices.
  ///
  ///@see CameraCharacteristics\#REQUEST_PIPELINE_MAX_DEPTH
  static CaptureResult_Key get REQUEST_PIPELINE_DEPTH =>
      CaptureResult_Key.fromRef(jniAccessors
          .getStaticField(
              _classRef, _id_REQUEST_PIPELINE_DEPTH, jni.JniType.objectType)
          .object);

  static final _id_SCALER_CROP_REGION = jniAccessors.getStaticFieldIDOf(
      _classRef,
      "SCALER_CROP_REGION",
      "Landroid/hardware/camera2/CaptureResult\$Key;");

  /// from: static public final android.hardware.camera2.CaptureResult.Key<android.graphics.Rect> SCALER_CROP_REGION
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// The desired region of the sensor to read out for this capture.
  ///
  /// This control can be used to implement digital zoom.
  ///
  /// For devices not supporting CaptureRequest\#DISTORTION_CORRECTION_MODE android.distortionCorrection.mode control, the coordinate
  /// system always follows that of CameraCharacteristics\#SENSOR_INFO_ACTIVE_ARRAY_SIZE android.sensor.info.activeArraySize, with <code>(0, 0)</code> being
  /// the top-left pixel of the active array.
  ///
  /// For devices supporting CaptureRequest\#DISTORTION_CORRECTION_MODE android.distortionCorrection.mode control, the coordinate
  /// system depends on the mode being set.
  /// When the distortion correction mode is OFF, the coordinate system follows
  /// CameraCharacteristics\#SENSOR_INFO_PRE_CORRECTION_ACTIVE_ARRAY_SIZE android.sensor.info.preCorrectionActiveArraySize, with
  /// <code>(0, 0)</code> being the top-left pixel of the pre-correction active array.
  /// When the distortion correction mode is not OFF, the coordinate system follows
  /// CameraCharacteristics\#SENSOR_INFO_ACTIVE_ARRAY_SIZE android.sensor.info.activeArraySize, with
  /// <code>(0, 0)</code> being the top-left pixel of the active array.
  ///
  /// Output streams use this rectangle to produce their output,
  /// cropping to a smaller region if necessary to maintain the
  /// stream's aspect ratio, then scaling the sensor input to
  /// match the output's configured resolution.
  ///
  /// The crop region is applied after the RAW to other color
  /// space (e.g. YUV) conversion. Since raw streams
  /// (e.g. RAW16) don't have the conversion stage, they are not
  /// croppable. The crop region will be ignored by raw streams.
  ///
  /// For non-raw streams, any additional per-stream cropping will
  /// be done to maximize the final pixel area of the stream.
  ///
  /// For example, if the crop region is set to a 4:3 aspect
  /// ratio, then 4:3 streams will use the exact crop
  /// region. 16:9 streams will further crop vertically
  /// (letterbox).
  ///
  /// Conversely, if the crop region is set to a 16:9, then 4:3
  /// outputs will crop horizontally (pillarbox), and 16:9
  /// streams will match exactly. These additional crops will
  /// be centered within the crop region.
  ///
  /// If the coordinate system is android.sensor.info.activeArraysSize, the width and height
  /// of the crop region cannot be set to be smaller than
  /// <code>floor( activeArraySize.width / CameraCharacteristics\#SCALER_AVAILABLE_MAX_DIGITAL_ZOOM android.scaler.availableMaxDigitalZoom )</code> and
  /// <code>floor( activeArraySize.height / CameraCharacteristics\#SCALER_AVAILABLE_MAX_DIGITAL_ZOOM android.scaler.availableMaxDigitalZoom )</code>, respectively.
  ///
  /// If the coordinate system is CameraCharacteristics\#SENSOR_INFO_PRE_CORRECTION_ACTIVE_ARRAY_SIZE android.sensor.info.preCorrectionActiveArraySize, the width
  /// and height of the crop region cannot be set to be smaller than
  /// <code>floor( preCorrectionActiveArraySize.width / CameraCharacteristics\#SCALER_AVAILABLE_MAX_DIGITAL_ZOOM android.scaler.availableMaxDigitalZoom )</code>
  /// and
  /// <code>floor( preCorrectionActiveArraySize.height / CameraCharacteristics\#SCALER_AVAILABLE_MAX_DIGITAL_ZOOM android.scaler.availableMaxDigitalZoom )</code>,
  /// respectively.
  ///
  /// The camera device may adjust the crop region to account
  /// for rounding and other hardware requirements; the final
  /// crop region used will be included in the output capture
  /// result.
  ///
  /// __Units__: Pixel coordinates relative to
  /// CameraCharacteristics\#SENSOR_INFO_ACTIVE_ARRAY_SIZE android.sensor.info.activeArraySize or
  /// CameraCharacteristics\#SENSOR_INFO_PRE_CORRECTION_ACTIVE_ARRAY_SIZE android.sensor.info.preCorrectionActiveArraySize depending on distortion correction
  /// capability and mode
  ///
  /// This key is available on all devices.
  ///
  ///@see CaptureRequest\#DISTORTION_CORRECTION_MODE
  ///@see CameraCharacteristics\#SCALER_AVAILABLE_MAX_DIGITAL_ZOOM
  ///@see CameraCharacteristics\#SENSOR_INFO_ACTIVE_ARRAY_SIZE
  ///@see CameraCharacteristics\#SENSOR_INFO_PRE_CORRECTION_ACTIVE_ARRAY_SIZE
  static CaptureResult_Key get SCALER_CROP_REGION =>
      CaptureResult_Key.fromRef(jniAccessors
          .getStaticField(
              _classRef, _id_SCALER_CROP_REGION, jni.JniType.objectType)
          .object);

  static final _id_SENSOR_DYNAMIC_BLACK_LEVEL = jniAccessors.getStaticFieldIDOf(
      _classRef,
      "SENSOR_DYNAMIC_BLACK_LEVEL",
      "Landroid/hardware/camera2/CaptureResult\$Key;");

  /// from: static public final android.hardware.camera2.CaptureResult.Key<float[]> SENSOR_DYNAMIC_BLACK_LEVEL
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// A per-frame dynamic black level offset for each of the color filter
  /// arrangement (CFA) mosaic channels.
  ///
  /// Camera sensor black levels may vary dramatically for different
  /// capture settings (e.g. CaptureRequest\#SENSOR_SENSITIVITY android.sensor.sensitivity). The fixed black
  /// level reported by CameraCharacteristics\#SENSOR_BLACK_LEVEL_PATTERN android.sensor.blackLevelPattern may be too
  /// inaccurate to represent the actual value on a per-frame basis. The
  /// camera device internal pipeline relies on reliable black level values
  /// to process the raw images appropriately. To get the best image
  /// quality, the camera device may choose to estimate the per frame black
  /// level values either based on optically shielded black regions
  /// (CameraCharacteristics\#SENSOR_OPTICAL_BLACK_REGIONS android.sensor.opticalBlackRegions) or its internal model.
  ///
  /// This key reports the camera device estimated per-frame zero light
  /// value for each of the CFA mosaic channels in the camera sensor. The
  /// CameraCharacteristics\#SENSOR_BLACK_LEVEL_PATTERN android.sensor.blackLevelPattern may only represent a coarse
  /// approximation of the actual black level values. This value is the
  /// black level used in camera device internal image processing pipeline
  /// and generally more accurate than the fixed black level values.
  /// However, since they are estimated values by the camera device, they
  /// may not be as accurate as the black level values calculated from the
  /// optical black pixels reported by CameraCharacteristics\#SENSOR_OPTICAL_BLACK_REGIONS android.sensor.opticalBlackRegions.
  ///
  /// The values are given in the same order as channels listed for the CFA
  /// layout key (see CameraCharacteristics\#SENSOR_INFO_COLOR_FILTER_ARRANGEMENT android.sensor.info.colorFilterArrangement), i.e. the
  /// nth value given corresponds to the black level offset for the nth
  /// color channel listed in the CFA.
  ///
  /// This key will be available if CameraCharacteristics\#SENSOR_OPTICAL_BLACK_REGIONS android.sensor.opticalBlackRegions is available or the
  /// camera device advertises this key via android.hardware.camera2.CameraCharacteristics\#getAvailableCaptureResultKeys.
  ///
  /// __Range of valid values:__<br>
  /// &gt;= 0 for each.
  ///
  /// __Optional__ - This value may be {@code null} on some devices.
  ///
  ///@see CameraCharacteristics\#SENSOR_BLACK_LEVEL_PATTERN
  ///@see CameraCharacteristics\#SENSOR_INFO_COLOR_FILTER_ARRANGEMENT
  ///@see CameraCharacteristics\#SENSOR_OPTICAL_BLACK_REGIONS
  ///@see CaptureRequest\#SENSOR_SENSITIVITY
  static CaptureResult_Key get SENSOR_DYNAMIC_BLACK_LEVEL =>
      CaptureResult_Key.fromRef(jniAccessors
          .getStaticField(
              _classRef, _id_SENSOR_DYNAMIC_BLACK_LEVEL, jni.JniType.objectType)
          .object);

  static final _id_SENSOR_DYNAMIC_WHITE_LEVEL = jniAccessors.getStaticFieldIDOf(
      _classRef,
      "SENSOR_DYNAMIC_WHITE_LEVEL",
      "Landroid/hardware/camera2/CaptureResult\$Key;");

  /// from: static public final android.hardware.camera2.CaptureResult.Key<java.lang.Integer> SENSOR_DYNAMIC_WHITE_LEVEL
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// Maximum raw value output by sensor for this frame.
  ///
  /// Since the CameraCharacteristics\#SENSOR_BLACK_LEVEL_PATTERN android.sensor.blackLevelPattern may change for different
  /// capture settings (e.g., CaptureRequest\#SENSOR_SENSITIVITY android.sensor.sensitivity), the white
  /// level will change accordingly. This key is similar to
  /// CameraCharacteristics\#SENSOR_INFO_WHITE_LEVEL android.sensor.info.whiteLevel, but specifies the camera device
  /// estimated white level for each frame.
  ///
  /// This key will be available if CameraCharacteristics\#SENSOR_OPTICAL_BLACK_REGIONS android.sensor.opticalBlackRegions is
  /// available or the camera device advertises this key via
  /// android.hardware.camera2.CameraCharacteristics\#getAvailableCaptureRequestKeys.
  ///
  /// __Range of valid values:__<br>
  /// &gt;= 0
  ///
  /// __Optional__ - This value may be {@code null} on some devices.
  ///
  ///@see CameraCharacteristics\#SENSOR_BLACK_LEVEL_PATTERN
  ///@see CameraCharacteristics\#SENSOR_INFO_WHITE_LEVEL
  ///@see CameraCharacteristics\#SENSOR_OPTICAL_BLACK_REGIONS
  ///@see CaptureRequest\#SENSOR_SENSITIVITY
  static CaptureResult_Key get SENSOR_DYNAMIC_WHITE_LEVEL =>
      CaptureResult_Key.fromRef(jniAccessors
          .getStaticField(
              _classRef, _id_SENSOR_DYNAMIC_WHITE_LEVEL, jni.JniType.objectType)
          .object);

  static final _id_SENSOR_EXPOSURE_TIME = jniAccessors.getStaticFieldIDOf(
      _classRef,
      "SENSOR_EXPOSURE_TIME",
      "Landroid/hardware/camera2/CaptureResult\$Key;");

  /// from: static public final android.hardware.camera2.CaptureResult.Key<java.lang.Long> SENSOR_EXPOSURE_TIME
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// Duration each pixel is exposed to
  /// light.
  ///
  /// If the sensor can't expose this exact duration, it will shorten the
  /// duration exposed to the nearest possible value (rather than expose longer).
  /// The final exposure time used will be available in the output capture result.
  ///
  /// This control is only effective if CaptureRequest\#CONTROL_AE_MODE android.control.aeMode or CaptureRequest\#CONTROL_MODE android.control.mode is set to
  /// OFF; otherwise the auto-exposure algorithm will override this value.
  ///
  /// __Units__: Nanoseconds
  ///
  /// __Range of valid values:__<br>
  /// CameraCharacteristics\#SENSOR_INFO_EXPOSURE_TIME_RANGE android.sensor.info.exposureTimeRange
  ///
  /// __Optional__ - This value may be {@code null} on some devices.
  ///
  /// __Full capability__ -
  /// Present on all camera devices that report being CameraCharacteristics\#INFO_SUPPORTED_HARDWARE_LEVEL_FULL HARDWARE_LEVEL_FULL devices in the
  /// CameraCharacteristics\#INFO_SUPPORTED_HARDWARE_LEVEL android.info.supportedHardwareLevel key
  ///
  ///@see CaptureRequest\#CONTROL_AE_MODE
  ///@see CaptureRequest\#CONTROL_MODE
  ///@see CameraCharacteristics\#INFO_SUPPORTED_HARDWARE_LEVEL
  ///@see CameraCharacteristics\#SENSOR_INFO_EXPOSURE_TIME_RANGE
  static CaptureResult_Key get SENSOR_EXPOSURE_TIME =>
      CaptureResult_Key.fromRef(jniAccessors
          .getStaticField(
              _classRef, _id_SENSOR_EXPOSURE_TIME, jni.JniType.objectType)
          .object);

  static final _id_SENSOR_FRAME_DURATION = jniAccessors.getStaticFieldIDOf(
      _classRef,
      "SENSOR_FRAME_DURATION",
      "Landroid/hardware/camera2/CaptureResult\$Key;");

  /// from: static public final android.hardware.camera2.CaptureResult.Key<java.lang.Long> SENSOR_FRAME_DURATION
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// Duration from start of frame exposure to
  /// start of next frame exposure.
  ///
  /// The maximum frame rate that can be supported by a camera subsystem is
  /// a function of many factors:
  ///
  /// <ul>
  /// <li>Requested resolutions of output image streams</li>
  /// <li>Availability of binning / skipping modes on the imager</li>
  /// <li>The bandwidth of the imager interface</li>
  /// <li>The bandwidth of the various ISP processing blocks</li>
  /// </ul>
  /// Since these factors can vary greatly between different ISPs and
  /// sensors, the camera abstraction tries to represent the bandwidth
  /// restrictions with as simple a model as possible.
  ///
  /// The model presented has the following characteristics:
  ///
  /// <ul>
  /// <li>The image sensor is always configured to output the smallest
  /// resolution possible given the application's requested output stream
  /// sizes.  The smallest resolution is defined as being at least as large
  /// as the largest requested output stream size; the camera pipeline must
  /// never digitally upsample sensor data when the crop region covers the
  /// whole sensor. In general, this means that if only small output stream
  /// resolutions are configured, the sensor can provide a higher frame
  /// rate.</li>
  /// <li>Since any request may use any or all the currently configured
  /// output streams, the sensor and ISP must be configured to support
  /// scaling a single capture to all the streams at the same time.  This
  /// means the camera pipeline must be ready to produce the largest
  /// requested output size without any delay.  Therefore, the overall
  /// frame rate of a given configured stream set is governed only by the
  /// largest requested stream resolution.</li>
  /// <li>Using more than one output stream in a request does not affect the
  /// frame duration.</li>
  /// <li>Certain format-streams may need to do additional background processing
  /// before data is consumed/produced by that stream. These processors
  /// can run concurrently to the rest of the camera pipeline, but
  /// cannot process more than 1 capture at a time.</li>
  /// </ul>
  /// The necessary information for the application, given the model above, is provided via
  /// android.hardware.camera2.params.StreamConfigurationMap\#getOutputMinFrameDuration.
  /// These are used to determine the maximum frame rate / minimum frame duration that is
  /// possible for a given stream configuration.
  ///
  /// Specifically, the application can use the following rules to
  /// determine the minimum frame duration it can request from the camera
  /// device:
  ///
  /// <ol>
  /// <li>Let the set of currently configured input/output streams be called <code>S</code>.</li>
  /// <li>Find the minimum frame durations for each stream in <code>S</code>, by looking it up in android.hardware.camera2.params.StreamConfigurationMap\#getOutputMinFrameDuration
  /// (with its respective size/format). Let this set of frame durations be called <code>F</code>.</li>
  /// <li>For any given request <code>R</code>, the minimum frame duration allowed for <code>R</code> is the maximum
  /// out of all values in <code>F</code>. Let the streams used in <code>R</code> be called <code>S_r</code>.</li>
  /// </ol>
  /// If none of the streams in <code>S_r</code> have a stall time (listed in android.hardware.camera2.params.StreamConfigurationMap\#getOutputStallDuration
  /// using its respective size/format), then the frame duration in <code>F</code> determines the steady
  /// state frame rate that the application will get if it uses <code>R</code> as a repeating request. Let
  /// this special kind of request be called <code>Rsimple</code>.
  ///
  /// A repeating request <code>Rsimple</code> can be _occasionally_ interleaved by a single capture of a
  /// new request <code>Rstall</code> (which has at least one in-use stream with a non-0 stall time) and if
  /// <code>Rstall</code> has the same minimum frame duration this will not cause a frame rate loss if all
  /// buffers from the previous <code>Rstall</code> have already been delivered.
  ///
  /// For more details about stalling, see android.hardware.camera2.params.StreamConfigurationMap\#getOutputStallDuration.
  ///
  /// This control is only effective if CaptureRequest\#CONTROL_AE_MODE android.control.aeMode or CaptureRequest\#CONTROL_MODE android.control.mode is set to
  /// OFF; otherwise the auto-exposure algorithm will override this value.
  ///
  /// __Units__: Nanoseconds
  ///
  /// __Range of valid values:__<br>
  /// See CameraCharacteristics\#SENSOR_INFO_MAX_FRAME_DURATION android.sensor.info.maxFrameDuration, android.hardware.camera2.params.StreamConfigurationMap.
  /// The duration is capped to <code>max(duration, exposureTime + overhead)</code>.
  ///
  /// __Optional__ - This value may be {@code null} on some devices.
  ///
  /// __Full capability__ -
  /// Present on all camera devices that report being CameraCharacteristics\#INFO_SUPPORTED_HARDWARE_LEVEL_FULL HARDWARE_LEVEL_FULL devices in the
  /// CameraCharacteristics\#INFO_SUPPORTED_HARDWARE_LEVEL android.info.supportedHardwareLevel key
  ///
  ///@see CaptureRequest\#CONTROL_AE_MODE
  ///@see CaptureRequest\#CONTROL_MODE
  ///@see CameraCharacteristics\#INFO_SUPPORTED_HARDWARE_LEVEL
  ///@see CameraCharacteristics\#SENSOR_INFO_MAX_FRAME_DURATION
  static CaptureResult_Key get SENSOR_FRAME_DURATION =>
      CaptureResult_Key.fromRef(jniAccessors
          .getStaticField(
              _classRef, _id_SENSOR_FRAME_DURATION, jni.JniType.objectType)
          .object);

  static final _id_SENSOR_GREEN_SPLIT = jniAccessors.getStaticFieldIDOf(
      _classRef,
      "SENSOR_GREEN_SPLIT",
      "Landroid/hardware/camera2/CaptureResult\$Key;");

  /// from: static public final android.hardware.camera2.CaptureResult.Key<java.lang.Float> SENSOR_GREEN_SPLIT
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// The worst-case divergence between Bayer green channels.
  ///
  /// This value is an estimate of the worst case split between the
  /// Bayer green channels in the red and blue rows in the sensor color
  /// filter array.
  ///
  /// The green split is calculated as follows:
  ///
  /// <ol>
  /// <li>A 5x5 pixel (or larger) window W within the active sensor array is
  /// chosen. The term 'pixel' here is taken to mean a group of 4 Bayer
  /// mosaic channels (R, Gr, Gb, B).  The location and size of the window
  /// chosen is implementation defined, and should be chosen to provide a
  /// green split estimate that is both representative of the entire image
  /// for this camera sensor, and can be calculated quickly.</li>
  /// <li>The arithmetic mean of the green channels from the red
  /// rows (mean_Gr) within W is computed.</li>
  /// <li>The arithmetic mean of the green channels from the blue
  /// rows (mean_Gb) within W is computed.</li>
  /// <li>The maximum ratio R of the two means is computed as follows:
  /// <code>R = max((mean_Gr + 1)/(mean_Gb + 1), (mean_Gb + 1)/(mean_Gr + 1))</code></li>
  /// </ol>
  /// The ratio R is the green split divergence reported for this property,
  /// which represents how much the green channels differ in the mosaic
  /// pattern.  This value is typically used to determine the treatment of
  /// the green mosaic channels when demosaicing.
  ///
  /// The green split value can be roughly interpreted as follows:
  ///
  /// <ul>
  /// <li>R &lt; 1.03 is a negligible split (&lt;3% divergence).</li>
  /// <li>1.20 &lt;= R &gt;= 1.03 will require some software
  /// correction to avoid demosaic errors (3-20% divergence).</li>
  /// <li>R &gt; 1.20 will require strong software correction to produce
  /// a usuable image (&gt;20% divergence).</li>
  /// </ul>
  /// __Range of valid values:__<br>
  ///
  /// &gt;= 0
  ///
  /// __Optional__ - This value may be {@code null} on some devices.
  ///
  static CaptureResult_Key get SENSOR_GREEN_SPLIT =>
      CaptureResult_Key.fromRef(jniAccessors
          .getStaticField(
              _classRef, _id_SENSOR_GREEN_SPLIT, jni.JniType.objectType)
          .object);

  static final _id_SENSOR_NEUTRAL_COLOR_POINT = jniAccessors.getStaticFieldIDOf(
      _classRef,
      "SENSOR_NEUTRAL_COLOR_POINT",
      "Landroid/hardware/camera2/CaptureResult\$Key;");

  /// from: static public final android.hardware.camera2.CaptureResult.Key<android.util.Rational[]> SENSOR_NEUTRAL_COLOR_POINT
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// The estimated camera neutral color in the native sensor colorspace at
  /// the time of capture.
  ///
  /// This value gives the neutral color point encoded as an RGB value in the
  /// native sensor color space.  The neutral color point indicates the
  /// currently estimated white point of the scene illumination.  It can be
  /// used to interpolate between the provided color transforms when
  /// processing raw sensor data.
  ///
  /// The order of the values is R, G, B; where R is in the lowest index.
  ///
  /// __Optional__ - This value may be {@code null} on some devices.
  ///
  static CaptureResult_Key get SENSOR_NEUTRAL_COLOR_POINT =>
      CaptureResult_Key.fromRef(jniAccessors
          .getStaticField(
              _classRef, _id_SENSOR_NEUTRAL_COLOR_POINT, jni.JniType.objectType)
          .object);

  static final _id_SENSOR_NOISE_PROFILE = jniAccessors.getStaticFieldIDOf(
      _classRef,
      "SENSOR_NOISE_PROFILE",
      "Landroid/hardware/camera2/CaptureResult\$Key;");

  /// from: static public final android.hardware.camera2.CaptureResult.Key<android.util.Pair<java.lang.Double,java.lang.Double>[]> SENSOR_NOISE_PROFILE
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// Noise model coefficients for each CFA mosaic channel.
  ///
  /// This key contains two noise model coefficients for each CFA channel
  /// corresponding to the sensor amplification (S) and sensor readout
  /// noise (O).  These are given as pairs of coefficients for each channel
  /// in the same order as channels listed for the CFA layout key
  /// (see CameraCharacteristics\#SENSOR_INFO_COLOR_FILTER_ARRANGEMENT android.sensor.info.colorFilterArrangement).  This is
  /// represented as an array of Pair&lt;Double, Double&gt;, where
  /// the first member of the Pair at index n is the S coefficient and the
  /// second member is the O coefficient for the nth color channel in the CFA.
  ///
  /// These coefficients are used in a two parameter noise model to describe
  /// the amount of noise present in the image for each CFA channel.  The
  /// noise model used here is:
  ///
  /// N(x) = sqrt(Sx + O)
  ///
  /// Where x represents the recorded signal of a CFA channel normalized to
  /// the range [0, 1], and S and O are the noise model coeffiecients for
  /// that channel.
  ///
  /// A more detailed description of the noise model can be found in the
  /// Adobe DNG specification for the NoiseProfile tag.
  ///
  /// __Optional__ - This value may be {@code null} on some devices.
  ///
  ///@see CameraCharacteristics\#SENSOR_INFO_COLOR_FILTER_ARRANGEMENT
  static CaptureResult_Key get SENSOR_NOISE_PROFILE =>
      CaptureResult_Key.fromRef(jniAccessors
          .getStaticField(
              _classRef, _id_SENSOR_NOISE_PROFILE, jni.JniType.objectType)
          .object);

  static final _id_SENSOR_ROLLING_SHUTTER_SKEW =
      jniAccessors.getStaticFieldIDOf(_classRef, "SENSOR_ROLLING_SHUTTER_SKEW",
          "Landroid/hardware/camera2/CaptureResult\$Key;");

  /// from: static public final android.hardware.camera2.CaptureResult.Key<java.lang.Long> SENSOR_ROLLING_SHUTTER_SKEW
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// Duration between the start of first row exposure
  /// and the start of last row exposure.
  ///
  /// This is the exposure time skew between the first and last
  /// row exposure start times. The first row and the last row are
  /// the first and last rows inside of the
  /// CameraCharacteristics\#SENSOR_INFO_ACTIVE_ARRAY_SIZE android.sensor.info.activeArraySize.
  ///
  /// For typical camera sensors that use rolling shutters, this is also equivalent
  /// to the frame readout time.
  ///
  /// __Units__: Nanoseconds
  ///
  /// __Range of valid values:__<br>
  /// &gt;= 0 and &lt;
  /// android.hardware.camera2.params.StreamConfigurationMap\#getOutputMinFrameDuration.
  ///
  /// __Optional__ - This value may be {@code null} on some devices.
  ///
  /// __Limited capability__ -
  /// Present on all camera devices that report being at least CameraCharacteristics\#INFO_SUPPORTED_HARDWARE_LEVEL_LIMITED HARDWARE_LEVEL_LIMITED devices in the
  /// CameraCharacteristics\#INFO_SUPPORTED_HARDWARE_LEVEL android.info.supportedHardwareLevel key
  ///
  ///@see CameraCharacteristics\#INFO_SUPPORTED_HARDWARE_LEVEL
  ///@see CameraCharacteristics\#SENSOR_INFO_ACTIVE_ARRAY_SIZE
  static CaptureResult_Key get SENSOR_ROLLING_SHUTTER_SKEW =>
      CaptureResult_Key.fromRef(jniAccessors
          .getStaticField(_classRef, _id_SENSOR_ROLLING_SHUTTER_SKEW,
              jni.JniType.objectType)
          .object);

  static final _id_SENSOR_SENSITIVITY = jniAccessors.getStaticFieldIDOf(
      _classRef,
      "SENSOR_SENSITIVITY",
      "Landroid/hardware/camera2/CaptureResult\$Key;");

  /// from: static public final android.hardware.camera2.CaptureResult.Key<java.lang.Integer> SENSOR_SENSITIVITY
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// The amount of gain applied to sensor data
  /// before processing.
  ///
  /// The sensitivity is the standard ISO sensitivity value,
  /// as defined in ISO 12232:2006.
  ///
  /// The sensitivity must be within CameraCharacteristics\#SENSOR_INFO_SENSITIVITY_RANGE android.sensor.info.sensitivityRange, and
  /// if if it less than CameraCharacteristics\#SENSOR_MAX_ANALOG_SENSITIVITY android.sensor.maxAnalogSensitivity, the camera device
  /// is guaranteed to use only analog amplification for applying the gain.
  ///
  /// If the camera device cannot apply the exact sensitivity
  /// requested, it will reduce the gain to the nearest supported
  /// value. The final sensitivity used will be available in the
  /// output capture result.
  ///
  /// This control is only effective if CaptureRequest\#CONTROL_AE_MODE android.control.aeMode or CaptureRequest\#CONTROL_MODE android.control.mode is set to
  /// OFF; otherwise the auto-exposure algorithm will override this value.
  ///
  /// __Units__: ISO arithmetic units
  ///
  /// __Range of valid values:__<br>
  /// CameraCharacteristics\#SENSOR_INFO_SENSITIVITY_RANGE android.sensor.info.sensitivityRange
  ///
  /// __Optional__ - This value may be {@code null} on some devices.
  ///
  /// __Full capability__ -
  /// Present on all camera devices that report being CameraCharacteristics\#INFO_SUPPORTED_HARDWARE_LEVEL_FULL HARDWARE_LEVEL_FULL devices in the
  /// CameraCharacteristics\#INFO_SUPPORTED_HARDWARE_LEVEL android.info.supportedHardwareLevel key
  ///
  ///@see CaptureRequest\#CONTROL_AE_MODE
  ///@see CaptureRequest\#CONTROL_MODE
  ///@see CameraCharacteristics\#INFO_SUPPORTED_HARDWARE_LEVEL
  ///@see CameraCharacteristics\#SENSOR_INFO_SENSITIVITY_RANGE
  ///@see CameraCharacteristics\#SENSOR_MAX_ANALOG_SENSITIVITY
  static CaptureResult_Key get SENSOR_SENSITIVITY =>
      CaptureResult_Key.fromRef(jniAccessors
          .getStaticField(
              _classRef, _id_SENSOR_SENSITIVITY, jni.JniType.objectType)
          .object);

  static final _id_SENSOR_TEST_PATTERN_DATA = jniAccessors.getStaticFieldIDOf(
      _classRef,
      "SENSOR_TEST_PATTERN_DATA",
      "Landroid/hardware/camera2/CaptureResult\$Key;");

  /// from: static public final android.hardware.camera2.CaptureResult.Key<int[]> SENSOR_TEST_PATTERN_DATA
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// A pixel <code>[R, G_even, G_odd, B]</code> that supplies the test pattern
  /// when CaptureRequest\#SENSOR_TEST_PATTERN_MODE android.sensor.testPatternMode is SOLID_COLOR.
  ///
  /// Each color channel is treated as an unsigned 32-bit integer.
  /// The camera device then uses the most significant X bits
  /// that correspond to how many bits are in its Bayer raw sensor
  /// output.
  ///
  /// For example, a sensor with RAW10 Bayer output would use the
  /// 10 most significant bits from each color channel.
  ///
  /// __Optional__ - This value may be {@code null} on some devices.
  ///
  ///@see CaptureRequest\#SENSOR_TEST_PATTERN_MODE
  static CaptureResult_Key get SENSOR_TEST_PATTERN_DATA =>
      CaptureResult_Key.fromRef(jniAccessors
          .getStaticField(
              _classRef, _id_SENSOR_TEST_PATTERN_DATA, jni.JniType.objectType)
          .object);

  static final _id_SENSOR_TEST_PATTERN_MODE = jniAccessors.getStaticFieldIDOf(
      _classRef,
      "SENSOR_TEST_PATTERN_MODE",
      "Landroid/hardware/camera2/CaptureResult\$Key;");

  /// from: static public final android.hardware.camera2.CaptureResult.Key<java.lang.Integer> SENSOR_TEST_PATTERN_MODE
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// When enabled, the sensor sends a test pattern instead of
  /// doing a real exposure from the camera.
  ///
  /// When a test pattern is enabled, all manual sensor controls specified
  /// by android.sensor.* will be ignored. All other controls should
  /// work as normal.
  ///
  /// For example, if manual flash is enabled, flash firing should still
  /// occur (and that the test pattern remain unmodified, since the flash
  /// would not actually affect it).
  ///
  /// Defaults to OFF.
  ///
  /// __Possible values:__
  /// <ul>
  ///   <li>\#SENSOR_TEST_PATTERN_MODE_OFF OFF</li>
  ///   <li>\#SENSOR_TEST_PATTERN_MODE_SOLID_COLOR SOLID_COLOR</li>
  ///   <li>\#SENSOR_TEST_PATTERN_MODE_COLOR_BARS COLOR_BARS</li>
  ///   <li>\#SENSOR_TEST_PATTERN_MODE_COLOR_BARS_FADE_TO_GRAY COLOR_BARS_FADE_TO_GRAY</li>
  ///   <li>\#SENSOR_TEST_PATTERN_MODE_PN9 PN9</li>
  ///   <li>\#SENSOR_TEST_PATTERN_MODE_CUSTOM1 CUSTOM1</li>
  /// </ul>
  ///
  /// __Available values for this device:__<br>
  /// CameraCharacteristics\#SENSOR_AVAILABLE_TEST_PATTERN_MODES android.sensor.availableTestPatternModes
  ///
  /// __Optional__ - This value may be {@code null} on some devices.
  ///
  ///@see CameraCharacteristics\#SENSOR_AVAILABLE_TEST_PATTERN_MODES
  ///@see \#SENSOR_TEST_PATTERN_MODE_OFF
  ///@see \#SENSOR_TEST_PATTERN_MODE_SOLID_COLOR
  ///@see \#SENSOR_TEST_PATTERN_MODE_COLOR_BARS
  ///@see \#SENSOR_TEST_PATTERN_MODE_COLOR_BARS_FADE_TO_GRAY
  ///@see \#SENSOR_TEST_PATTERN_MODE_PN9
  ///@see \#SENSOR_TEST_PATTERN_MODE_CUSTOM1
  static CaptureResult_Key get SENSOR_TEST_PATTERN_MODE =>
      CaptureResult_Key.fromRef(jniAccessors
          .getStaticField(
              _classRef, _id_SENSOR_TEST_PATTERN_MODE, jni.JniType.objectType)
          .object);

  static final _id_SENSOR_TIMESTAMP = jniAccessors.getStaticFieldIDOf(_classRef,
      "SENSOR_TIMESTAMP", "Landroid/hardware/camera2/CaptureResult\$Key;");

  /// from: static public final android.hardware.camera2.CaptureResult.Key<java.lang.Long> SENSOR_TIMESTAMP
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// Time at start of exposure of first
  /// row of the image sensor active array, in nanoseconds.
  ///
  /// The timestamps are also included in all image
  /// buffers produced for the same capture, and will be identical
  /// on all the outputs.
  ///
  /// When CameraCharacteristics\#SENSOR_INFO_TIMESTAMP_SOURCE android.sensor.info.timestampSource <code>==</code> UNKNOWN,
  /// the timestamps measure time since an unspecified starting point,
  /// and are monotonically increasing. They can be compared with the
  /// timestamps for other captures from the same camera device, but are
  /// not guaranteed to be comparable to any other time source.
  ///
  /// When CameraCharacteristics\#SENSOR_INFO_TIMESTAMP_SOURCE android.sensor.info.timestampSource <code>==</code> REALTIME, the
  /// timestamps measure time in the same timebase as android.os.SystemClock\#elapsedRealtimeNanos, and they can
  /// be compared to other timestamps from other subsystems that
  /// are using that base.
  ///
  /// For reprocessing, the timestamp will match the start of exposure of
  /// the input image, i.e. CaptureResult\#SENSOR_TIMESTAMP the
  /// timestamp in the TotalCaptureResult that was used to create the
  /// reprocess capture request.
  ///
  /// __Units__: Nanoseconds
  ///
  /// __Range of valid values:__<br>
  /// &gt; 0
  ///
  /// This key is available on all devices.
  ///
  ///@see CameraCharacteristics\#SENSOR_INFO_TIMESTAMP_SOURCE
  static CaptureResult_Key get SENSOR_TIMESTAMP =>
      CaptureResult_Key.fromRef(jniAccessors
          .getStaticField(
              _classRef, _id_SENSOR_TIMESTAMP, jni.JniType.objectType)
          .object);

  static final _id_SHADING_MODE = jniAccessors.getStaticFieldIDOf(_classRef,
      "SHADING_MODE", "Landroid/hardware/camera2/CaptureResult\$Key;");

  /// from: static public final android.hardware.camera2.CaptureResult.Key<java.lang.Integer> SHADING_MODE
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// Quality of lens shading correction applied
  /// to the image data.
  ///
  /// When set to OFF mode, no lens shading correction will be applied by the
  /// camera device, and an identity lens shading map data will be provided
  /// if <code>CaptureRequest\#STATISTICS_LENS_SHADING_MAP_MODE android.statistics.lensShadingMapMode == ON</code>. For example, for lens
  /// shading map with size of <code>[ 4, 3 ]</code>,
  /// the output CaptureResult\#STATISTICS_LENS_SHADING_CORRECTION_MAP android.statistics.lensShadingCorrectionMap for this case will be an identity
  /// map shown below:
  ///
  /// <pre><code>[ 1.0, 1.0, 1.0, 1.0,  1.0, 1.0, 1.0, 1.0,
  ///  1.0, 1.0, 1.0, 1.0,  1.0, 1.0, 1.0, 1.0,
  ///  1.0, 1.0, 1.0, 1.0,  1.0, 1.0, 1.0, 1.0,
  ///  1.0, 1.0, 1.0, 1.0,  1.0, 1.0, 1.0, 1.0,
  ///  1.0, 1.0, 1.0, 1.0,  1.0, 1.0, 1.0, 1.0,
  ///  1.0, 1.0, 1.0, 1.0,  1.0, 1.0, 1.0, 1.0 ]
  /// </code></pre>
  /// When set to other modes, lens shading correction will be applied by the camera
  /// device. Applications can request lens shading map data by setting
  /// CaptureRequest\#STATISTICS_LENS_SHADING_MAP_MODE android.statistics.lensShadingMapMode to ON, and then the camera device will provide lens
  /// shading map data in CaptureResult\#STATISTICS_LENS_SHADING_CORRECTION_MAP android.statistics.lensShadingCorrectionMap; the returned shading map
  /// data will be the one applied by the camera device for this capture request.
  ///
  /// The shading map data may depend on the auto-exposure (AE) and AWB statistics, therefore
  /// the reliability of the map data may be affected by the AE and AWB algorithms. When AE and
  /// AWB are in AUTO modes(CaptureRequest\#CONTROL_AE_MODE android.control.aeMode <code>!=</code> OFF and CaptureRequest\#CONTROL_AWB_MODE android.control.awbMode <code>!=</code>
  /// OFF), to get best results, it is recommended that the applications wait for the AE and AWB
  /// to be converged before using the returned shading map data.
  ///
  /// __Possible values:__
  /// <ul>
  ///   <li>\#SHADING_MODE_OFF OFF</li>
  ///   <li>\#SHADING_MODE_FAST FAST</li>
  ///   <li>\#SHADING_MODE_HIGH_QUALITY HIGH_QUALITY</li>
  /// </ul>
  ///
  /// __Available values for this device:__<br>
  /// CameraCharacteristics\#SHADING_AVAILABLE_MODES android.shading.availableModes
  ///
  /// __Optional__ - This value may be {@code null} on some devices.
  ///
  /// __Full capability__ -
  /// Present on all camera devices that report being CameraCharacteristics\#INFO_SUPPORTED_HARDWARE_LEVEL_FULL HARDWARE_LEVEL_FULL devices in the
  /// CameraCharacteristics\#INFO_SUPPORTED_HARDWARE_LEVEL android.info.supportedHardwareLevel key
  ///
  ///@see CaptureRequest\#CONTROL_AE_MODE
  ///@see CaptureRequest\#CONTROL_AWB_MODE
  ///@see CameraCharacteristics\#INFO_SUPPORTED_HARDWARE_LEVEL
  ///@see CameraCharacteristics\#SHADING_AVAILABLE_MODES
  ///@see CaptureResult\#STATISTICS_LENS_SHADING_CORRECTION_MAP
  ///@see CaptureRequest\#STATISTICS_LENS_SHADING_MAP_MODE
  ///@see \#SHADING_MODE_OFF
  ///@see \#SHADING_MODE_FAST
  ///@see \#SHADING_MODE_HIGH_QUALITY
  static CaptureResult_Key get SHADING_MODE =>
      CaptureResult_Key.fromRef(jniAccessors
          .getStaticField(_classRef, _id_SHADING_MODE, jni.JniType.objectType)
          .object);

  static final _id_STATISTICS_FACES = jniAccessors.getStaticFieldIDOf(_classRef,
      "STATISTICS_FACES", "Landroid/hardware/camera2/CaptureResult\$Key;");

  /// from: static public final android.hardware.camera2.CaptureResult.Key<android.hardware.camera2.params.Face[]> STATISTICS_FACES
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// List of the faces detected through camera face detection
  /// in this capture.
  ///
  /// Only available if CaptureRequest\#STATISTICS_FACE_DETECT_MODE android.statistics.faceDetectMode <code>!=</code> OFF.
  ///
  /// This key is available on all devices.
  ///
  ///@see CaptureRequest\#STATISTICS_FACE_DETECT_MODE
  static CaptureResult_Key get STATISTICS_FACES =>
      CaptureResult_Key.fromRef(jniAccessors
          .getStaticField(
              _classRef, _id_STATISTICS_FACES, jni.JniType.objectType)
          .object);

  static final _id_STATISTICS_FACE_DETECT_MODE =
      jniAccessors.getStaticFieldIDOf(_classRef, "STATISTICS_FACE_DETECT_MODE",
          "Landroid/hardware/camera2/CaptureResult\$Key;");

  /// from: static public final android.hardware.camera2.CaptureResult.Key<java.lang.Integer> STATISTICS_FACE_DETECT_MODE
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// Operating mode for the face detector
  /// unit.
  ///
  /// Whether face detection is enabled, and whether it
  /// should output just the basic fields or the full set of
  /// fields.
  ///
  /// __Possible values:__
  /// <ul>
  ///   <li>\#STATISTICS_FACE_DETECT_MODE_OFF OFF</li>
  ///   <li>\#STATISTICS_FACE_DETECT_MODE_SIMPLE SIMPLE</li>
  ///   <li>\#STATISTICS_FACE_DETECT_MODE_FULL FULL</li>
  /// </ul>
  ///
  /// __Available values for this device:__<br>
  /// CameraCharacteristics\#STATISTICS_INFO_AVAILABLE_FACE_DETECT_MODES android.statistics.info.availableFaceDetectModes
  ///
  /// This key is available on all devices.
  ///
  ///@see CameraCharacteristics\#STATISTICS_INFO_AVAILABLE_FACE_DETECT_MODES
  ///@see \#STATISTICS_FACE_DETECT_MODE_OFF
  ///@see \#STATISTICS_FACE_DETECT_MODE_SIMPLE
  ///@see \#STATISTICS_FACE_DETECT_MODE_FULL
  static CaptureResult_Key get STATISTICS_FACE_DETECT_MODE =>
      CaptureResult_Key.fromRef(jniAccessors
          .getStaticField(_classRef, _id_STATISTICS_FACE_DETECT_MODE,
              jni.JniType.objectType)
          .object);

  static final _id_STATISTICS_HOT_PIXEL_MAP = jniAccessors.getStaticFieldIDOf(
      _classRef,
      "STATISTICS_HOT_PIXEL_MAP",
      "Landroid/hardware/camera2/CaptureResult\$Key;");

  /// from: static public final android.hardware.camera2.CaptureResult.Key<android.graphics.Point[]> STATISTICS_HOT_PIXEL_MAP
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// List of <code>(x, y)</code> coordinates of hot/defective pixels on the sensor.
  ///
  /// A coordinate <code>(x, y)</code> must lie between <code>(0, 0)</code>, and
  /// <code>(width - 1, height - 1)</code> (inclusive), which are the top-left and
  /// bottom-right of the pixel array, respectively. The width and
  /// height dimensions are given in CameraCharacteristics\#SENSOR_INFO_PIXEL_ARRAY_SIZE android.sensor.info.pixelArraySize.
  /// This may include hot pixels that lie outside of the active array
  /// bounds given by CameraCharacteristics\#SENSOR_INFO_ACTIVE_ARRAY_SIZE android.sensor.info.activeArraySize.
  ///
  /// __Range of valid values:__<br>
  ///
  /// n &lt;= number of pixels on the sensor.
  /// The <code>(x, y)</code> coordinates must be bounded by
  /// CameraCharacteristics\#SENSOR_INFO_PIXEL_ARRAY_SIZE android.sensor.info.pixelArraySize.
  ///
  /// __Optional__ - This value may be {@code null} on some devices.
  ///
  ///@see CameraCharacteristics\#SENSOR_INFO_ACTIVE_ARRAY_SIZE
  ///@see CameraCharacteristics\#SENSOR_INFO_PIXEL_ARRAY_SIZE
  static CaptureResult_Key get STATISTICS_HOT_PIXEL_MAP =>
      CaptureResult_Key.fromRef(jniAccessors
          .getStaticField(
              _classRef, _id_STATISTICS_HOT_PIXEL_MAP, jni.JniType.objectType)
          .object);

  static final _id_STATISTICS_HOT_PIXEL_MAP_MODE =
      jniAccessors.getStaticFieldIDOf(
          _classRef,
          "STATISTICS_HOT_PIXEL_MAP_MODE",
          "Landroid/hardware/camera2/CaptureResult\$Key;");

  /// from: static public final android.hardware.camera2.CaptureResult.Key<java.lang.Boolean> STATISTICS_HOT_PIXEL_MAP_MODE
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// Operating mode for hot pixel map generation.
  ///
  /// If set to <code>true</code>, a hot pixel map is returned in CaptureResult\#STATISTICS_HOT_PIXEL_MAP android.statistics.hotPixelMap.
  /// If set to <code>false</code>, no hot pixel map will be returned.
  ///
  /// __Range of valid values:__<br>
  /// CameraCharacteristics\#STATISTICS_INFO_AVAILABLE_HOT_PIXEL_MAP_MODES android.statistics.info.availableHotPixelMapModes
  ///
  /// __Optional__ - This value may be {@code null} on some devices.
  ///
  ///@see CaptureResult\#STATISTICS_HOT_PIXEL_MAP
  ///@see CameraCharacteristics\#STATISTICS_INFO_AVAILABLE_HOT_PIXEL_MAP_MODES
  static CaptureResult_Key get STATISTICS_HOT_PIXEL_MAP_MODE =>
      CaptureResult_Key.fromRef(jniAccessors
          .getStaticField(_classRef, _id_STATISTICS_HOT_PIXEL_MAP_MODE,
              jni.JniType.objectType)
          .object);

  static final _id_STATISTICS_LENS_SHADING_CORRECTION_MAP =
      jniAccessors.getStaticFieldIDOf(
          _classRef,
          "STATISTICS_LENS_SHADING_CORRECTION_MAP",
          "Landroid/hardware/camera2/CaptureResult\$Key;");

  /// from: static public final android.hardware.camera2.CaptureResult.Key<android.hardware.camera2.params.LensShadingMap> STATISTICS_LENS_SHADING_CORRECTION_MAP
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// The shading map is a low-resolution floating-point map
  /// that lists the coefficients used to correct for vignetting, for each
  /// Bayer color channel.
  ///
  /// The map provided here is the same map that is used by the camera device to
  /// correct both color shading and vignetting for output non-RAW images.
  ///
  /// When there is no lens shading correction applied to RAW
  /// output images (CameraCharacteristics\#SENSOR_INFO_LENS_SHADING_APPLIED android.sensor.info.lensShadingApplied <code>==</code>
  /// false), this map is the complete lens shading correction
  /// map; when there is some lens shading correction applied to
  /// the RAW output image (CameraCharacteristics\#SENSOR_INFO_LENS_SHADING_APPLIED android.sensor.info.lensShadingApplied<code>==</code> true), this map reports the remaining lens shading
  /// correction map that needs to be applied to get shading
  /// corrected images that match the camera device's output for
  /// non-RAW formats.
  ///
  /// For a complete shading correction map, the least shaded
  /// section of the image will have a gain factor of 1; all
  /// other sections will have gains above 1.
  ///
  /// When CaptureRequest\#COLOR_CORRECTION_MODE android.colorCorrection.mode = TRANSFORM_MATRIX, the map
  /// will take into account the colorCorrection settings.
  ///
  /// The shading map is for the entire active pixel array, and is not
  /// affected by the crop region specified in the request. Each shading map
  /// entry is the value of the shading compensation map over a specific
  /// pixel on the sensor.  Specifically, with a (N x M) resolution shading
  /// map, and an active pixel array size (W x H), shading map entry
  /// (x,y) \u03f5 (0 ... N-1, 0 ... M-1) is the value of the shading map at
  /// pixel ( ((W-1)/(N-1)) * x, ((H-1)/(M-1)) * y) for the four color channels.
  /// The map is assumed to be bilinearly interpolated between the sample points.
  ///
  /// The channel order is [R, Geven, Godd, B], where Geven is the green
  /// channel for the even rows of a Bayer pattern, and Godd is the odd rows.
  /// The shading map is stored in a fully interleaved format.
  ///
  /// The shading map will generally have on the order of 30-40 rows and columns,
  /// and will be smaller than 64x64.
  ///
  /// As an example, given a very small map defined as:
  ///
  /// <pre><code>width,height = [ 4, 3 ]
  /// values =
  /// [ 1.3, 1.2, 1.15, 1.2,  1.2, 1.2, 1.15, 1.2,
  ///     1.1, 1.2, 1.2, 1.2,  1.3, 1.2, 1.3, 1.3,
  ///   1.2, 1.2, 1.25, 1.1,  1.1, 1.1, 1.1, 1.0,
  ///     1.0, 1.0, 1.0, 1.0,  1.2, 1.3, 1.25, 1.2,
  ///   1.3, 1.2, 1.2, 1.3,   1.2, 1.15, 1.1, 1.2,
  ///     1.2, 1.1, 1.0, 1.2,  1.3, 1.15, 1.2, 1.3 ]
  /// </code></pre>
  /// The low-resolution scaling map images for each channel are
  /// (displayed using nearest-neighbor interpolation):
  ///
  /// <img alt="Red lens shading map"src="/reference/images/camera2/metadata/android.statistics.lensShadingMap/red_shading.png"/>
  /// <img alt="Green (even rows) lens shading map"src="/reference/images/camera2/metadata/android.statistics.lensShadingMap/green_e_shading.png"/>
  /// <img alt="Green (odd rows) lens shading map"src="/reference/images/camera2/metadata/android.statistics.lensShadingMap/green_o_shading.png"/>
  /// <img alt="Blue lens shading map"src="/reference/images/camera2/metadata/android.statistics.lensShadingMap/blue_shading.png"/>
  ///
  /// As a visualization only, inverting the full-color map to recover an
  /// image of a gray wall (using bicubic interpolation for visual quality) as captured by the sensor gives:
  ///
  /// <img alt="Image of a uniform white wall (inverse shading map)"src="/reference/images/camera2/metadata/android.statistics.lensShadingMap/inv_shading.png"/>
  ///
  /// __Range of valid values:__<br>
  /// Each gain factor is &gt;= 1
  ///
  /// __Optional__ - This value may be {@code null} on some devices.
  ///
  /// __Full capability__ -
  /// Present on all camera devices that report being CameraCharacteristics\#INFO_SUPPORTED_HARDWARE_LEVEL_FULL HARDWARE_LEVEL_FULL devices in the
  /// CameraCharacteristics\#INFO_SUPPORTED_HARDWARE_LEVEL android.info.supportedHardwareLevel key
  ///
  ///@see CaptureRequest\#COLOR_CORRECTION_MODE
  ///@see CameraCharacteristics\#INFO_SUPPORTED_HARDWARE_LEVEL
  ///@see CameraCharacteristics\#SENSOR_INFO_LENS_SHADING_APPLIED
  static CaptureResult_Key get STATISTICS_LENS_SHADING_CORRECTION_MAP =>
      CaptureResult_Key.fromRef(jniAccessors
          .getStaticField(_classRef, _id_STATISTICS_LENS_SHADING_CORRECTION_MAP,
              jni.JniType.objectType)
          .object);

  static final _id_STATISTICS_LENS_SHADING_MAP_MODE =
      jniAccessors.getStaticFieldIDOf(
          _classRef,
          "STATISTICS_LENS_SHADING_MAP_MODE",
          "Landroid/hardware/camera2/CaptureResult\$Key;");

  /// from: static public final android.hardware.camera2.CaptureResult.Key<java.lang.Integer> STATISTICS_LENS_SHADING_MAP_MODE
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// Whether the camera device will output the lens
  /// shading map in output result metadata.
  ///
  /// When set to ON,
  /// android.statistics.lensShadingMap will be provided in
  /// the output result metadata.
  ///
  /// ON is always supported on devices with the RAW capability.
  ///
  /// __Possible values:__
  /// <ul>
  ///   <li>\#STATISTICS_LENS_SHADING_MAP_MODE_OFF OFF</li>
  ///   <li>\#STATISTICS_LENS_SHADING_MAP_MODE_ON ON</li>
  /// </ul>
  ///
  /// __Available values for this device:__<br>
  /// CameraCharacteristics\#STATISTICS_INFO_AVAILABLE_LENS_SHADING_MAP_MODES android.statistics.info.availableLensShadingMapModes
  ///
  /// __Optional__ - This value may be {@code null} on some devices.
  ///
  /// __Full capability__ -
  /// Present on all camera devices that report being CameraCharacteristics\#INFO_SUPPORTED_HARDWARE_LEVEL_FULL HARDWARE_LEVEL_FULL devices in the
  /// CameraCharacteristics\#INFO_SUPPORTED_HARDWARE_LEVEL android.info.supportedHardwareLevel key
  ///
  ///@see CameraCharacteristics\#INFO_SUPPORTED_HARDWARE_LEVEL
  ///@see CameraCharacteristics\#STATISTICS_INFO_AVAILABLE_LENS_SHADING_MAP_MODES
  ///@see \#STATISTICS_LENS_SHADING_MAP_MODE_OFF
  ///@see \#STATISTICS_LENS_SHADING_MAP_MODE_ON
  static CaptureResult_Key get STATISTICS_LENS_SHADING_MAP_MODE =>
      CaptureResult_Key.fromRef(jniAccessors
          .getStaticField(_classRef, _id_STATISTICS_LENS_SHADING_MAP_MODE,
              jni.JniType.objectType)
          .object);

  static final _id_STATISTICS_OIS_DATA_MODE = jniAccessors.getStaticFieldIDOf(
      _classRef,
      "STATISTICS_OIS_DATA_MODE",
      "Landroid/hardware/camera2/CaptureResult\$Key;");

  /// from: static public final android.hardware.camera2.CaptureResult.Key<java.lang.Integer> STATISTICS_OIS_DATA_MODE
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// A control for selecting whether OIS position information is included in output
  /// result metadata.
  ///
  /// __Possible values:__
  /// <ul>
  ///   <li>\#STATISTICS_OIS_DATA_MODE_OFF OFF</li>
  ///   <li>\#STATISTICS_OIS_DATA_MODE_ON ON</li>
  /// </ul>
  ///
  /// __Available values for this device:__<br>
  /// CameraCharacteristics\#STATISTICS_INFO_AVAILABLE_OIS_DATA_MODES android.statistics.info.availableOisDataModes
  ///
  /// __Optional__ - This value may be {@code null} on some devices.
  ///
  ///@see CameraCharacteristics\#STATISTICS_INFO_AVAILABLE_OIS_DATA_MODES
  ///@see \#STATISTICS_OIS_DATA_MODE_OFF
  ///@see \#STATISTICS_OIS_DATA_MODE_ON
  static CaptureResult_Key get STATISTICS_OIS_DATA_MODE =>
      CaptureResult_Key.fromRef(jniAccessors
          .getStaticField(
              _classRef, _id_STATISTICS_OIS_DATA_MODE, jni.JniType.objectType)
          .object);

  static final _id_STATISTICS_OIS_SAMPLES = jniAccessors.getStaticFieldIDOf(
      _classRef,
      "STATISTICS_OIS_SAMPLES",
      "Landroid/hardware/camera2/CaptureResult\$Key;");

  /// from: static public final android.hardware.camera2.CaptureResult.Key<android.hardware.camera2.params.OisSample[]> STATISTICS_OIS_SAMPLES
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// An array of OIS samples.
  ///
  /// Each OIS sample contains the timestamp and the amount of shifts in x and y direction,
  /// in pixels, of the OIS sample.
  ///
  /// A positive value for a shift in x direction is a shift from left to right in active array
  /// coordinate system. For example, if the optical center is (1000, 500) in active array
  /// coordinates, a shift of (3, 0) puts the new optical center at (1003, 500).
  ///
  /// A positive value for a shift in y direction is a shift from top to bottom in active array
  /// coordinate system. For example, if the optical center is (1000, 500) in active array
  /// coordinates, a shift of (0, 5) puts the new optical center at (1000, 505).
  ///
  /// __Optional__ - This value may be {@code null} on some devices.
  ///
  static CaptureResult_Key get STATISTICS_OIS_SAMPLES =>
      CaptureResult_Key.fromRef(jniAccessors
          .getStaticField(
              _classRef, _id_STATISTICS_OIS_SAMPLES, jni.JniType.objectType)
          .object);

  static final _id_STATISTICS_SCENE_FLICKER = jniAccessors.getStaticFieldIDOf(
      _classRef,
      "STATISTICS_SCENE_FLICKER",
      "Landroid/hardware/camera2/CaptureResult\$Key;");

  /// from: static public final android.hardware.camera2.CaptureResult.Key<java.lang.Integer> STATISTICS_SCENE_FLICKER
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// The camera device estimated scene illumination lighting
  /// frequency.
  ///
  /// Many light sources, such as most fluorescent lights, flicker at a rate
  /// that depends on the local utility power standards. This flicker must be
  /// accounted for by auto-exposure routines to avoid artifacts in captured images.
  /// The camera device uses this entry to tell the application what the scene
  /// illuminant frequency is.
  ///
  /// When manual exposure control is enabled
  /// (<code>CaptureRequest\#CONTROL_AE_MODE android.control.aeMode == OFF</code> or <code>CaptureRequest\#CONTROL_MODE android.control.mode ==
  /// OFF</code>), the CaptureRequest\#CONTROL_AE_ANTIBANDING_MODE android.control.aeAntibandingMode doesn't perform
  /// antibanding, and the application can ensure it selects
  /// exposure times that do not cause banding issues by looking
  /// into this metadata field. See
  /// CaptureRequest\#CONTROL_AE_ANTIBANDING_MODE android.control.aeAntibandingMode for more details.
  ///
  /// Reports NONE if there doesn't appear to be flickering illumination.
  ///
  /// __Possible values:__
  /// <ul>
  ///   <li>\#STATISTICS_SCENE_FLICKER_NONE NONE</li>
  ///   <li>\#STATISTICS_SCENE_FLICKER_50HZ 50HZ</li>
  ///   <li>\#STATISTICS_SCENE_FLICKER_60HZ 60HZ</li>
  /// </ul>
  ///
  /// __Optional__ - This value may be {@code null} on some devices.
  ///
  /// __Full capability__ -
  /// Present on all camera devices that report being CameraCharacteristics\#INFO_SUPPORTED_HARDWARE_LEVEL_FULL HARDWARE_LEVEL_FULL devices in the
  /// CameraCharacteristics\#INFO_SUPPORTED_HARDWARE_LEVEL android.info.supportedHardwareLevel key
  ///
  ///@see CaptureRequest\#CONTROL_AE_ANTIBANDING_MODE
  ///@see CaptureRequest\#CONTROL_AE_MODE
  ///@see CaptureRequest\#CONTROL_MODE
  ///@see CameraCharacteristics\#INFO_SUPPORTED_HARDWARE_LEVEL
  ///@see \#STATISTICS_SCENE_FLICKER_NONE
  ///@see \#STATISTICS_SCENE_FLICKER_50HZ
  ///@see \#STATISTICS_SCENE_FLICKER_60HZ
  static CaptureResult_Key get STATISTICS_SCENE_FLICKER =>
      CaptureResult_Key.fromRef(jniAccessors
          .getStaticField(
              _classRef, _id_STATISTICS_SCENE_FLICKER, jni.JniType.objectType)
          .object);

  static final _id_TONEMAP_CURVE = jniAccessors.getStaticFieldIDOf(_classRef,
      "TONEMAP_CURVE", "Landroid/hardware/camera2/CaptureResult\$Key;");

  /// from: static public final android.hardware.camera2.CaptureResult.Key<android.hardware.camera2.params.TonemapCurve> TONEMAP_CURVE
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// Tonemapping / contrast / gamma curve to use when CaptureRequest\#TONEMAP_MODE android.tonemap.mode
  /// is CONTRAST_CURVE.
  ///
  /// The tonemapCurve consist of three curves for each of red, green, and blue
  /// channels respectively. The following example uses the red channel as an
  /// example. The same logic applies to green and blue channel.
  /// Each channel's curve is defined by an array of control points:
  ///
  /// <pre><code>curveRed =
  ///   [ P0(in, out), P1(in, out), P2(in, out), P3(in, out), ..., PN(in, out) ]
  /// 2 &lt;= N &lt;= CameraCharacteristics\#TONEMAP_MAX_CURVE_POINTS android.tonemap.maxCurvePoints</code></pre>
  /// These are sorted in order of increasing <code>Pin</code>; it is always
  /// guaranteed that input values 0.0 and 1.0 are included in the list to
  /// define a complete mapping. For input values between control points,
  /// the camera device must linearly interpolate between the control
  /// points.
  ///
  /// Each curve can have an independent number of points, and the number
  /// of points can be less than max (that is, the request doesn't have to
  /// always provide a curve with number of points equivalent to
  /// CameraCharacteristics\#TONEMAP_MAX_CURVE_POINTS android.tonemap.maxCurvePoints).
  ///
  /// For devices with MONOCHROME capability, only red channel is used. Green and blue channels
  /// are ignored.
  ///
  /// A few examples, and their corresponding graphical mappings; these
  /// only specify the red channel and the precision is limited to 4
  /// digits, for conciseness.
  ///
  /// Linear mapping:
  ///
  /// <pre><code>curveRed = [ (0, 0), (1.0, 1.0) ]
  /// </code></pre>
  /// <img alt="Linear mapping curve"src="/reference/images/camera2/metadata/android.tonemap.curveRed/linear_tonemap.png"/>
  ///
  /// Invert mapping:
  ///
  /// <pre><code>curveRed = [ (0, 1.0), (1.0, 0) ]
  /// </code></pre>
  /// <img alt="Inverting mapping curve"src="/reference/images/camera2/metadata/android.tonemap.curveRed/inverse_tonemap.png"/>
  ///
  /// Gamma 1/2.2 mapping, with 16 control points:
  ///
  /// <pre><code>curveRed = [
  ///   (0.0000, 0.0000), (0.0667, 0.2920), (0.1333, 0.4002), (0.2000, 0.4812),
  ///   (0.2667, 0.5484), (0.3333, 0.6069), (0.4000, 0.6594), (0.4667, 0.7072),
  ///   (0.5333, 0.7515), (0.6000, 0.7928), (0.6667, 0.8317), (0.7333, 0.8685),
  ///   (0.8000, 0.9035), (0.8667, 0.9370), (0.9333, 0.9691), (1.0000, 1.0000) ]
  /// </code></pre>
  /// <img alt="Gamma = 1/2.2 tonemapping curve"src="/reference/images/camera2/metadata/android.tonemap.curveRed/gamma_tonemap.png"/>
  ///
  /// Standard sRGB gamma mapping, per IEC 61966-2-1:1999, with 16 control points:
  ///
  /// <pre><code>curveRed = [
  ///   (0.0000, 0.0000), (0.0667, 0.2864), (0.1333, 0.4007), (0.2000, 0.4845),
  ///   (0.2667, 0.5532), (0.3333, 0.6125), (0.4000, 0.6652), (0.4667, 0.7130),
  ///   (0.5333, 0.7569), (0.6000, 0.7977), (0.6667, 0.8360), (0.7333, 0.8721),
  ///   (0.8000, 0.9063), (0.8667, 0.9389), (0.9333, 0.9701), (1.0000, 1.0000) ]
  /// </code></pre>
  /// <img alt="sRGB tonemapping curve"src="/reference/images/camera2/metadata/android.tonemap.curveRed/srgb_tonemap.png"/>
  ///
  /// __Optional__ - This value may be {@code null} on some devices.
  ///
  /// __Full capability__ -
  /// Present on all camera devices that report being CameraCharacteristics\#INFO_SUPPORTED_HARDWARE_LEVEL_FULL HARDWARE_LEVEL_FULL devices in the
  /// CameraCharacteristics\#INFO_SUPPORTED_HARDWARE_LEVEL android.info.supportedHardwareLevel key
  ///
  ///@see CameraCharacteristics\#INFO_SUPPORTED_HARDWARE_LEVEL
  ///@see CameraCharacteristics\#TONEMAP_MAX_CURVE_POINTS
  ///@see CaptureRequest\#TONEMAP_MODE
  static CaptureResult_Key get TONEMAP_CURVE =>
      CaptureResult_Key.fromRef(jniAccessors
          .getStaticField(_classRef, _id_TONEMAP_CURVE, jni.JniType.objectType)
          .object);

  static final _id_TONEMAP_GAMMA = jniAccessors.getStaticFieldIDOf(_classRef,
      "TONEMAP_GAMMA", "Landroid/hardware/camera2/CaptureResult\$Key;");

  /// from: static public final android.hardware.camera2.CaptureResult.Key<java.lang.Float> TONEMAP_GAMMA
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// Tonemapping curve to use when CaptureRequest\#TONEMAP_MODE android.tonemap.mode is
  /// GAMMA_VALUE
  ///
  /// The tonemap curve will be defined the following formula:
  /// * OUT = pow(IN, 1.0 / gamma)
  /// where IN and OUT is the input pixel value scaled to range [0.0, 1.0],
  /// pow is the power function and gamma is the gamma value specified by this
  /// key.
  ///
  /// The same curve will be applied to all color channels. The camera device
  /// may clip the input gamma value to its supported range. The actual applied
  /// value will be returned in capture result.
  ///
  /// The valid range of gamma value varies on different devices, but values
  /// within [1.0, 5.0] are guaranteed not to be clipped.
  ///
  /// __Optional__ - This value may be {@code null} on some devices.
  ///
  ///@see CaptureRequest\#TONEMAP_MODE
  static CaptureResult_Key get TONEMAP_GAMMA =>
      CaptureResult_Key.fromRef(jniAccessors
          .getStaticField(_classRef, _id_TONEMAP_GAMMA, jni.JniType.objectType)
          .object);

  static final _id_TONEMAP_MODE = jniAccessors.getStaticFieldIDOf(_classRef,
      "TONEMAP_MODE", "Landroid/hardware/camera2/CaptureResult\$Key;");

  /// from: static public final android.hardware.camera2.CaptureResult.Key<java.lang.Integer> TONEMAP_MODE
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// High-level global contrast/gamma/tonemapping control.
  ///
  /// When switching to an application-defined contrast curve by setting
  /// CaptureRequest\#TONEMAP_MODE android.tonemap.mode to CONTRAST_CURVE, the curve is defined
  /// per-channel with a set of <code>(in, out)</code> points that specify the
  /// mapping from input high-bit-depth pixel value to the output
  /// low-bit-depth value.  Since the actual pixel ranges of both input
  /// and output may change depending on the camera pipeline, the values
  /// are specified by normalized floating-point numbers.
  ///
  /// More-complex color mapping operations such as 3D color look-up
  /// tables, selective chroma enhancement, or other non-linear color
  /// transforms will be disabled when CaptureRequest\#TONEMAP_MODE android.tonemap.mode is
  /// CONTRAST_CURVE.
  ///
  /// When using either FAST or HIGH_QUALITY, the camera device will
  /// emit its own tonemap curve in CaptureRequest\#TONEMAP_CURVE android.tonemap.curve.
  /// These values are always available, and as close as possible to the
  /// actually used nonlinear/nonglobal transforms.
  ///
  /// If a request is sent with CONTRAST_CURVE with the camera device's
  /// provided curve in FAST or HIGH_QUALITY, the image's tonemap will be
  /// roughly the same.
  ///
  /// __Possible values:__
  /// <ul>
  ///   <li>\#TONEMAP_MODE_CONTRAST_CURVE CONTRAST_CURVE</li>
  ///   <li>\#TONEMAP_MODE_FAST FAST</li>
  ///   <li>\#TONEMAP_MODE_HIGH_QUALITY HIGH_QUALITY</li>
  ///   <li>\#TONEMAP_MODE_GAMMA_VALUE GAMMA_VALUE</li>
  ///   <li>\#TONEMAP_MODE_PRESET_CURVE PRESET_CURVE</li>
  /// </ul>
  ///
  /// __Available values for this device:__<br>
  /// CameraCharacteristics\#TONEMAP_AVAILABLE_TONE_MAP_MODES android.tonemap.availableToneMapModes
  ///
  /// __Optional__ - This value may be {@code null} on some devices.
  ///
  /// __Full capability__ -
  /// Present on all camera devices that report being CameraCharacteristics\#INFO_SUPPORTED_HARDWARE_LEVEL_FULL HARDWARE_LEVEL_FULL devices in the
  /// CameraCharacteristics\#INFO_SUPPORTED_HARDWARE_LEVEL android.info.supportedHardwareLevel key
  ///
  ///@see CameraCharacteristics\#INFO_SUPPORTED_HARDWARE_LEVEL
  ///@see CameraCharacteristics\#TONEMAP_AVAILABLE_TONE_MAP_MODES
  ///@see CaptureRequest\#TONEMAP_CURVE
  ///@see CaptureRequest\#TONEMAP_MODE
  ///@see \#TONEMAP_MODE_CONTRAST_CURVE
  ///@see \#TONEMAP_MODE_FAST
  ///@see \#TONEMAP_MODE_HIGH_QUALITY
  ///@see \#TONEMAP_MODE_GAMMA_VALUE
  ///@see \#TONEMAP_MODE_PRESET_CURVE
  static CaptureResult_Key get TONEMAP_MODE =>
      CaptureResult_Key.fromRef(jniAccessors
          .getStaticField(_classRef, _id_TONEMAP_MODE, jni.JniType.objectType)
          .object);

  static final _id_TONEMAP_PRESET_CURVE = jniAccessors.getStaticFieldIDOf(
      _classRef,
      "TONEMAP_PRESET_CURVE",
      "Landroid/hardware/camera2/CaptureResult\$Key;");

  /// from: static public final android.hardware.camera2.CaptureResult.Key<java.lang.Integer> TONEMAP_PRESET_CURVE
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// Tonemapping curve to use when CaptureRequest\#TONEMAP_MODE android.tonemap.mode is
  /// PRESET_CURVE
  ///
  /// The tonemap curve will be defined by specified standard.
  ///
  /// sRGB (approximated by 16 control points):
  ///
  /// <img alt="sRGB tonemapping curve"src="/reference/images/camera2/metadata/android.tonemap.curveRed/srgb_tonemap.png"/>
  ///
  /// Rec. 709 (approximated by 16 control points):
  ///
  /// <img alt="Rec. 709 tonemapping curve"src="/reference/images/camera2/metadata/android.tonemap.curveRed/rec709_tonemap.png"/>
  ///
  /// Note that above figures show a 16 control points approximation of preset
  /// curves. Camera devices may apply a different approximation to the curve.
  ///
  /// __Possible values:__
  /// <ul>
  ///   <li>\#TONEMAP_PRESET_CURVE_SRGB SRGB</li>
  ///   <li>\#TONEMAP_PRESET_CURVE_REC709 REC709</li>
  /// </ul>
  ///
  /// __Optional__ - This value may be {@code null} on some devices.
  ///
  ///@see CaptureRequest\#TONEMAP_MODE
  ///@see \#TONEMAP_PRESET_CURVE_SRGB
  ///@see \#TONEMAP_PRESET_CURVE_REC709
  static CaptureResult_Key get TONEMAP_PRESET_CURVE =>
      CaptureResult_Key.fromRef(jniAccessors
          .getStaticField(
              _classRef, _id_TONEMAP_PRESET_CURVE, jni.JniType.objectType)
          .object);

  static final _id_ctor =
      jniAccessors.getMethodIDOf(_classRef, "<init>", "()V");

  /// from: void <init>()
  /// The returned object must be deleted after use, by calling the `delete` method.
  CaptureResult()
      : super.fromRef(
            jniAccessors.newObjectWithArgs(_classRef, _id_ctor, []).object);

  static final _id_getKeys =
      jniAccessors.getMethodIDOf(_classRef, "getKeys", "()Ljava/util/List;");

  /// from: public java.util.List<android.hardware.camera2.CaptureResult.Key<?>> getKeys()
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// {@inheritDoc}
  ///@return This value will never be {@code null}.
  jni.JniObject getKeys() =>
      jni.JniObject.fromRef(jniAccessors.callMethodWithArgs(
          reference, _id_getKeys, jni.JniType.objectType, []).object);

  static final _id_getRequest = jniAccessors.getMethodIDOf(
      _classRef, "getRequest", "()Landroid/hardware/camera2/CaptureRequest;");

  /// from: public android.hardware.camera2.CaptureRequest getRequest()
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// Get the request associated with this result.
  ///
  /// Whenever a request has been fully or partially captured, with
  /// CameraCaptureSession.CaptureCallback\#onCaptureCompleted or
  /// CameraCaptureSession.CaptureCallback\#onCaptureProgressed, the {@code result}'s
  /// {@code getRequest()} will return that {@code request}.
  ///
  ///
  ///
  /// For example,
  /// <code><pre>cameraDevice.capture(someRequest, new CaptureCallback() {
  ///     {@literal @}Override
  ///     void onCaptureCompleted(CaptureRequest myRequest, CaptureResult myResult) {
  ///         assert(myResult.getRequest.equals(myRequest) == true);
  ///     }
  /// }, null);
  /// </code></pre>
  ///
  ///
  ///@return The request associated with this result. Never {@code null}.
  capturerequest_.CaptureRequest getRequest() =>
      capturerequest_.CaptureRequest.fromRef(jniAccessors.callMethodWithArgs(
          reference, _id_getRequest, jni.JniType.objectType, []).object);

  static final _id_getFrameNumber =
      jniAccessors.getMethodIDOf(_classRef, "getFrameNumber", "()J");

  /// from: public long getFrameNumber()
  ///
  /// Get the frame number associated with this result.
  ///
  /// Whenever a request has been processed, regardless of failure or success,
  /// it gets a unique frame number assigned to its future result/failure.
  ///
  ///
  /// For the same type of request (capturing from the camera device or reprocessing), this
  /// value monotonically increments, starting with 0, for every new result or failure and the
  /// scope is the lifetime of the CameraDevice. Between different types of requests,
  /// the frame number may not monotonically increment. For example, the frame number of a newer
  /// reprocess result may be smaller than the frame number of an older result of capturing new
  /// images from the camera device, but the frame number of a newer reprocess result will never be
  /// smaller than the frame number of an older reprocess result.
  ///
  ///@return The frame number
  ///@see CameraDevice\#createCaptureRequest
  ///@see CameraDevice\#createReprocessCaptureRequest
  int getFrameNumber() => jniAccessors.callMethodWithArgs(
      reference, _id_getFrameNumber, jni.JniType.longType, []).long;

  static final _id_getSequenceId =
      jniAccessors.getMethodIDOf(_classRef, "getSequenceId", "()I");

  /// from: public int getSequenceId()
  ///
  /// The sequence ID for this failure that was returned by the
  /// CameraCaptureSession\#capture family of functions.
  ///
  /// The sequence ID is a unique monotonically increasing value starting from 0,
  /// incremented every time a new group of requests is submitted to the CameraDevice.
  ///
  ///@return int The ID for the sequence of requests that this capture result is a part of
  ///@see CameraDevice.CaptureCallback\#onCaptureSequenceCompleted
  ///@see CameraDevice.CaptureCallback\#onCaptureSequenceAborted
  int getSequenceId() => jniAccessors.callMethodWithArgs(
      reference, _id_getSequenceId, jni.JniType.intType, []).integer;
}

/// from: android.hardware.camera2.CaptureResult$Key
///
/// A {@code Key} is used to do capture result field lookups with
/// CaptureResult\#get.
///
/// For example, to get the timestamp corresponding to the exposure of the first row:
/// <code><pre>
/// long timestamp = captureResult.get(CaptureResult.SENSOR_TIMESTAMP);
/// </pre></code>
///
///
///
/// To enumerate over all possible keys for CaptureResult, see
/// CameraCharacteristics\#getAvailableCaptureResultKeys.
///
///@see CaptureResult\#get
///@see CameraCharacteristics\#getAvailableCaptureResultKeys
class CaptureResult_Key extends jni.JniObject {
  static final _classRef =
      jniAccessors.getClassOf("android/hardware/camera2/CaptureResult\$Key");
  CaptureResult_Key.fromRef(jni.JObject ref) : super.fromRef(ref);

  static final _id_ctor = jniAccessors.getMethodIDOf(
      _classRef, "<init>", "(Ljava/lang/String;Ljava/lang/Class;)V");

  /// from: void <init>(java.lang.String name, java.lang.Class<T> type)
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// Visible for testing and vendor extensions only.
  ///@hide
  CaptureResult_Key(jni.JniString name, jni.JniObject type)
      : super.fromRef(jniAccessors.newObjectWithArgs(
            _classRef, _id_ctor, [name.reference, type.reference]).object);

  static final _id_getName =
      jniAccessors.getMethodIDOf(_classRef, "getName", "()Ljava/lang/String;");

  /// from: public java.lang.String getName()
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// Return a camelCase, period separated name formatted like:
  /// {@code "root.section[.subsections].name"}.
  ///
  /// Built-in keys exposed by the Android SDK are always prefixed with {@code "android."};
  /// keys that are device/platform-specific are prefixed with {@code "com."}.
  ///
  ///
  /// For example, {@code CameraCharacteristics.SCALER_STREAM_CONFIGURATION_MAP} would
  /// have a name of {@code "android.scaler.streamConfigurationMap"}; whereas a device
  /// specific key might look like {@code "com.google.nexus.data.private"}.
  ///
  ///@return String representation of the key name
  ///
  /// This value will never be {@code null}.
  jni.JniString getName() =>
      jni.JniString.fromRef(jniAccessors.callMethodWithArgs(
          reference, _id_getName, jni.JniType.objectType, []).object);

  static final _id_hashCode1 =
      jniAccessors.getMethodIDOf(_classRef, "hashCode", "()I");

  /// from: public int hashCode()
  ///
  /// {@inheritDoc}
  int hashCode1() => jniAccessors.callMethodWithArgs(
      reference, _id_hashCode1, jni.JniType.intType, []).integer;

  static final _id_equals1 =
      jniAccessors.getMethodIDOf(_classRef, "equals", "(Ljava/lang/Object;)Z");

  /// from: public boolean equals(java.lang.Object o)
  ///
  /// {@inheritDoc}
  bool equals1(jni.JniObject o) => jniAccessors.callMethodWithArgs(
      reference, _id_equals1, jni.JniType.booleanType, [o.reference]).boolean;

  static final _id_toString1 =
      jniAccessors.getMethodIDOf(_classRef, "toString", "()Ljava/lang/String;");

  /// from: public java.lang.String toString()
  /// The returned object must be deleted after use, by calling the `delete` method.
  ///
  /// Return this Key as a string representation.
  ///
  /// {@code "CaptureResult.Key(%s)"}, where {@code %s} represents
  /// the name of this key as returned by \#getName.
  ///
  ///@return string representation of Key
  ///
  /// This value will never be {@code null}.
  jni.JniString toString1() =>
      jni.JniString.fromRef(jniAccessors.callMethodWithArgs(
          reference, _id_toString1, jni.JniType.objectType, []).object);
}
